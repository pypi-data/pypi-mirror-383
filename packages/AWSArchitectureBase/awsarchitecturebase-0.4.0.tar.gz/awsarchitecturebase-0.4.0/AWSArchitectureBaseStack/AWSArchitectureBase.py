"""
AWS Architecture Base Class
==========================

This module provides a base class for AWS infrastructure deployments
using CDKTF (Cloud Development Kit for Terraform) with Python.

The base class includes common functionality for:
    * Architecture flags management
    * S3 bucket operations and naming utilities
    * Terraform backend setup
    * Pre/post deployment script handling
    * Archetype integration
    * Common AWS resource patterns

:author: Generated by Claude Code
:version: 1.0.0
:license: MIT
"""

import os
import json
from enum import Enum
from constructs import Construct
from cdktf import TerraformStack, TerraformOutput, S3Backend

# AWS Provider and Resources
from cdktf_cdktf_provider_aws.provider import AwsProvider
from cdktf_cdktf_provider_aws import s3_bucket

# Random Provider
from cdktf_cdktf_provider_random.provider import RandomProvider

# Null Provider
from cdktf_cdktf_provider_null.provider import NullProvider



class AWSArchitectureBase(TerraformStack):
    """
    Base class for AWS infrastructure stacks.

    Provides common functionality for AWS deployments including:
        * Provider initialization (AWS, Random, Null)
        * S3 bucket management and naming utilities
        * Terraform backend configuration
        * Architecture flags management
        * Pre/post deployment script handling
        * Resource registry management

    :param scope: The construct scope
    :param id: The construct ID
    :param kwargs: Configuration parameters including region, profile, flags, etc.
    """

    # Class-level resource registry
    resources = {}

    # Default post-apply scripts executed after deployment
    default_post_apply_scripts = []

    @staticmethod
    def get_architecture_flags():
        """
        Get the ArchitectureFlags enum for configuration.

        :returns: ArchitectureFlags enum class
        :rtype: type[ArchitectureFlags]
        """
        from .ArchitectureFlags import ArchitectureFlags
        return ArchitectureFlags

    @staticmethod
    def get_archetype(product, app, tier, organization, region):
        """
        Get the BuzzerboyArchetype instance for advanced configuration.

        :param product: Product name
        :param app: Application name
        :param tier: Environment tier (dev, staging, prod)
        :param organization: Organization name
        :param region: AWS region
        :returns: BuzzerboyArchetype instance
        :rtype: BuzzerboyArchetype

        .. note::
           This method requires the BuzzerboyArchetypeStack module to be available.
        """
        from BuzzerboyArchetypeStack.BuzzerboyArchetype import BuzzerboyArchetype

        return BuzzerboyArchetype(product=product, app=app, tier=tier, organization=organization, region=region)

    @staticmethod
    def properize_s3_bucketname(string):
        """
        Convert a string to a valid S3 bucket name.

        Replaces invalid characters with hyphens and truncates to 63 characters
        as per AWS S3 bucket naming requirements.

        :param string: Input string to convert
        :type string: str
        :returns: Valid S3 bucket name
        :rtype: str

        Example:
            >>> AWSArchitectureBase.properize_s3_bucketname("My App_Name.v1")
            'my-app-name-v1'
        """
        return (
            string.lower()
            .replace(" ", "-")
            .replace("_", "-")
            .replace(".", "-")
            .replace(":", "-")
            .replace("/", "-")
            .replace("\\", "-")[:63]
        )

    @staticmethod
    def properize_s3_keyname(string):
        """
        Convert a string to a valid S3 key name.

        Similar to bucket name conversion but allows up to 255 characters.

        :param string: Input string to convert
        :type string: str
        :returns: Valid S3 key name
        :rtype: str
        """
        return (
            string.lower()
            .replace(" ", "-")
            .replace("_", "-")
            .replace(".", "-")
            .replace(":", "-")
            .replace("/", "-")
            .replace("\\", "-")[:255]
        )

    def __init__(self, scope, id, **kwargs):
        """
        Initialize the AWS Architecture Base.

        :param scope: The construct scope
        :param id: Unique identifier for this stack
        :param kwargs: Configuration parameters

        **Configuration Parameters:**

        :param region: AWS region (default: "us-east-1")
        :param environment: Environment name (default: "dev")
        :param project_name: Project identifier (default: "aws-architecture-app")
        :param profile: AWS profile to use (default: "default")
        :param flags: List of ArchitectureFlags to modify behavior
        :param postApplyScripts: List of shell commands to execute after deployment
        """
        super().__init__(scope, id)

        # ===== Base Configuration =====
        self.region = kwargs.get("region", "us-east-1")
        self.environment = kwargs.get("environment", "dev")
        self.project_name = kwargs.get("project_name", "aws-architecture-app")
        self.profile = kwargs.get("profile", "default")
        self.flags = kwargs.get("flags", [])
        self.post_apply_scripts = kwargs.get("postApplyScripts", []) or []

        # ===== Storage Configuration =====
        self.state_bucket_name = kwargs.get(
            "state_bucket_name", self.properize_s3_bucketname(f"{self.region}-{self.project_name}-tfstate")
        )

        # ===== Internal State =====
        self.secrets = {}
        self.post_terraform_messages = []
        self._post_plan_guidance: list[str] = []

        # ===== Base Infrastructure Setup =====
        self._boto_create_s3_bucket()
        self._setup_terraform_backend()
        self._initialize_providers()

    def clean_hyphens(self, string):
        """
        Clean hyphens and spaces from string for database naming.

        Converts hyphens and spaces to underscores and makes lowercase
        for database compatibility.

        :param string: Input string to clean
        :type string: str
        :returns: Cleaned string suitable for database names
        :rtype: str

        Example:
            >>> stack.clean_hyphens("my-app name")
            'my_app_name'
        """
        return string.replace("-", "_").replace(" ", "_").lower()

    def has_flag(self, flag):
        """
        Check if a specific architecture flag is set.

        :param flag: Flag to check (from ArchitectureFlags enum)
        :type flag: str
        :returns: True if flag is set, False otherwise
        :rtype: bool

        Example:
            >>> if stack.has_flag(ArchitectureFlags.SKIP_DATABASE.value):
            ...     print("Database creation skipped")
        """
        return flag in self.flags

    def _setup_terraform_backend(self):
        """Setup Terraform S3 backend configuration."""
        self.create_terraform_backend()

    def _initialize_providers(self):
        """Initialize all required Terraform providers."""
        # Main AWS provider for the specified region
        aws = AwsProvider(self, "aws", region=self.region, profile=self.profile)
        self.resources["aws"] = aws

        # Random provider for password generation
        RandomProvider(self, "random")
        self.resources["random"] = RandomProvider

        # Null provider for post-deployment scripts
        NullProvider(self, "null")
        self.resources["null"] = NullProvider

    def create_state_bucket(self):
        """
        Create S3 bucket for Terraform state storage.

        Creates a versioned, encrypted S3 bucket for storing Terraform state files.

        .. warning::
           This method creates the bucket resource but does not actually provision it.
           The bucket must exist before running Terraform operations.
        """
        self.state_bucket_name = f"{self.project_name}-tfstate"
        self.state_bucket_name = self.properize_s3_bucketname(self.state_bucket_name)
        self.state_bucket = s3_bucket.S3Bucket(
            self,
            f"{self.project_name}-tfstate-bucket",
            bucket=self.state_bucket_name,
            versioning=[{"enabled": True}],
            server_side_encryption_configuration=[
                {"rule": [{"apply_server_side_encryption_by_default": [{"sse_algorithm": "AES256"}]}]}
            ],
        )
        self.resources["state_bucket"] = self.state_bucket

    def _boto_create_s3_bucket(self):
        """
        Create S3 bucket using Boto3 with proper error handling and region support.

        This method checks if a bucket exists and creates it if necessary,
        handling AWS S3 bucket naming conventions and regional constraints.

        :returns: The bucket name if successful
        :rtype: str
        :raises: Exception if bucket creation fails

        .. note::
           This method is called automatically during initialization.
           The bucket name is automatically sanitized using properize_s3_bucketname() method.
        """
        import boto3
        from botocore.exceptions import ClientError

        # Create session with profile, then create client from session
        session = boto3.Session(profile_name=self.profile)
        s3 = session.client("s3", region_name=self.region)

        # Ensure bucket name follows AWS S3 naming conventions
        self.state_bucket_name = self.properize_s3_bucketname(self.state_bucket_name)

        # Check if bucket exists
        try:
            s3.head_bucket(Bucket=self.state_bucket_name)
            print(f"âœ“ Bucket '{self.state_bucket_name}' already exists")
            return self.state_bucket_name
        except ClientError as e:
            error_code = e.response['Error']['Code']

            if error_code == '404':
                # Bucket doesn't exist, create it
                try:
                    # Handle us-east-1 region special case (no LocationConstraint needed)
                    if self.region == 'us-east-1':
                        s3.create_bucket(Bucket=self.state_bucket_name)
                    else:
                        s3.create_bucket(
                            Bucket=self.state_bucket_name,
                            CreateBucketConfiguration={'LocationConstraint': self.region}
                        )

                    print(f"âœ“ Created bucket '{self.state_bucket_name}' in region '{self.region}'")
                    return self.state_bucket_name

                except ClientError as create_error:
                    print(f"âœ— Failed to create bucket '{self.state_bucket_name}': {create_error}")
                    raise create_error
            else:
                # Other errors (like access denied)
                print(f"âœ— Error accessing bucket '{self.state_bucket_name}': {e}")
                raise e

    def create_terraform_backend(self):
        """
        Configure Terraform S3 backend for state storage.

        Sets up remote state storage in S3 with proper bucket naming and
        creates a Terraform output with the bucket name for reference.

        .. important::
           The S3 bucket must be created manually before running cdktf deploy.
        """
        if not self.state_bucket_name:
            self.state_bucket_name = self.properize_s3_bucketname(f"{self.region}-{self.__class__.__name__}-tfstate")

        TerraformOutput(
            self,
            "state_bucket_name",
            value=self.state_bucket_name,
            description=(
                "Name of the S3 bucket for Terraform state. "
                "This bucket must be created before running cdktf deploy with S3Backend."
            ),
        )

        S3Backend(self, bucket=self.state_bucket_name, key=f"{self.project_name}/terraform.tfstate", region=self.region)