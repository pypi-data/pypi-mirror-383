Metadata-Version: 2.4
Name: semanticscout
Version: 1.0.0
Summary: A semantic code search MCP server for AI agents to index and retrieve code from codebases
Author-email: Psynosaur <psynosaur@gmail.com>
Maintainer-email: Psynosaur <psynosaur@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/Psynosaur/SemanticScout
Project-URL: Repository, https://github.com/Psynosaur/SemanticScout.git
Project-URL: Issues, https://github.com/Psynosaur/SemanticScout/issues
Project-URL: Documentation, https://github.com/Psynosaur/SemanticScout#readme
Keywords: mcp,context-engine,code-search,vector-database,ai-agents,semantic-search,ollama,chromadb
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: mcp[cli]>=1.2.0
Requires-Dist: chromadb>=0.4.0
Requires-Dist: openai>=1.0.0
Requires-Dist: tree-sitter>=0.20.0
Requires-Dist: tree-sitter-languages>=1.10.0; python_version < "3.13"
Requires-Dist: httpx>=0.25.0
Requires-Dist: pathspec>=0.11.0
Requires-Dist: watchdog>=3.0.0
Requires-Dist: python-dotenv>=1.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.4.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-mock>=3.11.0; extra == "dev"
Requires-Dist: pytest-cov>=4.1.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: mypy>=1.5.0; extra == "dev"

# SemanticScout ğŸ”

> A powerful semantic code search engine for AI agents, built as an MCP server

[![Tests](https://img.shields.io/badge/tests-172%20passing-brightgreen)]()
[![Coverage](https://img.shields.io/badge/coverage-74%25-yellow)]()
[![Python](https://img.shields.io/badge/python-3.12-blue)]()
[![License](https://img.shields.io/badge/license-MIT-blue)]()

SemanticScout is a **Model Context Protocol (MCP) server** that enables AI agents to understand and search codebases using semantic search. It indexes code files, generates embeddings, and provides natural language search capabilities.

## âœ¨ Features

- ğŸ” **Semantic Code Search** - Find code using natural language queries
- ğŸŒ³ **AST-Based Chunking** - Intelligent code splitting that preserves semantic meaning
- ğŸŒ **Multi-Language Support** - Python, JavaScript, TypeScript, Java, C++, Go, Rust, C#, and more
- ğŸ  **Local or Cloud Embeddings** - Use Ollama (free, local) or OpenAI (cloud, paid)
- âš¡ **GPU Acceleration** - Uses your host's Ollama with GPU support automatically
- ğŸ”’ **Security Built-in** - Path validation, rate limiting, and resource limits
- ğŸ“Š **Progress Reporting** - Real-time feedback during indexing
- ğŸ¤– **MCP Integration** - Works with Claude Desktop and other MCP clients

## ğŸš€ Quick Start

Get started in minutes with **uvx** - zero installation required!

### Prerequisites

- **uv** - [Install uv](https://docs.astral.sh/uv/getting-started/installation/)
- **Ollama** (running locally) - [Install Ollama](https://ollama.ai/)
- **Claude Desktop** (or other MCP client) - [Install Claude Desktop](https://claude.ai/download)

### 1. Setup Ollama

```bash
# Start Ollama service
ollama serve

# Pull the embedding model
ollama pull nomic-embed-text
```

### 2. Configure Claude Desktop

Add to your Claude Desktop MCP configuration (`%APPDATA%\Claude\claude_desktop_config.json` on Windows or `~/Library/Application Support/Claude/claude_desktop_config.json` on Mac):

```json
{
  "mcpServers": {
    "semanticscout": {
      "command": "uvx",
      "args": ["--python", "3.12", "semanticscout@latest"],
      "env": {
        "OLLAMA_BASE_URL": "http://localhost:11434"
      }
    }
  }
}
```

**Note:** We specify `--python 3.12` because some dependencies don't yet support Python 3.13. If you only have Python 3.13, install Python 3.12 with `brew install python@3.12` (Mac) or download from [python.org](https://www.python.org/downloads/) (Windows).

**Optional: Custom Data Directory**

By default, uvx stores data in `~/.semanticscout/`. To use a custom location:

```json
{
  "mcpServers": {
    "semanticscout": {
      "command": "uvx",
      "args": [
        "--python", "3.12",
        "semanticscout@latest",
        "--data-dir", "/path/to/your/data"
      ],
      "env": {
        "OLLAMA_BASE_URL": "http://localhost:11434"
      }
    }
  }
}
```

### 3. Restart Claude Desktop

That's it! SemanticScout will be automatically downloaded and run when Claude needs it.

**âœ¨ Benefits:**
- âœ… No manual installation
- âœ… Always uses latest version
- âœ… Automatic dependency management
- âœ… Isolated environment per run
- âœ… Works on Windows, Mac, and Linux
- âœ… Data stored in `~/.semanticscout/` (or custom location)

---

## ğŸ“– Usage

Once configured in Claude Desktop, you can use natural language to interact with the MCP server:

### Example Conversations

**Index a codebase:**
```
You: "Index my codebase at /workspace"
Claude: [Calls index_codebase tool and shows indexing progress]
```

**Search for code:**
```
You: "Find the authentication logic"
Claude: [Calls search_code tool and shows relevant code snippets]
```

**List indexed projects:**
```
You: "What codebases have been indexed?"
Claude: [Calls list_collections tool and shows all indexed projects]
```

**Clear an index:**
```
You: "Delete the index for my old project"
Claude: [Calls clear_index tool after confirmation]
```

### Available MCP Tools

The server exposes these tools to Claude (you don't call them directly):

| Tool | Description | Parameters |
|------|-------------|------------|
| `index_codebase` | Index a codebase for semantic search | `path` (optional, defaults to `/workspace`) |
| `search_code` | Search indexed code with natural language | `query`, `collection_name`, `top_k` |
| `list_collections` | List all indexed codebases | None |
| `get_indexing_status` | Get statistics for a collection | `collection_name` |
| `clear_index` | Delete a collection (permanent) | `collection_name` |

## âš™ï¸ Configuration

Configuration is done via environment variables in the MCP JSON config:

### MCP JSON Configuration

```json
{
  "mcpServers": {
    "semanticscout": {
      "command": "uvx",
      "args": ["--python", "3.12", "semanticscout@latest"],
      "env": {
        "OLLAMA_BASE_URL": "http://localhost:11434",
        "OLLAMA_MODEL": "nomic-embed-text",
        "MAX_FILE_SIZE_MB": "10.0"
      }
    }
  }
}
```

**With custom data directory:**

```json
{
  "mcpServers": {
    "semanticscout": {
      "command": "uvx",
      "args": [
        "--python", "3.12",
        "semanticscout@latest",
        "--data-dir", "~/semanticscout-data"
      ],
      "env": {
        "OLLAMA_BASE_URL": "http://localhost:11434"
      }
    }
  }
}
```

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_BASE_URL` | `http://localhost:11434` | Ollama server URL |
| `OLLAMA_MODEL` | `nomic-embed-text` | Embedding model to use |
| `MAX_FILE_SIZE_MB` | `10.0` | Skip files larger than this |
| `MAX_CODEBASE_SIZE_GB` | `10.0` | Maximum total codebase size |
| `MAX_FILES` | `100000` | Maximum number of files |
| `CHUNK_SIZE_MIN` | `500` | Minimum chunk size (chars) |
| `CHUNK_SIZE_MAX` | `1500` | Maximum chunk size (chars) |
| `LOG_LEVEL` | `INFO` | Logging level |

**Note:** Most users won't need to change these defaults. The MCP server will work out of the box with Ollama running locally.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP Client    â”‚  (Claude Desktop, etc.)
â”‚  (AI Agent)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ JSON-RPC over STDIO
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP Server    â”‚
â”‚  (FastMCP)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚        â”‚          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
â”‚Indexerâ”‚ â”‚Queryâ”‚ â”‚Securityâ”‚ â”‚Vector â”‚
â”‚       â”‚ â”‚Proc â”‚ â”‚        â”‚ â”‚ Store â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚        â”‚                    â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
â”‚         ChromaDB (Vector DB)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

- **File Discovery**: Finds code files, respects `.gitignore`
- **Code Chunker**: AST-based semantic chunking with tree-sitter
- **Embedding Provider**: Generates vector embeddings (Ollama/OpenAI)
- **Vector Store**: Stores and searches embeddings (ChromaDB)
- **Query Processor**: Converts queries to embeddings, caching
- **Semantic Searcher**: Finds relevant code chunks
- **Security Validators**: Path validation, rate limiting, input sanitization

## ğŸ§ª Development

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov

# Run specific test file
pytest tests/unit/test_semantic_search.py -v
```

### Test Coverage

Current coverage: **74%** (172 tests passing)

- File Discovery: 83%
- Code Chunker: 92%
- Ollama Provider: 92%
- Vector Store: 100%
- Query Processor: 100%
- Semantic Search: 99%
- Security Validators: 95%

### Project Structure

```
semanticscout/
â”œâ”€â”€ src/semanticscout/
â”‚   â”œâ”€â”€ mcp_server.py          # MCP server entry point
â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ logging_config.py      # Logging setup
â”‚   â”œâ”€â”€ indexer/               # Indexing components
â”‚   â”‚   â”œâ”€â”€ file_discovery.py
â”‚   â”‚   â”œâ”€â”€ code_chunker.py
â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”œâ”€â”€ embeddings/            # Embedding providers
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â””â”€â”€ ollama_provider.py
â”‚   â”œâ”€â”€ vector_store/          # Vector database
â”‚   â”‚   â””â”€â”€ chroma_store.py
â”‚   â”œâ”€â”€ retriever/             # Search components
â”‚   â”‚   â”œâ”€â”€ query_processor.py
â”‚   â”‚   â””â”€â”€ semantic_search.py
â”‚   â””â”€â”€ security/              # Security & validation
â”‚       â””â”€â”€ validators.py
â”œâ”€â”€ tests/                     # Unit tests
â”œâ”€â”€ examples/                  # Example scripts
â””â”€â”€ docs/                      # Documentation
```

## ğŸ“š Examples

See the [examples/](examples/) directory for working examples:

- `test_full_pipeline.py` - Complete indexing and search workflow
- `test_retrieval_system.py` - Advanced search with filtering
- `index_weather_unified.py` - Real-world codebase indexing

## ğŸ› Troubleshooting

### Python Version Issues

**Error:** `No module named 'onnxruntime'` or tree-sitter compatibility issues

**Solution:** Use Python 3.12 (not 3.14). See [PYTHON_VERSION_ISSUE.md](PYTHON_VERSION_ISSUE.md).

### Ollama Not Running

**Error:** `Ollama server not available`

**Solution:** Start Ollama and pull the model:
```bash
ollama serve
ollama pull nomic-embed-text
```

### Rate Limit Exceeded

**Error:** `Rate limit exceeded: Maximum X requests per hour`

**Solution:** Adjust rate limits in `.env`:
```bash
MAX_INDEXING_REQUESTS_PER_HOUR=20
MAX_SEARCH_REQUESTS_PER_MINUTE=200
```

### Path Not Allowed

**Error:** `Path is not within allowed directories`

**Solution:** The server only allows indexing within the current working directory by default.

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- [Anthropic](https://anthropic.com/) for the MCP protocol
- [Ollama](https://ollama.ai/) for local embeddings
- [ChromaDB](https://www.trychroma.com/) for vector storage
- [Tree-sitter](https://tree-sitter.github.io/) for code parsing

---

**Built with â¤ï¸ for the AI agent ecosystem**

