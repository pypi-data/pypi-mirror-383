# åŸºç¡€ç”¨æ³•ç¤ºä¾‹

æœ¬é¡µé¢æä¾›äº†åœ¨å¸¸è§åœºæ™¯ä¸­ä½¿ç”¨ Hypergraph-DB çš„å®ç”¨ç¤ºä¾‹ã€‚

## ç¤ºä¾‹ 1: å­¦æœ¯åˆä½œç½‘ç»œ

å»ºæ¨¡å­¦è€…ä¹‹é—´çš„ç ”ç©¶åˆä½œå…³ç³»ï¼š

```python
from hyperdb import HypergraphDB

# åˆ›å»ºè¶…å›¾
hg = HypergraphDB()

# æ·»åŠ ç ”ç©¶äººå‘˜ä½œä¸ºé¡¶ç‚¹
researchers = {
    "alice": {"name": "å¼ çˆ±ä¸½åšå£«", "field": "æœºå™¨å­¦ä¹ ", "university": "æ¸…åå¤§å­¦"},
    "bob": {"name": "ç‹åšæ–‡æ•™æˆ", "field": "è‡ªç„¶è¯­è¨€å¤„ç†", "university": "åŒ—äº¬å¤§å­¦"},
    "charlie": {"name": "ææŸ¥ç†ç ”ç©¶å‘˜", "field": "è®¡ç®—æœºè§†è§‰", "university": "ä¸­ç§‘é™¢"},
    "diana": {"name": "é™ˆé»›å®‰å‰¯æ•™æˆ", "field": "æœºå™¨äººå­¦", "university": "å¤æ—¦å¤§å­¦"},
    "eve": {"name": "åˆ˜ä¼ŠèŠ™è®²å¸ˆ", "field": "ç†è®ºè®¡ç®—æœº", "university": "ä¸Šæµ·äº¤å¤§"}
}

for researcher_id, info in researchers.items():
    hg.add_v(researcher_id, info)

# æ·»åŠ è®ºæ–‡ä½œä¸ºè¶…è¾¹ï¼ˆè¿æ¥æ‰€æœ‰å…±åŒä½œè€…ï¼‰
papers = [
    (("alice", "bob"), {
        "title": "æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€ç†è§£ä¸­çš„åº”ç”¨",
        "year": 2023,
        "venue": "AAAI",
        "citations": 45
    }),
    (("alice", "charlie"), {
        "title": "è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨åœºæ™¯ç†è§£ä¸­çš„åº”ç”¨",
        "year": 2023,
        "venue": "CVPR",
        "citations": 38
    }),
    (("bob", "charlie", "diana"), {
        "title": "è‡ªä¸»ç³»ç»Ÿçš„å¤šæ¨¡æ€äººå·¥æ™ºèƒ½",
        "year": 2024,
        "venue": "NeurIPS",
        "citations": 12
    }),
    (("alice", "bob", "charlie", "eve"), {
        "title": "ç°ä»£äººå·¥æ™ºèƒ½çš„ç†è®ºåŸºç¡€",
        "year": 2024,
        "venue": "JMLR",
        "citations": 28
    })
]

for authors, paper_info in papers:
    hg.add_e(authors, paper_info)

# åˆ†æç½‘ç»œ
print(f"å­¦æœ¯ç½‘ç»œåŒ…å« {hg.num_v} ä½ç ”ç©¶äººå‘˜å’Œ {hg.num_e} ç¯‡åˆä½œè®ºæ–‡")

# æ‰¾å‡ºæœ€æ´»è·ƒçš„ç ”ç©¶äººå‘˜
most_collaborative = max(hg.all_v, key=lambda v: hg.degree_v(v))
print(f"æœ€æ´»è·ƒçš„ç ”ç©¶äººå‘˜: {hg.v(most_collaborative)['name']} "
      f"({hg.degree_v(most_collaborative)} ç¯‡è®ºæ–‡)")

# æ‰¾å‡ºæœ€å¤§çš„åˆä½œé¡¹ç›®
largest_paper = max(hg.all_e, key=lambda e: hg.degree_e(e))
num_authors = hg.degree_e(largest_paper)
print(f"æœ€å¤§åˆä½œé¡¹ç›®: {num_authors} ä½ä½œè€…")

# å¯è§†åŒ–ç½‘ç»œ
hg.draw()
```

## ç¤ºä¾‹ 2: ç”µå­å•†åŠ¡æ¨èç³»ç»Ÿ

å»ºæ¨¡è´­ç‰©æ¨¡å¼å’Œäº§å“å…³ç³»ï¼š

```python
from hyperdb import HypergraphDB
from collections import defaultdict

# åˆ›å»ºç”µå•†è¶…å›¾
hg = HypergraphDB()

# æ·»åŠ äº§å“ä½œä¸ºé¡¶ç‚¹
products = {
    "laptop_1": {"name": "æ¸¸æˆç¬”è®°æœ¬", "category": "ç”µè„‘", "price": 8999},
    "mouse_1": {"name": "æ¸¸æˆé¼ æ ‡", "category": "é…ä»¶", "price": 299},
    "keyboard_1": {"name": "æœºæ¢°é”®ç›˜", "category": "é…ä»¶", "price": 599},
    "monitor_1": {"name": "4Kæ˜¾ç¤ºå™¨", "category": "é…ä»¶", "price": 2199},
    "headset_1": {"name": "æ¸¸æˆè€³æœº", "category": "é…ä»¶", "price": 799},
    "phone_1": {"name": "æ™ºèƒ½æ‰‹æœº", "category": "æ‰‹æœº", "price": 4999}
}

for product_id, info in products.items():
    hg.add_v(product_id, info)

# æ·»åŠ è´­ç‰©ä¼šè¯ä½œä¸ºè¶…è¾¹ï¼ˆåœ¨åŒä¸€è®¢å•ä¸­è´­ä¹°çš„äº§å“ï¼‰
shopping_sessions = [
    (("laptop_1", "mouse_1", "keyboard_1"), {"user": "ç”¨æˆ·A", "date": "2024-01-15", "total": 9897}),
    (("laptop_1", "monitor_1"), {"user": "ç”¨æˆ·B", "date": "2024-01-16", "total": 11198}),
    (("mouse_1", "keyboard_1", "headset_1"), {"user": "ç”¨æˆ·C", "date": "2024-01-17", "total": 1697}),
    (("phone_1", "headset_1"), {"user": "ç”¨æˆ·D", "date": "2024-01-18", "total": 5798}),
    (("laptop_1", "mouse_1", "keyboard_1", "monitor_1"), {"user": "ç”¨æˆ·E", "date": "2024-01-19", "total": 12496})
]

for products_in_session, session_info in shopping_sessions:
    hg.add_e(products_in_session, session_info)

# å•†å“æ¨èåŠŸèƒ½
def find_frequently_bought_together(product_id, min_frequency=1):
    """æ‰¾å‡ºç»å¸¸ä¸ç»™å®šäº§å“ä¸€èµ·è´­ä¹°çš„å•†å“"""
    sessions_with_product = hg.nbr_e_of_v(product_id)
    
    # ç»Ÿè®¡å…±ç°æ¬¡æ•°
    co_occurrence = defaultdict(int)
    for session in sessions_with_product:
        other_products = hg.nbr_v_of_e(session) - {product_id}
        for other_product in other_products:
            co_occurrence[other_product] += 1
    
    # è¿‡æ»¤æœ€å°é¢‘ç‡
    recommendations = {product: count for product, count in co_occurrence.items() 
                      if count >= min_frequency}
    
    # æŒ‰é¢‘ç‡æ’åº
    return sorted(recommendations.items(), key=lambda x: x[1], reverse=True)

# ç”Ÿæˆæ¨è
laptop_recommendations = find_frequently_bought_together("laptop_1")
print("ä¸æ¸¸æˆç¬”è®°æœ¬ç»å¸¸ä¸€èµ·è´­ä¹°çš„äº§å“:")
for product, frequency in laptop_recommendations:
    product_name = hg.v(product)["name"]
    print(f"  {product_name}: {frequency} æ¬¡")

# æ‰¾å‡ºæœ€å—æ¬¢è¿çš„äº§å“ç±»åˆ«
category_popularity = defaultdict(int)
for edge in hg.all_e:
    products_in_session = hg.nbr_v_of_e(edge)
    for product in products_in_session:
        category = hg.v(product)["category"]
        category_popularity[category] += 1

print("\näº§å“ç±»åˆ«å—æ¬¢è¿ç¨‹åº¦:")
for category, count in sorted(category_popularity.items(), key=lambda x: x[1], reverse=True):
    print(f"  {category}: {count} æ¬¡è´­ä¹°")

# å¯è§†åŒ–è´­ç‰©ç½‘ç»œ
hg.draw()
```

## ç¤ºä¾‹ 3: ç¤¾äº¤ç½‘ç»œåˆ†æ

å»ºæ¨¡ç¾¤ä½“äº’åŠ¨å’Œå¤šæ–¹å…³ç³»ï¼š

```python
# åˆ›å»ºç¤¾äº¤ç½‘ç»œè¶…å›¾
social_hg = HypergraphDB()

# æ·»åŠ äººå‘˜
people = {
    "alice": {"name": "çˆ±ä¸½ä¸", "age": 28, "city": "åŒ—äº¬", "interests": ["è¯»ä¹¦", "æ—…è¡Œ", "æ‘„å½±"]},
    "bob": {"name": "é²å‹ƒ", "age": 32, "city": "ä¸Šæµ·", "interests": ["è¿åŠ¨", "éŸ³ä¹", "ç¼–ç¨‹"]},
    "charlie": {"name": "æŸ¥ç†", "age": 25, "city": "æ·±åœ³", "interests": ["æ¸¸æˆ", "åŠ¨æ¼«", "ç¾é£Ÿ"]},
    "diana": {"name": "é»›å®‰", "age": 30, "city": "æ­å·", "interests": ["è‰ºæœ¯", "è®¾è®¡", "æ—…è¡Œ"]},
    "eve": {"name": "ä¼ŠèŠ™", "age": 27, "city": "æˆéƒ½", "interests": ["ç¾é£Ÿ", "éŸ³ä¹", "å¥èº«"]}
}

for person_id, info in people.items():
    social_hg.add_v(person_id, info)

# æ·»åŠ ç¾¤ä½“æ´»åŠ¨ä½œä¸ºè¶…è¾¹
group_activities = [
    (("alice", "bob"), {"activity": "å’–å•¡èŠå¤©", "date": "2024-01-10", "location": "æ˜Ÿå·´å…‹"}),
    (("alice", "diana"), {"activity": "ç¾æœ¯é¦†å‚è§‚", "date": "2024-01-12", "location": "å›½å®¶ç¾æœ¯é¦†"}),
    (("bob", "charlie", "eve"), {"activity": "å¥èº«æˆ¿", "date": "2024-01-15", "location": "24å°æ—¶å¥èº«"}),
    (("alice", "charlie", "diana"), {"activity": "æ‘„å½±å¤–æ‹", "date": "2024-01-18", "location": "é¢å’Œå›­"}),
    (("bob", "diana", "eve", "charlie"), {"activity": "èšé¤", "date": "2024-01-20", "location": "å·èœé¦†"})
]

for participants, activity_info in group_activities:
    social_hg.add_e(participants, activity_info)

# ç¤¾äº¤ç½‘ç»œåˆ†æ
print(f"ç¤¾äº¤ç½‘ç»œåŒ…å« {social_hg.num_v} ä¸ªäººå’Œ {social_hg.num_e} ä¸ªç¾¤ä½“æ´»åŠ¨")

# æ‰¾å‡ºæœ€ç¤¾äº¤çš„äººï¼ˆæœ€é«˜åº¦æ•°ï¼‰
most_social = max(social_hg.all_v, key=lambda v: social_hg.degree_v(v))
print(f"æœ€ç¤¾äº¤çš„äºº: {social_hg.v(most_social)['name']} "
      f"(å‚ä¸ {social_hg.degree_v(most_social)} ä¸ªæ´»åŠ¨)")

# åˆ†æç¾¤ä½“è§„æ¨¡
group_sizes = [social_hg.degree_e(e) for e in social_hg.all_e]
avg_group_size = sum(group_sizes) / len(group_sizes)
print(f"å¹³å‡ç¾¤ä½“è§„æ¨¡: {avg_group_size:.1f}")
print(f"æœ€å¤§ç¾¤ä½“: {max(group_sizes)} äºº")

# æ‰¾å‡ºå…´è¶£ç›¸ä¼¼çš„ç¤¾åŒº
print("\nåŸºäºå…±åŒæ´»åŠ¨çš„ç¤¾åŒº:")
for edge in social_hg.all_e:
    if social_hg.degree_e(edge) >= 3:  # è‡³å°‘3äººçš„ç¾¤ä½“
        participants = social_hg.nbr_v_of_e(edge)
        activity = social_hg.e(edge)
        
        # æ‰¾å‡ºå…±åŒå…´è¶£
        if len(participants) > 1:
            common_interests = set(social_hg.v(list(participants)[0])["interests"])
            for person in participants:
                common_interests &= set(social_hg.v(person)["interests"])
            
            if common_interests:
                print(f"  {activity['activity']}: {len(participants)} äººï¼Œå…±åŒå…´è¶£: {', '.join(common_interests)}")

# æ‰¾å‡ºç¤¾äº¤æ¡¥æ¢ï¼ˆè¿æ¥ä¸åŒç¾¤ä½“çš„äººï¼‰
print("\nç¤¾äº¤æ¡¥æ¢:")
for person in social_hg.all_v:
    person_groups = social_hg.nbr_e_of_v(person)
    if len(person_groups) >= 2:
        # æ£€æŸ¥æ˜¯å¦è¿æ¥äº†ä¸åŒçš„ç¾¤ä½“
        unique_groups = set()
        for group1 in person_groups:
            for group2 in person_groups:
                if group1 != group2:
                    # æ£€æŸ¥ä¸¤ä¸ªç¾¤ä½“æ˜¯å¦æœ‰å…¶ä»–å…±åŒæˆå‘˜
                    group1_members = social_hg.nbr_v_of_e(group1) - {person}
                    group2_members = social_hg.nbr_v_of_e(group2) - {person}
                    if not group1_members.intersection(group2_members):
                        unique_groups.add((group1, group2))
        
        if unique_groups:
            name = social_hg.v(person)["name"]
            num_groups = social_hg.degree_v(person)
            print(f"  {name} (è¿æ¥ {num_groups} ä¸ªç¾¤ä½“)")

# å¯è§†åŒ–ç¤¾äº¤ç½‘ç»œ
social_hg.draw()
```

## ç¤ºä¾‹ 4: çŸ¥è¯†å›¾è°±

å»ºæ¨¡å¤æ‚çš„çŸ¥è¯†å…³ç³»ï¼š

```python
# åˆ›å»ºçŸ¥è¯†å›¾è°±è¶…å›¾
kg = HypergraphDB()

# æ·»åŠ å®ä½“
entities = {
    "einstein": {"name": "é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦", "type": "äººç‰©", "birth_year": 1879},
    "relativity": {"name": "ç›¸å¯¹è®º", "type": "ç†è®º", "year": 1905},
    "nobel_prize": {"name": "è¯ºè´å°”ç‰©ç†å­¦å¥–", "type": "å¥–é¡¹", "year": 1921},
    "princeton": {"name": "æ™®æ—æ–¯é¡¿å¤§å­¦", "type": "æœºæ„", "founded": 1746},
    "photoelectric": {"name": "å…‰ç”µæ•ˆåº”", "type": "ç°è±¡", "discovery": 1905},
    "quantum": {"name": "é‡å­åŠ›å­¦", "type": "ç†è®º", "era": "20ä¸–çºªåˆ"}
}

for entity_id, info in entities.items():
    kg.add_v(entity_id, info)

# æ·»åŠ å¤æ‚å…³ç³»ä½œä¸ºè¶…è¾¹
knowledge_relations = [
    (("einstein", "relativity"), {"relation": "æå‡º", "year": 1905, "impact": "é©å‘½æ€§"}),
    (("einstein", "nobel_prize", "photoelectric"), {"relation": "å› ...è·å¾—", "year": 1921}),
    (("einstein", "princeton"), {"relation": "ä»»èŒäº", "period": "1933-1955"}),
    (("relativity", "quantum", "einstein"), {"relation": "ç†è®ºè´¡çŒ®", "field": "ç°ä»£ç‰©ç†å­¦"}),
    (("photoelectric", "quantum"), {"relation": "ç†è®ºåŸºç¡€", "contribution": "é‡å­æ¦‚å¿µ"})
]

for vertices, relation_info in knowledge_relations.items():
    kg.add_e(vertices, relation_info)

# çŸ¥è¯†å›¾è°±åˆ†æ
print(f"çŸ¥è¯†å›¾è°±åŒ…å« {kg.num_v} ä¸ªå®ä½“å’Œ {kg.num_e} ä¸ªå…³ç³»")

# æ‰¾å‡ºæœ€é‡è¦çš„å®ä½“ï¼ˆæœ€é«˜åº¦æ•°ï¼‰
most_important = max(kg.all_v, key=lambda v: kg.degree_v(v))
entity_info = kg.v(most_important)
print(f"æœ€é‡è¦çš„å®ä½“: {entity_info['name']} ({entity_info['type']})")

# åˆ†æè·å¥–ä¿¡æ¯
print("\nè·å¥–ä¿¡æ¯:")
for edge in kg.all_e:
    edge_info = kg.e(edge)
    if "nobel_prize" in kg.nbr_v_of_e(edge):
        winner = [e for e in kg.nbr_v_of_e(edge) if e != "nobel_prize"][0]
        winner_info = kg.v(winner)
        print(f"  {winner_info['name']} äº {edge_info['year']} å¹´è·å¾—è¯ºè´å°”å¥–")

# ç†è®ºå‘å±•å…³ç³»
print("\nç†è®ºå‘å±•:")
for edge in kg.all_e:
    if kg.degree_e(edge) >= 3:  # å¤šå…ƒå…³ç³»
        entities_in_relation = kg.nbr_v_of_e(edge)
        theory_entities = [e for e in entities_in_relation if kg.v(e)['type'] == 'theory']
        
        if len(theory_entities) >= 2:
            theory_name = kg.v(theory_entities[0])['name']
            developer_names = [kg.v(dev)['name'] for dev in entities_in_relation if kg.v(dev)['type'] == 'person']
            print(f"  {theory_name}: {', '.join(developer_names)}")

# å¯è§†åŒ–çŸ¥è¯†å›¾è°±
kg.draw()
```

## æœ‰æ•ˆä½¿ç”¨æŠ€å·§

### 1. é€‰æ‹©æœ‰æ„ä¹‰çš„ ID
```python
# å¥½çš„: æè¿°æ€§ ID
hg.add_v("user_alice_chen", {"name": "é™ˆçˆ±ä¸½ä¸"})

# ä¸å¥½çš„: æ— æ„ä¹‰çš„æ•°å­—
hg.add_v(12345, {"name": "é™ˆçˆ±ä¸½ä¸"})
```

### 2. ç»“æ„åŒ–æ•°æ®å±æ€§
```python
# å¥½çš„: ç»“æ„åŒ–å±æ€§
hg.add_v("researcher_001", {
    "personal": {"name": "å¼ ä¸‰", "age": 35},
    "academic": {"field": "AI", "university": "æ¸…å"},
    "contact": {"email": "zhang@example.com"}
})
```

### 3. æœ‰æ„ä¹‰çš„è¶…è¾¹æ•°æ®
```python
# å¥½çš„: ä¸°å¯Œçš„è¶…è¾¹ä¿¡æ¯
hg.add_e(("alice", "bob", "charlie"), {
    "event": "é¡¹ç›®ä¼šè®®",
    "project": "ç§»åŠ¨åº”ç”¨å¼€å‘",
    "date": "2024-01-15",
    "duration": "2å°æ—¶",
    "outcome": "ç¡®å®šæŠ€æœ¯æ–¹æ¡ˆ"
})
```

### 4. ä¸€è‡´çš„æ•°æ®æ ¼å¼
```python
# ç¡®ä¿åŒç±»æ•°æ®æ ¼å¼ä¸€è‡´
date_format = "%Y-%m-%d"
for event_data in events:
    hg.add_e(event_data["participants"], {
        "date": event_data["date"].strftime(date_format),
        "type": event_data["type"]
    })
```

### 5. æ‰¹é‡æ“ä½œæå‡æ€§èƒ½
```python
# å¥½çš„: æ‰¹é‡æ“ä½œ
vertices_to_add = [
    ("v1", {"name": "é¡¶ç‚¹1"}),
    ("v2", {"name": "é¡¶ç‚¹2"}),
    # ... æ›´å¤šé¡¶ç‚¹
]

for vertex_id, vertex_data in vertices_to_add:
    hg.add_v(vertex_id, vertex_data)
```

## ä¸‹ä¸€æ­¥

ç°åœ¨æ‚¨å·²ç»çœ‹åˆ°äº†åŸºæœ¬ç”¨æ³•ï¼Œæ‚¨å¯ä»¥ï¼š

- **[æ¢ç´¢é«˜çº§åŠŸèƒ½](advanced.zh.md)**: å¤æ‚åˆ†æå’Œç®—æ³•
- **[å­¦ä¹  API è¯¦ç»†ä¿¡æ¯](../api/index.zh.md)**: æ·±å…¥äº†è§£æ‰€æœ‰æ–¹æ³•
- **[å¯è§†åŒ–æŒ‡å—](../visualization/index.zh.md)**: åˆ›å»ºä»¤äººå°è±¡æ·±åˆ»çš„å¯è§†åŒ–

ç¥æ‚¨ä½¿ç”¨ Hypergraph-DB æ„‰å¿«ï¼ğŸš€
