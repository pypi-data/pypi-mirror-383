import React, { createRef } from "react"
import {
  Streamlit,
  StreamlitComponentBase,
  withStreamlitConnection,
} from "streamlit-component-lib"
import { BarVisualizer } from "./components/visualizers/bar-visualizer"
import { OrbVisualizer } from "./components/visualizers/orb-visualizer"
import type { BarAgentState, OrbAgentState } from "./types"
import "./index.css"

type AudioState = "loading" | "playing" | "ended" | "idle"

interface State {
  mediaStream: MediaStream | null
  audioState: AudioState
  audioVolume: number
}

class BarVisualizerComponent extends StreamlitComponentBase<State> {
  public state: State = { mediaStream: null, audioState: "idle", audioVolume: 0 }
  private audioRef = createRef<HTMLAudioElement>()
  private analyzerRef: AnalyserNode | null = null
  private audioContextRef: AudioContext | null = null
  private animationFrameId: number | null = null

  public render = (): React.ReactNode => {
    const mode = this.props.args["mode"] || "bar"
    const barCount = this.props.args["barCount"] || 20
    const minHeight = this.props.args["minHeight"] || 15
    const maxHeight = this.props.args["maxHeight"] || 90
    const centerAlign = this.props.args["centerAlign"] || false
    const streamUrl = this.props.args["streamUrl"]
    const barColor = this.props.args["barColor"] || "#3b82f6"
    const backgroundColor = this.props.args["backgroundColor"] || "#f1f5f9"
    const orbColors = this.props.args["orbColors"] || ["#CADCFC", "#A0B9D1"]
    const orbSeed = this.props.args["orbSeed"] || 1000

    // æª¢æŸ¥å¿…å¡«åƒæ•¸
    if (!streamUrl) {
      return (
        <div className="streamlit-bar-visualizer" style={{ padding: "20px", color: "red" }}>
          âŒ Error: stream_url is required
        </div>
      )
    }

    // state å›ºå®šç‚º autoï¼šæ ¹æ“šéŸ³é »ç‹€æ…‹è‡ªå‹•åˆ‡æ›é¡¯ç¤º
    // Bar æ¨¡å¼: loading â†’ thinking, playing â†’ speaking, ended â†’ initializing
    // Orb æ¨¡å¼: loading â†’ listening, playing â†’ talking, ended â†’ idle (null)
    let barDisplayState: BarAgentState
    let orbDisplayState: OrbAgentState
    
    switch (this.state.audioState) {
      case "loading":
        // é‚„æ²’ç²å–åˆ°é¦–åŒ…éŸ³æª”
        barDisplayState = "thinking"
        orbDisplayState = "listening"
        break
      case "playing":
        // æ’­æ”¾ä½¿ç”¨ä¸­
        barDisplayState = "speaking"
        orbDisplayState = "talking"
        break
      case "ended":
        // æ’­æ”¾å®Œç•¢
        barDisplayState = "initializing"
        orbDisplayState = null  // idle state
        break
      case "idle":
      default:
        barDisplayState = "listening"
        orbDisplayState = "thinking"  // ElevenLabs orb uses "thinking" for idle
        break
    }
    console.log("ğŸ¤– Auto mode: audioState =", this.state.audioState, "â†’ displayState =", mode === "orb" ? orbDisplayState : barDisplayState)

    return (
      <div className="streamlit-bar-visualizer">
        <audio
          ref={this.audioRef}
          controls={false}
          autoPlay={false}
          crossOrigin="anonymous"
          style={{ display: "none" }}
        />
        {mode === "orb" ? (
          <div
            className="relative h-32 w-32 mx-auto rounded-full p-1 shadow-[inset_0_2px_8px_rgba(0,0,0,0.1)]"
            style={{ backgroundColor }}
          >
            <div className="h-full w-full overflow-hidden rounded-full shadow-[inset_0_0_12px_rgba(0,0,0,0.05)]">
              <OrbVisualizer
                colors={orbColors as [string, string]}
                seed={orbSeed}
                agentState={orbDisplayState}
                volumeMode="manual"
                manualOutput={this.state.audioVolume}
              />
            </div>
          </div>
        ) : (
          <BarVisualizer
            mediaStream={this.state.mediaStream}
            state={barDisplayState}
            barCount={barCount}
            minHeight={minHeight}
            maxHeight={maxHeight}
            centerAlign={centerAlign}
            barColor={barColor}
            backgroundColor={backgroundColor}
          />
        )}
      </div>
    )
  }

  public componentDidMount = async (): Promise<void> => {
    const streamUrl = this.props.args["streamUrl"]
    
    if (!streamUrl || !this.audioRef.current) {
      Streamlit.setFrameHeight()
      return
    }

    console.log("ğŸµ Attempting to load audio stream:", streamUrl)
    const audioEl = this.audioRef.current
    
    // Force reload by setting src explicitly and calling load()
    // This ensures audio loads even on page refresh with same URL
    audioEl.src = streamUrl
    audioEl.load()
    
    // è¨­ç½®éŸ³é »ç‹€æ…‹ç‚º loading
    this.setState({ audioState: "loading" })
    
    // æ·»åŠ éŸ³é »äº‹ä»¶ç›£è½å™¨
    audioEl.addEventListener("loadstart", this.handleLoadStart)
    audioEl.addEventListener("playing", this.handlePlaying)
    audioEl.addEventListener("ended", this.handleEnded)
    
    try {
      // Wait for audio to be ready
      await new Promise((resolve, reject) => {
        const timeout = setTimeout(() => reject(new Error("Audio load timeout")), 10000)
        
        audioEl.oncanplay = () => {
          clearTimeout(timeout)
          resolve(true)
        }
        
        audioEl.onerror = (e: any) => {
          clearTimeout(timeout)
          console.error("âŒ Audio element error event:", e)
          console.error("   Error code:", audioEl.error?.code)
          console.error("   Error message:", audioEl.error?.message)
          console.error("   Network state:", audioEl.networkState)
          console.error("   Ready state:", audioEl.readyState)
          reject(new Error(`Audio load error: ${audioEl.error?.message || 'Unknown error'}`))
        }
      })

      // Try to play the audio (muted first to bypass autoplay restrictions)
      audioEl.muted = true
      await audioEl.play()
      console.log("âœ… Audio stream is playing (initially muted)")

      // Small delay to ensure audio context is ready
      await new Promise(resolve => setTimeout(resolve, 100))

      // Capture the stream and setup audio analysis
      const audioElAny = audioEl as any
      if (typeof audioElAny.captureStream === "function") {
        const mediaStream = audioElAny.captureStream()
        this.setState({ mediaStream })
        console.log("âœ… Audio stream captured successfully via captureStream()")
        
        // Setup audio analysis for orb visualization
        this.setupAudioAnalysis(mediaStream)
        
        // Unmute after successful capture so user can hear the audio
        audioEl.muted = false
        console.log("ğŸ”Š Audio unmuted - you should now hear the sound")
      } else if (typeof audioElAny.mozCaptureStream === "function") {
        // Firefox compatibility
        const mediaStream = audioElAny.mozCaptureStream()
        this.setState({ mediaStream })
        console.log("âœ… Audio stream captured successfully via mozCaptureStream() (Firefox)")
        
        // Setup audio analysis for orb visualization
        this.setupAudioAnalysis(mediaStream)
        
        // Unmute after successful capture
        audioEl.muted = false
        console.log("ğŸ”Š Audio unmuted - you should now hear the sound")
      } else {
        console.error("âŒ HTMLAudioElement.captureStream() is not supported in this browser.")
        // Still unmute so user can hear the audio even without visualization
        audioEl.muted = false
        console.warn("âš ï¸ Audio unmuted but visualization will not work")
      }
    } catch (error) {
      console.error("âŒ Error playing or capturing audio stream:", error)
      console.warn("âš ï¸ Audio stream failed. Check console for errors.")
    }
    
    Streamlit.setFrameHeight()
  }

  public componentWillUnmount = (): void => {
    // Clean up audio analysis
    this.cleanupAudioAnalysis()
    
    // Stop microphone tracks
    if (this.state.mediaStream && !this.props.args["streamUrl"]) {
      this.state.mediaStream.getTracks().forEach((track) => track.stop())
    }
    // Stop audio element and remove event listeners
    if (this.audioRef.current) {
      const audioEl = this.audioRef.current
      audioEl.pause()
      audioEl.removeEventListener("loadstart", this.handleLoadStart)
      audioEl.removeEventListener("playing", this.handlePlaying)
      audioEl.removeEventListener("ended", this.handleEnded)
    }
  }

  // @ts-expect-error - StreamlitComponentBase typing issue with componentDidUpdate params
  public componentDidUpdate(
    prevProps: Readonly<BarVisualizerComponent["props"]>
  ): void {
    const oldStreamUrl = prevProps.args["streamUrl"]
    const newStreamUrl = this.props.args["streamUrl"]

    // ç•¶æœ‰ streamUrl æ™‚ï¼Œæª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åŠ è¼‰éŸ³é »
    // åªåœ¨ URL æ”¹è®Šæ™‚é‡æ–°åŠ è¼‰ï¼Œé¿å…éŸ³é »çµæŸå¾Œè‡ªå‹•å¾ªç’°æ’­æ”¾
    const urlChanged = oldStreamUrl !== newStreamUrl
    const shouldReload = newStreamUrl && this.audioRef.current && urlChanged

    if (shouldReload) {
      console.log("ğŸ”„ Reloading audio:", urlChanged ? "URL changed" : "Replay same URL")
      
      // å…ˆæ¸…é™¤ mediaStream ä¸¦è¨­ç½®ç‚º loading ç‹€æ…‹
      this.setState({ mediaStream: null, audioState: "loading" })
      
      const audioEl = this.audioRef.current
      if (!audioEl) return
      
      // ç§»é™¤èˆŠçš„äº‹ä»¶ç›£è½å™¨ï¼ˆå¦‚æœæœ‰ï¼‰
      audioEl.removeEventListener("loadstart", this.handleLoadStart)
      audioEl.removeEventListener("playing", this.handlePlaying)
      audioEl.removeEventListener("ended", this.handleEnded)
      
      // æ·»åŠ æ–°çš„äº‹ä»¶ç›£è½å™¨
      audioEl.addEventListener("loadstart", this.handleLoadStart)
      audioEl.addEventListener("playing", this.handlePlaying)
      audioEl.addEventListener("ended", this.handleEnded)
      
      // å¦‚æœ URL æ”¹è®Šäº†ï¼Œæ›´æ–° srcï¼›å¦å‰‡åªéœ€è¦é‡æ–° load
      if (urlChanged) {
        audioEl.src = newStreamUrl
      } else {
        audioEl.load() // é‡æ–°åŠ è¼‰ç›¸åŒçš„ URL
      }
      
      // Use async IIFE to handle async operations
      ;(async () => {
        try {
          audioEl.muted = true
          await audioEl.play()
          
          const audioElAny = audioEl as any
          if (typeof audioElAny.captureStream === "function") {
            const mediaStream = audioElAny.captureStream()
            this.setState({ mediaStream })
            console.log("âœ… Audio stream updated and captured successfully")
            
            // Setup audio analysis for orb visualization
            this.setupAudioAnalysis(mediaStream)
            
            // Unmute so user can hear the audio
            audioEl.muted = false
            console.log("ğŸ”Š Audio unmuted")
          } else if (typeof audioElAny.mozCaptureStream === "function") {
            const mediaStream = audioElAny.mozCaptureStream()
            this.setState({ mediaStream })
            console.log("âœ… Audio stream updated and captured successfully (Firefox)")
            
            // Setup audio analysis for orb visualization
            this.setupAudioAnalysis(mediaStream)
            
            // Unmute so user can hear the audio
            audioEl.muted = false
            console.log("ğŸ”Š Audio unmuted")
          } else {
            // Still unmute even if capture is not supported
            audioEl.muted = false
            console.warn("âš ï¸ captureStream not supported, audio unmuted but using demo visualization")
          }
        } catch (error) {
          console.error("âŒ Error updating audio stream:", error)
        }
      })()
    }

    Streamlit.setFrameHeight()
  }

  // äº‹ä»¶è™•ç†å™¨æ–¹æ³•ï¼ˆä½¿ç”¨ç®­é ­å‡½æ•¸ä¿æŒ this ç¶å®šï¼‰
  private handleLoadStart = () => {
    console.log("ğŸ“¥ Audio loadstart")
    this.setState({ audioState: "loading" })
  }

  private handlePlaying = () => {
    console.log("â–¶ï¸ Audio playing")
    this.setState({ audioState: "playing" })
  }

  private handleEnded = () => {
    console.log("â¹ï¸ Audio ended")
    // æ¸…é™¤ mediaStreamï¼Œè®“å¯è¦–åŒ–åœæ­¢
    this.setState({ audioState: "ended", mediaStream: null, audioVolume: 0 })
    // Clean up audio analysis
    this.cleanupAudioAnalysis()
  }

  // Setup audio analysis for volume tracking
  private setupAudioAnalysis = (mediaStream: MediaStream): void => {
    // Clean up any existing analysis first
    this.cleanupAudioAnalysis()

    try {
      const audioContext = new AudioContext()
      const analyzer = audioContext.createAnalyser()
      analyzer.fftSize = 256
      analyzer.smoothingTimeConstant = 0.8
      
      const source = audioContext.createMediaStreamSource(mediaStream)
      source.connect(analyzer)
      
      this.audioContextRef = audioContext
      this.analyzerRef = analyzer

      const dataArray = new Uint8Array(analyzer.frequencyBinCount)

      const updateVolume = () => {
        if (!this.analyzerRef) return
        
        this.analyzerRef.getByteFrequencyData(dataArray)
        const average = dataArray.reduce((a, b) => a + b) / dataArray.length
        const normalizedVolume = Math.min(1, average / 128) // Normalize to 0-1 range
        
        this.setState({ audioVolume: normalizedVolume })
        this.animationFrameId = requestAnimationFrame(updateVolume)
      }

      updateVolume()
      console.log("âœ… Audio analysis setup complete")
    } catch (error) {
      console.error("âŒ Error setting up audio analysis:", error)
    }
  }

  // Clean up audio analysis resources
  private cleanupAudioAnalysis = (): void => {
    if (this.animationFrameId !== null) {
      cancelAnimationFrame(this.animationFrameId)
      this.animationFrameId = null
    }
    
    if (this.audioContextRef) {
      this.audioContextRef.close()
      this.audioContextRef = null
    }
    
    this.analyzerRef = null
  }
}

export default withStreamlitConnection(BarVisualizerComponent)

