#!/usr/bin/env python3
"""
MCP Server for AL Parser - finds pages and fields for Business Central scenarios
"""
from typing import Dict, Any, Optional
from dataclasses import dataclass
from mcp.server.fastmcp import FastMCP
from .alparser import build_cache, needs_rebuild, ALCache
from .extract_al import ALExtractor
import os
import shutil
import subprocess
import json
from pathlib import Path

@dataclass
class PageInfo:
    name: str
    page_id: Optional[int]
    app_name: Optional[str]
    caption: Optional[str]
    source_table: Optional[str]
    file_path: str

# Initialize FastMCP Server
mcp = FastMCP("AL Parser Server")

# Configuration paths - supports shared folder via environment variable
PACKAGE_DIR = os.path.dirname(os.path.abspath(__file__))

AZURE_DEVOPS_REPO_URL = "https://schouw.visualstudio.com/Foodware%20365%20BC/_git/PageScripting"
AZURE_DEVOPS_BRANCH = "feature/MCPALFiles"
# Removed PAT support - using Azure CLI authentication only

# Local paths in package directory
AL_FILES_PATH = r"C:\al_files"
YAML_TEMPLATES_PATH = os.path.join(PACKAGE_DIR, "..", "..")

def check_git_available() -> bool:
    """Check if Git is available on the system"""
    try:
        result = subprocess.run(['git', '--version'], capture_output=True, text=True, timeout=10, shell=True)
        return result.returncode == 0
    except Exception:
        return False

def construct_git_url_with_auth(repo_url: str, pat: str = '') -> str:
    """Construct Git URL with authentication if PAT is provided"""
    if not pat:
        return repo_url
    
    # Handle Azure DevOps URLs
    if 'dev.azure.com' in repo_url:
        return repo_url.replace('https://', f'https://{pat}@')
    elif 'visualstudio.com' in repo_url:
        # Handle legacy Azure DevOps URLs
        return repo_url.replace('https://', f'https://{pat}@')
    else:
        # Generic Git URL with PAT
        return repo_url.replace('https://', f'https://{pat}@')

def check_az_login() -> tuple[bool, str]:
    """Check if user is logged in via Azure CLI and get access token"""
    try:
        # Check if Azure CLI is available
        result = subprocess.run(['az', '--version'], capture_output=True, text=True, timeout=10, shell=True)
        if result.returncode != 0:
            return False, "Azure CLI not installed. Please install: winget install Microsoft.AzureCLI"
        
        # Check if user is logged in
        result = subprocess.run(['az', 'account', 'show'], capture_output=True, text=True, timeout=30, shell=True)
        if result.returncode != 0:
            # Check if we should attempt auto-login (via environment variable)
            auto_login = os.environ.get('MCP_AUTO_LOGIN', '').lower() in ('true', '1', 'yes')
            print(f"üîß MCP_AUTO_LOGIN setting: {os.environ.get('MCP_AUTO_LOGIN', 'Not set')} (auto_login: {auto_login})")
            
            if auto_login:
                print("üîê Azure CLI not authenticated. Attempting automatic login...")
                try:
                    print("‚è≥ Running 'az login'... (this may take up to 2 minutes)")
                    login_result = subprocess.run(['az', 'login'], timeout=120, shell=True)
                    print(f"üîç Login result return code: {login_result.returncode}")
                    
                    if login_result.returncode == 0:
                        print("‚úÖ Azure CLI login successful!")
                        # Verify login worked by checking account again
                        print("üîç Verifying login by checking account...")
                        verify_result = subprocess.run(['az', 'account', 'show'], capture_output=True, text=True, timeout=30, shell=True)
                        if verify_result.returncode != 0:
                            print(f"‚ùå Login verification failed: {verify_result.stderr}")
                            return False, "Login appeared successful but account verification failed"
                        print("‚úÖ Login verification successful!")
                        # Continue to get token below
                    else:
                        return False, "Azure CLI login failed. Please run 'az login' manually."
                except subprocess.TimeoutExpired:
                    print("‚è∞ Azure CLI login timed out after 2 minutes")
                    return False, "Azure CLI login timed out. Please run 'az login' manually."
                except Exception as e:
                    print(f"üí• Exception during automatic login: {str(e)}")
                    return False, f"Error during automatic login: {str(e)}"
            else:
                return False, "Not logged in to Azure CLI. Run 'az login' first or set MCP_AUTO_LOGIN=true"
        
        # Get access token for Azure DevOps
        result = subprocess.run([
            'az', 'account', 'get-access-token', 
            '--resource', '499b84ac-1321-427f-aa17-267ca6975798'  # Azure DevOps resource ID
        ], capture_output=True, text=True, timeout=30, shell=True)
        
        if result.returncode == 0:
            import json
            token_data = json.loads(result.stdout)
            return True, token_data['accessToken']
        else:
            return False, f"Failed to get Azure DevOps token: {result.stderr}"
            
    except Exception as e:
        return False, f"Error checking Azure CLI: {str(e)}"

def get_auth_token() -> str:
    """Get authentication token - Azure CLI only"""
    print("üîë Checking Azure CLI authentication...")
    
    # Try Azure CLI authentication
    az_success, az_token = check_az_login()
    if az_success:
        print("‚úÖ Azure CLI authentication successful")
        return az_token
    else:
        print(f"‚ùå Azure CLI authentication failed: {az_token}")
        auto_login_enabled = os.environ.get('MCP_AUTO_LOGIN', '').lower() in ('true', '1', 'yes')
        if auto_login_enabled:
            print("üîÑ MCP_AUTO_LOGIN is enabled but authentication still failed")
        else:
            print("üí° To enable automatic login, set environment variable: MCP_AUTO_LOGIN=true")
        print("   Or manually run: az login")
        return ""

def clone_azure_devops_repo(repo_url: str, branch: str, destination_path: str) -> bool:
    """Clone Azure DevOps repository to destination path using Azure CLI authentication only"""
    print(f"üîÑ Starting repository clone process...")
    print(f"üìç Repository: {repo_url}")
    print(f"üåø Branch: {branch}")
    print(f"üìÇ Destination: {destination_path}")
    
    try:
        # Check if Git is available
        print("üîç Checking Git availability...")
        if not check_git_available():
            print("‚ùå Git is not available on the system. Please install Git.")
            return False
        print("‚úÖ Git is available")

        # Get authentication token (Azure CLI only)
        auth_token = get_auth_token()
        if not auth_token:
            print("‚ùå Could not obtain Azure CLI authentication token")
            return False
        print("‚úÖ Authentication token obtained")

        # Remove existing directory if it exists
        if os.path.exists(destination_path):
            print(f"Removing existing directory: {destination_path}")
            shutil.rmtree(destination_path)

        # Create parent directory if it doesn't exist
        os.makedirs(os.path.dirname(destination_path), exist_ok=True)

        print(f"Cloning Azure DevOps repository to {destination_path}...")
        print(f"Repository: {repo_url}")
        print(f"Branch: {branch}")

        # Construct authenticated URL
        clone_url = construct_git_url_with_auth(repo_url, auth_token)

        # Clone the repository with Windows long path support
        cmd = [
            'git', 'clone', 
            '--config', 'core.longpaths=true',
            '--config', 'core.autocrlf=false',
            '--branch', branch, 
            '--single-branch', 
            clone_url, 
            destination_path
        ]
        
        # Hide the URL in output for security
        display_cmd = ['git', 'clone', '--branch', branch, '--single-branch', repo_url, destination_path]
        print(f"Running: {' '.join(display_cmd)}")

        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300, shell=True)
        
        if result.returncode == 0:
            print("Repository cloned successfully!")
            
            # Check if we got AL files
            al_files_count = 0
            for root, dirs, files in os.walk(destination_path):
                for file in files:
                    if file.lower().endswith('.al'):
                        al_files_count += 1
            
            print(f"Found {al_files_count} AL files in the repository")
            return al_files_count > 0
        else:
            print(f"Git clone failed with error: {result.stderr}")
            return False

    except subprocess.TimeoutExpired:
        print("Git clone operation timed out (5 minutes)")
        return False
    except Exception as e:
        print(f"Error cloning repository: {str(e)}")
        return False

def pull_latest_changes(repo_path: str, branch: str) -> bool:
    """Pull latest changes from the repository if it already exists"""
    try:
        if not os.path.exists(os.path.join(repo_path, '.git')):
            return False
        
        print(f"Pulling latest changes from branch {branch}...")
        
        # Change to the repository directory and pull
        cmd = ['git', '-C', repo_path, 'pull', 'origin', branch]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60, shell=True)
        
        if result.returncode == 0:
            print("Repository updated successfully!")
            return True
        else:
            print(f"Git pull failed: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"Error pulling changes: {str(e)}")
        return False

def ensure_al_files() -> str:
    """Ensure AL files are available, clone from Azure DevOps if necessary"""
    print("üîç Checking for AL files...")
    
    # Check for environment override
    env_path = os.environ.get('AISCRIPTGEN_AL_PATH')
    print(f"üåç Environment path (AISCRIPTGEN_AL_PATH): {env_path}")
    if env_path and os.path.exists(env_path):
        print(f"‚úÖ Using AL files from environment variable: {env_path}")
        return env_path
    
    # Debug: Show current configuration
    print(f"üîß Azure DevOps Repository URL: {AZURE_DEVOPS_REPO_URL}")
    print(f"üîß Azure DevOps Branch: {AZURE_DEVOPS_BRANCH}")
    print(f"üîß Target AL Files Path: {AL_FILES_PATH}")
    print(f"üîß MCP_AUTO_LOGIN: {os.environ.get('MCP_AUTO_LOGIN', 'Not set')}")
    
    # Try to clone from Azure DevOps if URL is provided - Azure CLI only
    if AZURE_DEVOPS_REPO_URL and AZURE_DEVOPS_REPO_URL.strip():
        print(f"üöÄ Attempting to clone from Azure DevOps using Azure CLI authentication...")
        print(f"üìç Repository: {AZURE_DEVOPS_REPO_URL}")
        print(f"üåø Branch: {AZURE_DEVOPS_BRANCH}")
        
        # Check if repository already exists and try to pull latest changes
        if os.path.exists(AL_FILES_PATH) and os.path.exists(os.path.join(AL_FILES_PATH, '.git')):
            print("Repository already exists, trying to pull latest changes...")
            if pull_latest_changes(AL_FILES_PATH, AZURE_DEVOPS_BRANCH):
                return AL_FILES_PATH
            else:
                print("Pull failed, will try to clone fresh...")
        
        # Clone the repository using Azure CLI authentication only
        if clone_azure_devops_repo(AZURE_DEVOPS_REPO_URL, AZURE_DEVOPS_BRANCH, AL_FILES_PATH):
            return AL_FILES_PATH
        else:
            print("Azure DevOps clone failed with Azure CLI authentication")
            print("Please ensure you are logged in with 'az login' and have proper permissions")
    else:
        print("No Azure DevOps repository URL provided in AZURE_DEVOPS_REPO_URL environment variable")
    
    # Fall back to local directory if it exists
    local_foodfresh = os.path.join(PACKAGE_DIR, "..", "..", "FoodFresh")
    if os.path.exists(local_foodfresh):
        print(f"Using local FoodFresh directory: {local_foodfresh}")
        return local_foodfresh
    
    # Check if there are any AL files already in the target directory
    if os.path.exists(AL_FILES_PATH):
        al_files = []
        for root, dirs, files in os.walk(AL_FILES_PATH):
            al_files.extend([f for f in files if f.lower().endswith('.al')])
        if al_files:
            print(f"Found {len(al_files)} AL files in existing directory: {AL_FILES_PATH}")
            return AL_FILES_PATH
    
    # Create empty directory as last resort
    os.makedirs(AL_FILES_PATH, exist_ok=True)
    return AL_FILES_PATH

# Global cache data
cache_data: Optional[ALCache] = None

def get_al_cache() -> ALCache:
    """Get AL cache instance, initializing only if needed"""
    global cache_data
    if cache_data is None:
        # Use the same cache path as extract_al.py - in the project root
        cache_file = os.path.join(PACKAGE_DIR, "..", "..", "al_cache.json")
        cache_data = ALCache(cache_file)
    return cache_data

@mcp.tool()
def find_page_info_with_fields(page_name: str) -> Dict[str, Any]:
    """Find information about AL pages with fields, actions, repeaters."""
    cache = get_al_cache()  # Your ALCache instance

    # Search strategies
    search_strategies = [
        ("exact", lambda name: ALExtractor.get_page_info(name)),
        ("fuzzy_match", lambda name: ALExtractor.get_page_info_fuzzy(name)),
    ]

    search_method_used = None
    page_info = None

    for strategy_name, strategy_func in search_strategies:
        try:
            page_info = strategy_func(page_name)
            if page_info:
                search_method_used = strategy_name
                break
        except Exception:
            continue

    if not page_info:
        all_suggestions = ALExtractor.get_comprehensive_page_suggestions(page_name)
        return {
            "error": f"Page '{page_name}' not found",
            "search_suggestions": all_suggestions,
            "search_methods_tried": [s[0] for s in search_strategies]
        }

    # Extract base page content
    try:
        with open(page_info.file_path, 'r', encoding='utf-8') as f:
            al_file_content = f.read()
    except Exception as e:
        return {"error": f"Could not read file {page_info.file_path}: {str(e)}"}
    
    # Find related extensions
    related_extensions = []
    for ext in cache.pageext:
        if ext.get("extends") and ext["extends"].lower() == page_info.name.lower():
            try:
                with open(ext["location"], 'r', encoding='utf-8') as f:
                    ext_content = f.read()
                related_extensions.append({
                    "name": ext.get("name"),
                    "id": ext.get("id"),
                    "app_name": ext.get("app_name"),
                    "location": ext.get("location"),
                    "content": ext_content
                })
            except Exception:
                continue
                    
    return {
        "base_page": {
            "name": page_info.name,
            "app_name": page_info.app_name,
            "id": page_info.page_id,
            "caption": page_info.caption,
            "source_table": page_info.source_table,
            "location": page_info.file_path,
            "content": al_file_content
        },
        "extensions": related_extensions
    }



@mcp.tool()
def find_table_info_with_fields(table_name: str) -> Dict[str, Any]:
    """Find information about AL tables with fields, including extensions."""
    cache = get_al_cache()  # Your ALCache instance

    # Search strategies
    search_strategies = [
        ("exact", lambda name: ALExtractor.get_table_info(name)),
        ("fuzzy_match", lambda name: ALExtractor.get_table_info_fuzzy(name)),
    ]

    table_info = None

    for strategy_name, strategy_func in search_strategies:
        try:
            table_info = strategy_func(table_name)
            if table_info:
                search_method_used = strategy_name
                break
        except Exception:
            continue

    if not table_info:
        all_suggestions = ALExtractor.get_comprehensive_table_suggestions(table_name)
        return {
            "error": f"Table '{table_name}' not found",
            "search_suggestions": all_suggestions,
            "search_methods_tried": [s[0] for s in search_strategies]
        }

    # Extract base table content
    try:
        with open(table_info.file_path, 'r', encoding='utf-8') as f:
            al_file_content = f.read()
    except Exception as e:
        return {"error": f"Could not read file {table_info.file_path}: {str(e)}"}
    
    # Find related extensions
    related_extensions = []
    for ext in cache.tableext:
        if ext.get("extends") and ext["extends"].lower() == table_info.name.lower():
            try:
                with open(ext["location"], 'r', encoding='utf-8') as f:
                    ext_content = f.read()
                related_extensions.append({
                    "name": ext.get("name"),
                    "id": ext.get("id"),
                    "app_name": ext.get("app_name"),
                    "location": ext.get("location"),
                    "content": ext_content
                })
            except Exception:
                continue
                
    return {
        "base_table": {
            "name": table_info.name,
            "app_name": table_info.app_name,
            "id": table_info.table_id if hasattr(table_info, 'table_id') else None,
            "location": table_info.file_path,
            "content": al_file_content
        },
        "extensions": related_extensions
    }

@mcp.tool()
def find_enum_info(enum_name: str) -> Dict[str, Any]:
    """Find information about AL enums with fields, including extensions."""
    cache = get_al_cache()  # Your ALCache instance

    # Search strategies
    search_strategies = [
        ("exact", lambda name: ALExtractor.get_enum_info(name)),
        ("fuzzy_match", lambda name: ALExtractor.get_enum_info_fuzzy(name)),
    ]

    enum_info = None

    for strategy_name, strategy_func in search_strategies:
        try:
            enum_info = strategy_func(enum_name)
            if enum_info:
                search_method_used = strategy_name
                break
        except Exception:
            continue

    if not enum_info:
        all_suggestions = ALExtractor.get_comprehensive_enum_suggestions(enum_name)
        return {
            "error": f"Enum '{enum_name}' not found",
            "search_suggestions": all_suggestions,
            "search_methods_tried": [s[0] for s in search_strategies]
        }

    # Extract base enum content
    try:
        with open(enum_info.file_path, 'r', encoding='utf-8') as f:
            al_file_content = f.read()
    except Exception as e:
        return {"error": f"Could not read file {enum_info.file_path}: {str(e)}"}

    # Find related extensions
    related_extensions = []
    for ext in cache.enumext:
        if ext.get("extends") and ext["extends"].lower() == enum_info.name.lower():
            try:
                with open(ext["location"], 'r', encoding='utf-8') as f:
                    ext_content = f.read()
                related_extensions.append({
                    "name": ext.get("name"),
                    "id": ext.get("id"),
                    "app_name": ext.get("app_name"),
                    "location": ext.get("location"),
                    "content": ext_content
                })
            except Exception:
                continue
                
    return {
        "base_enum": {
            "name": enum_info.name,
            "app_name": enum_info.app_name,
            "id": enum_info.enum_id if hasattr(enum_info, 'enum_id') else None,
            "location": enum_info.file_path,
            "content": al_file_content
        },
        "extensions": related_extensions
    }


@mcp.tool()
def find_codeunit_info(codeunit_name: str) -> Dict[str, Any]:
    """Find information about AL codeunits with fields, including extensions."""
    cache = get_al_cache()  # Your ALCache instance

    # Search strategies
    search_strategies = [
        ("exact", lambda name: ALExtractor.get_codeunit_info(name)),
        ("fuzzy_match", lambda name: ALExtractor.get_codeunit_info_fuzzy(name)),
    ]

    codeunit_info = None

    for strategy_name, strategy_func in search_strategies:
        try:
            codeunit_info = strategy_func(codeunit_name)
            if codeunit_info:
                search_method_used = strategy_name
                break
        except Exception:
            continue

    if not codeunit_info:
        all_suggestions = ALExtractor.get_comprehensive_codeunit_suggestions(codeunit_name)
        return {
            "error": f"Codeunit '{codeunit_name}' not found",
            "search_suggestions": all_suggestions,
            "search_methods_tried": [s[0] for s in search_strategies]
        }

    # Extract base codeunit content
    try:
        with open(codeunit_info.file_path, 'r', encoding='utf-8') as f:
            al_file_content = f.read()
    except Exception as e:
        return {"error": f"Could not read file {codeunit_info.file_path}: {str(e)}"}

    return {
        "base_codeunit": {
            "name": codeunit_info.name,
            "app_name": codeunit_info.app_name,
            "id": codeunit_info.codeunit_id if hasattr(codeunit_info, 'codeunit_id') else None,
            "location": codeunit_info.file_path,
            "content": al_file_content
        }
    }

@mcp.tool()
def read_yaml_template() -> Dict[str, Any]:
    """
    Reads a YAML template file and returns the structure as a reference.
    Fixes 'tag:yaml.org,2002:value' by treating it as a plain string.
    """
    # Try to find template file in multiple locations
    template_locations = [
        os.path.join(YAML_TEMPLATES_PATH, "Template.yml"),  # Project root
        os.path.join(PACKAGE_DIR, "Template.yml"),          # In package directory
        os.path.join(PACKAGE_DIR, "..", "..", "Template.yml") # Project root (alternative)
    ]
    
    template_structure = None
    template_source = None
    
    for template_path in template_locations:
        try:
            if os.path.exists(template_path):
                with open(template_path, "r", encoding="utf-8") as f:
                    template_structure = f.read()
                template_source = template_path
                print(f"‚úÖ Found template file: {template_path}")
                break
            else:
                print(f"‚ùå Template not found at: {template_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è Error reading template at {template_path}: {str(e)}")
            continue
    
    if not template_structure:
        # Return a basic template structure if no file found
        template_structure = """# Basic YAML Template Structure
testSuite: 
  - testFunction:
      name: "Test Function Name"
      steps:
        - actionType: "Open"
          objectType: "Page"
          objectId: "PageName"
        - actionType: "Set"
          control: "FieldName"
          value: "FieldValue"
        - actionType: "Invoke"
          control: "ActionName"
"""
        template_source = "built-in default"
    
    return {
        "yaml_template_structure": template_structure,
        "structure_info": {
            "description": "Business Central YAML test template structure",
            "usage": "Use this structure as a reference when generating new YAML test files",
            "template_found": template_source is not None,
            "search_locations": template_locations
        },
        "file_source": template_source if template_source else "built-in default"
    }

@mcp.prompt("generate_yaml_scenario")
def generate_yaml_scenario(scenario: str, app_name: str) -> str:
    """Yaml Scenario Generator with Complete Field Analysis Instructions"""
    return f"""
    SCENARIO:
    {scenario}
    
    # üõ†Ô∏è **MPC-Powered YML Generator (Read-Only Base + Extension Mode)**

    ## üéØ ROLE
    You are an **MCP-driven AL Object Analyzer and YML Generator** for **Microsoft Dynamics 365 Business Central**.  

    Your responsibilities:  
    1. Systematically analyze AL objects using **MCP tools only** ‚Äî never assume.  
    2. For each **base object** (Page, Table, Enum, etc.), also **read the corresponding APP-level extension(s)** from the specified **APP NAME**.  
    3. Trace relationships:
    - Pages ‚Üí Actions ‚Üí Codeunits  
    - Pages ‚Üí Source Tables ‚Üí Fields ‚Üí Enums  
    4. Use analyzed data to create accurate, validated **YAML test files**.  
    5. Validate all references before YAML generation.  

    üö´ **Never assume, merge, or skip any step.**  
    üß© **Use only these MCP tools:**  
    `find_page_info_with_fields()`, `find_table_info_with_fields()`, `find_enum_info()`, `find_codeunit_info()`, `read_yaml_template()`

    ---

    ## ‚öôÔ∏è EXECUTION FLOW

    ### üîç **PHASE 1 ‚Äî Identify Pages**
    - Parse the given scenario to determine all relevant **Pages**.  
    - **Output:** List of all required **base Pages** and **subpages** (including parts, factboxes, and subforms).  

    ---

    ### üìÑ **PHASE 2 ‚Äî Read Pages**
    For each identified Page:
    1. Use `find_page_info_with_fields()` to read the **base Page**.  
    2. From the response, check for an `extensions` array.  
    3. For every Page extension related to the **target APP NAME**:
    - Read the **Page Extension** separately using the same MCP tool.  
    - Note any additional fields, actions, or control modifications for later reference.  
    4. **Do not merge** extension data into the base Page ‚Äî just record it as a separate reference.

    ---

    ### ‚öôÔ∏è **PHASE 2.1 ‚Äî App Page Extension Analysis**
    - For each Page analyzed:
    - Read all matching **Page Extensions** from the **APP NAME**.  
    - Document extension-specific:
        - Fields  
        - Actions  
        - Groups / Repeaters  

    **List the identified field names from page and it's extensions.**
    ---

    ### ‚ö° **PHASE 3 ‚Äî Action and Codeunit Analysis**
    - For each **Action** from both:
    - Base Page  
    - APP-level Page Extension  
    - Inspect its **OnAction() trigger**.  
    - If it calls a **procedure or codeunit**, read that object using `find_codeunit_info()`.  
    - Trace procedure logic and note any dependencies or validations.  

    ---

    ### üóÇÔ∏è **PHASE 4 ‚Äî Read Source Tables**
    For each Page (and Subpage):
    1. Identify the **SourceTable**.  
    2. Use `find_table_info_with_fields()` to read the **base Table**.  
    3. Check for and read all **Table Extensions** belonging to the **APP NAME**.  
    4. Record both **base Table fields** and **extension fields** separately for comparison.  
    5. Do **not** merge extension data into the base Table; treat as parallel objects.

    ---

    ### üß© **PHASE 4.1 ‚Äî Table Extension Analysis**
    - For each Table analyzed:
    - Read every **Table Extension** from the target **APP NAME**.  
    - Note all custom fields, validations, or triggers.  
    - Keep extension data separate ‚Äî only reference it where the scenario requires it.

    ---

    ### üî¢ **PHASE 5 ‚Äî Enum Analysis**
    - For every Enum field discovered in Tables or Pages:
    1. Use `find_enum_info()` to read the **base Enum**.  
    2. Read all **Enum Extensions** from the target APP NAME.  
    3. Record the ordinal index and captions for both sets (base and extension).  
    4. Treat base and app Enum definitions as separate data sources ‚Äî do not merge.

    ---

    ### ‚úÖ **PHASE 6 ‚Äî Validation**
    Before generating YAML, verify:
    - ‚úÖ All base Pages, Tables, and Enums were successfully read.  
    - ‚úÖ All corresponding APP-level Extensions (Pages, Tables, Enums) were read.  
    - ‚úÖ All Actions and Codeunits were analyzed.  
    - ‚úÖ Scenario requirements are fully supported.  
    - If any base or app extension object is missing ‚Üí re-fetch via MCP before YAML generation.

    ---

    ### üìè **PHASE 7 ‚Äî YAML Mapping Rules**

    | AL Type | YAML Format | Example |
    |----------|-------------|----------|
    | Text[N], Code[N] | `"quoted string"` | `"ITEM001"` |
    | Integer | `numeric_value` | `10` |
    | Decimal | `numeric_value.decimal` | `99.95` |
    | Boolean | `true` / `false` | `true` |
    | Date | `YYYY-MM-DD` | `2024-01-15` |
    | Enum | `ordinal_index` | `2` |
    | Option | `"option_text"` | `"Released"` |

    **Strict YAML Rules:**
    - Generate YAML **only** for the steps described in the scenario.  
    - Never assume or reuse template values.  
    - Always check record existence before creation (e.g., Item, Vendor, Customer).  
    - Use **exact action names** from AL definition.  
    - Add `wait` after every `invoke`.  
    - Use `equals` for integer validations.  
    - Represent repeater data as:
    ```yaml
    - repeater(<repeater_name>)
    ```
    - Validate non-editable fields (no data entry).  
    - Exclude `automationId` for confirmation dialogs.  
    - Ensure **fields and actions from app extensions** are used where relevant.
    - use field name from page not from table (field(field_name;Rec.Reference_name))

    ---

    ### üß† **PHASE 8 ‚Äî YAML Generation**
    1. Load the YAML base template via `read_yaml_template()`.  
    2. Map analyzed base and extension objects separately into scenario-relevant steps.  
    3. Include actions, validations, and field updates based on scenario flow.  
    4. Insert `wait` after every `invoke`.  
    5. Validate YAML against all rules and ensure structural correctness.

    ---

    ### üß© **QUALITY CONTROL RULES**
    - Always read **both base and APP-level extension objects**, even if extension fields aren‚Äôt used.  
    - Keep base and extension data **separate** ‚Äî never merged.  
    - Validate every object‚Äôs presence and correctness before YAML generation.  
    - Maintain strict YAML formatting and step order.  
    - Never output partial or assumed data.

    ---

    ‚úÖ **FINAL OUTPUT:**  
    A verified, scenario-specific **YAML test file**, based on:  
    - Base Pages, Tables, Enums, and Codeunits  
    - Corresponding App-level Extensions (read independently)  
    - Accurate field, action, and enum mappings  
    - Fully validated MCP-based analysis  

    """

@mcp.prompt("generate_test_scenario")
def generate_test_scenario(workitem: int) -> str:
    # Implementation for generating test scenario
    return f"""Work Item ID: {workitem} """ + """
    
    # DevOps Work Item Test Scenario Generator (Business Central Functional Testing)

        ## Project Overview  
        **PROJECT**: Microsoft Dynamics 365 Business Central Functional Requirements Testing  
        **PURPOSE**: Generate comprehensive **Test Scenarios** from DevOps work items following BaseScripts.csv format  
        **OUTPUT**: Functional QA-ready scenarios aligned with Business Central workflows  

        ---

        ## Step 1: DevOps Work Item Analysis  

        Before generating test scenarios, analyze the DevOps work item thoroughly:  

        - Fetch the work item using:  
        mcp_ado_wit_get_work_item(id=[{workitem}], project="[PROJECT_NAME]", expand="all")  

        - Extract comprehensive details:  
        ‚Ä¢ Title (System.Title)  
        ‚Ä¢ Description (System.Description)  
        ‚Ä¢ Acceptance Criteria (Microsoft.VSTS.Common.AcceptanceCriteria)  
        ‚Ä¢ Attachments & linked documents  
        ‚Ä¢ Linked Work Items (dependencies/bugs/enhancements)  

        ### REQUIRED OUTPUT:  
        Produce a **comprehensive business analysis** of:  
        1. **Business Objective** ‚Üí Functional requirement and business purpose  
        2. **Business Central Context** ‚Üí Which BC modules/areas are impacted (Purchase, Sales, Warehouse, Finance, Manufacturing)  
        3. **Functional Requirements** ‚Üí Key business flows and processes that need validation  
        4. **Dependencies & Prerequisites** ‚Üí Any linked requirements, bugs, or setup dependencies  

        Keep this **functional QA focused** and aligned with Business Central terminology.  

        ---

        ## Step 2: Test Scenario Generation (Structured Format Alignment)

        ### Test Scenario Standards  
        - **All scenarios must align with Business Central functional flows**  
        - **Follow the strict 3-column format: Title, Action, Expected Result**  
        - **Generate multiple scenarios per work item** (positive, negative, edge cases)  
        - **Ensure functional QA readiness** with clear preconditions and measurable outcomes  

        ---

        ## üìë Test Scenario Schema (Strict Adherence Required)
        The output must follow the exact 3-column format with these columns:

        ### Core Structure (3-Column Format):
        1. **Title**  
        - Business Central process-focused scenario title  
        - **CRITICAL**: Only populate title for the **first row** of each scenario  
        - **Leave title BLANK** for all subsequent action steps within the same scenario  
        - Examples: "Vendor creation", "Customer creation", "Item creation 1"  

        2. **Action**  
        - **Individual step-by-step actions** - ONE action per row  
        - Each action numbered sequentially (1., 2., 3., etc.)  
        - Precise Business Central UI/Process terminology  
        - Individual navigation steps, field entries, button clicks  
        - Each action step gets its own row with corresponding expected result  

        3. **Expected Result**  
        - **Specific expected outcome for each individual action step**  
        - Must include immediate system response for that step:  
            - Page opens (*System displays the Vendors page*)  
            - Dialog appearances (*Select a template for a new vendor dialog is shown*)  
            - Field acceptance (*System accepts and saves Name = Base Vendor*)  
            - Navigation confirmations (*New - Vendor Card page opens with template defaults*)  

        ### Extended Format (8-Column Format) for Comprehensive Testing:
        When generating comprehensive test scenarios, include additional columns:

        4. **Test Case ID**  
        - Unique identifier: TC[XX]_[MODULE]_[FUNCTION]  
        - Examples: TC01_PURCHASE_VENDOR_SETUP, TC02_SALES_ORDER_CREATION  

        5. **Pre-Conditions**  
        - Clearly defined setup requirements  
        - Master data prerequisites  
        - System configuration requirements  
        - User permissions and access requirements  

        6. **Priority**  
        - High: Critical business processes, core functionality  
        - Medium: Important workflows, moderate business impact  
        - Low: Edge cases, nice-to-have features  

        7. **Module/Area**  
        - Business Central functional areas: Purchase, Sales, Warehouse, Finance, Manufacturing, Planning  
        - Align with BC module structure  

        8. **Business Central Version / Feature Reference**  
        - BC version compatibility  
        - Specific feature or enhancement reference  
        - Related work item or requirement ID  

        ---

        ### Business Central Test Data Standards  
        **Use existing master data if available in workspace, otherwise use these standards:**

        - **Vendors**: Base Vendor, Primary Supplier, Secondary Supplier  
        - **Customers**: Base Customer, Primary Customer, Secondary Customer  
        - **Items**: 
        - Raw Material (with Item Tracking Code = "lotall", Lot Nos. = "LOT")  
        - BaseProductionItem (with Item Tracking Code = "lotall", Lot Nos. = "lot")  
        - Base Item 1, Base Item 2  
        - **Locations**: 
        - Aptean DIR (Direct location with Warehouse Employees and Inventory Posting Setup)  
        - TRANSIT (Aptean Transit, Use As In-Transit = true, with Warehouse Employees and Inventory Posting Setup)  
        - Apt WSWR (Warehouse location with Receive/Shipment/Bins, Warehouse Employees, Inventory Posting Setup)  
        - APT INV (Inventory location with Put-away/Pick/Bins, Warehouse Employees, Inventory Posting Setup)  
        - Apt WINV (Full warehouse with all features, Warehouse Employees, Inventory Posting Setup)  
        - **Bins**: REC, SHIP, DRY, COOL (must be created as part of location setup)  
        - **Inventory Posting Group**: RESALE (must be configured for all locations and items)  
        - **Item Tracking Codes**: lotall, LOT, lot  
        - **Warehouse Employees**: Current user must be added as warehouse employee for all locations  
        - **Dates**: Use current system date and logical business dates  

        ### **CRITICAL: Complete Base Functionality Patterns**

        **Location Creation Complete Pattern (ALL steps must be included):**
        1. Navigate to Locations page  
        2. Click "New" to create location  
        3. Enter Code and Name  
        4. Configure location-specific settings (bins, receive/shipment flags, etc.)  
        5. **Open "Warehouse Employees" from Location Card**  
        6. **Add current user as warehouse employee**  
        7. **Close Warehouse Employees page**  
        8. **Open "Inventory Posting Setup" from Location Card**  
        9. **Add Invt. Posting Group Code = RESALE**  
        10. **If Inventory Account is empty, use "Suggest Accounts" to populate it**  
        11. **Save and close Inventory Posting Setup page**  
        12. Save and close Location Card  
        13. Close Locations page  

        **Item Creation Complete Pattern (ALL steps must be included):**
        1. Navigate to Items page  
        2. Click "New" to create item  
        3. Select Item Template (when dialog appears)  
        4. Enter Description and item details  
        5. **Set Base Unit of Measure (e.g., KG)**  
        6. **Set Inventory Posting Group = RESALE**  
        7. Set Item Tracking Code (when applicable)  
        8. Set Lot Numbers series (when applicable)  
        9. Save and close Item Card  
        10. Verify item appears in items list  
        11. Close Items page  

        **Vendor/Customer Creation Complete Pattern (ALL steps must be included):**
        1. Navigate to respective page  
        2. Click "New"  
        3. **Select template when dialog appears**  
        4. **Confirm template selection**  
        5. Enter all required details (No., Name, etc.)  
        6. Save and close card  
        7. **Verify record appears in respective list**  
        8. Close page  

        ---

        ## üìù Test Scenario Generation Rules

        1. **Complete End-to-End Scenarios (Not Chunked)**  
        - **CRITICAL**: Generate complete, full scenarios from start to finish  
        - **Avoid scenario chunking** - each scenario must be self-contained and complete  
        - **One complete business process per scenario** (e.g., complete vendor creation including all setup steps)  
        - **Include ALL necessary setup steps** within each scenario (don't split into separate setup scenarios)  

        2. **Mandatory Base Functionality Coverage**  
        **CRITICAL**: Do NOT miss any base functionalities from BaseScripts.csv patterns:  
        
        **For Location Creation scenarios, ALWAYS include:**
        - Warehouse Employees setup (Add current user as warehouse employee)  
        - Inventory Posting Setup (Add Invt. Posting Group Code = RESALE)  
        - Account suggestion ("Use Suggest Accounts to populate if Inventory Account is empty")  
        - Proper bin setup for warehouse locations (REC, SHIP, DRY, COOL)  
        - Location-specific settings (Require Receive, Require Shipment, Bin Mandatory, etc.)  
        
        **For Item Creation scenarios, ALWAYS include:**
        - Base Unit of Measure setup  
        - Inventory Posting Group assignment  
        - Item Tracking Code setup (when applicable)  
        - Lot Numbers series setup (when applicable)  
        
        **For Master Data scenarios, ALWAYS include:**
        - Complete template selection process  
        - All required field configurations  
        - Proper save and validation steps  
        - Verification that records appear in respective lists  

        3. **Functional QA Alignment**  
        - All scenarios must be **functional QA ready**  
        - Clearly defined preconditions and setup  
        - Step-by-step actions in Business Central UI/Process terms  
        - Measurable and verifiable expected outcomes  
        - Avoid ambiguity in steps and results  

        4. **Business Central Context Requirements**  
        All scenarios must align with Business Central functional flows:  
        - **Purchase Order creation and posting**  
        - **Sales Order and shipment processing**  
        - **Warehouse operations** (Put-away, Pick, Movement)  
        - **Item tracking and lot/serial management**  
        - **Production and planning scenarios**  
        - **Financial posting and validation**  

        5. **Structured Format Compliance**  
        - **CRITICAL**: Each individual action step gets its own row  
        - **Title field populated only for first row** of each scenario  
        - **All subsequent rows have blank titles** but continue the action sequence  
        - **Each action has its corresponding immediate expected result**  
        - **One Action Per Row Format** - never compress multiple actions  

        6. **Scenario Coverage Types**  
        For each work item, generate scenarios covering:  
        - **Happy Path**: Successful business flows  
        - **Negative Scenarios**: Validation errors, business rule violations  
        - **Edge Cases**: Boundary conditions, exceptional scenarios  
        - **Integration Tests**: Cross-module business processes  

        7. **Professional QA Documentation Style**  
        - Use precise, functional terms from Business Central  
        - Maintain clarity for manual execution or automation  
        - Structure scenarios for reusability  
        - Ensure end-to-end business coverage  

        8. **Complete Setup Requirements**  
        - **Every scenario must be complete and self-contained**  
        - **Include ALL setup steps within the scenario** (don't separate into different scenarios)  
        - **Follow complete setup patterns** for consistency  
        - **Ensure all prerequisites are covered** within the same scenario execution  

        ---



        ## üìä Test Scenario Output Format (Structured 3-Column Format)

        ### Standard Format (3-Column Structure - COMPLETE SCENARIOS):
        | Title | Action | Expected Result |
        |-------|--------|-----------------|
        | Warehouse location creation | 1. Navigate to "Locations" page. | System displays the Locations page. |
        | | 2. Click "New" to add a location. | New - Location Card page opens. |
        | | 3. Enter Code = Apt WSWR on the Location Card. | System accepts and saves Code = Apt WSWR |
        | | 4. Enter Name = Apt WSWR on the Location Card. | System accepts and saves Name = Apt WSWR. |
        | | 5. Open "Bins" from the Location Card. | |
        | | 6. Add bin with Code = REC. | Bins REC is Created |
        | | 7. Add bin with Code = SHIP. | Bins SHIP is Created |
        | | 8. Add bin with Code = DRY. | Bins DRY is Created |
        | | 9. Add bin with Code = COOL. | Bins COOL is Created |
        | | 10. Close the Bins page. | |
        | | 11. Set "Require Receive" to true on the Location Card. | |
        | | 12. Set "Require Shipment" to true on the Location Card. | |
        | | 13. Set "Bin Mandatory" to true on the Location Card. | Require Receive, "Require Shipment", and "Bin Mandatory" are set to true. |
        | | 14. Set "Receipt Bin Code" to REC. | |
        | | 15. Set "Shipment Bin Code" to SHIP. | Receipt Bin Code is set to REC and "Shipment Bin Code" is set to SHIP. |
        | | 16. Open "Warehouse Employees" from the Location Card. | |
        | | 17. Add the current user as a warehouse employee. | User is added as a warehouse employee for the location. |
        | | 20. Open "Inventory Posting Setup" from the Location Card. | |
        | | 22. Add Invt. Posting Group Code = RESALE in Inventory Posting Setup. | |
        | | 23. If Inventory Account is empty, use "Suggest Accounts" to populate it. | |
        | | 24. Save and close the Inventory Posting Setup page. | |
        | | 25. Close the Location Card. | All pages close without error and the location is available for warehouse transactions. |
        | | 26. Close the Locations page. | |

        **CRITICAL NOTICE**: The above example shows a **COMPLETE** scenario that includes ALL necessary setup steps (Bins, Warehouse Employees, Inventory Posting Setup). This is the pattern that must be followed - **NOT chunked scenarios**.

        ### Extended Format (For Comprehensive Test Documentation):
        | Test Case ID | Test Scenario Title | Pre-Conditions | Test Steps | Expected Results | Priority | Module/Area | BC Version/Feature Reference |
        |--------------|-------------------|-----------------|------------|-----------------|----------|-------------|----------------------------|
        | TC01_SETUP_VENDOR | Setup Master Data - Vendor Creation | 1. User has Purchase module access<br>2. Vendor template configured<br>3. Business Central environment ready | 1. Navigate to "Vendors" page<br>2. Click "New" to add a vendor<br>3. Select Vendor Template<br>4. Enter vendor details<br>5. Save vendor record | 1. Vendors page opens successfully<br>2. New vendor card opens<br>3. Template applied correctly<br>4. Vendor details accepted<br>5. Vendor created and available | High | Purchase | BC 24.0 Master Data |

        ---

        ## üì¶ Final Output Requirements

        ### CSV File Structure Options  
        **Option 1: Standard Format (3-Column)**  
        - Save as: `[WorkItemID]_TestScenarios.csv`  
        - Columns: Title, Action, Expected Result  
        - Format: Exactly match 3-column structure  

        **Option 2: Comprehensive Format (8-Column)**  
        - Save as: `[WorkItemID]_Comprehensive_TestScenarios.csv`  
        - Columns: Test Case ID, Test Scenario Title, Pre-Conditions, Test Steps, Expected Results, Priority, Module/Area, BC Version/Feature Reference  

        - Location: `$env:USERPROFILE\Downloads`  

        ### Quality Standards  
        1. **Each scenario must be completely self-contained and follow complete setup patterns**  
        2. **NO SCENARIO CHUNKING** - scenarios must be complete from start to finish  
        3. **ALL base functionalities must be included** (Warehouse Employees, Inventory Posting Setup, etc.)  
        4. **Title populated only for first row of each scenario**  
        5. **Actions must be numbered and sequential with ALL required steps**  
        6. **Expected results must be specific and immediate for each action**  
        7. **Business Central terminology must be precise and functional**  
        8. **Complete setup within each scenario** (don't split setup across multiple scenarios)  

        ### Scenario Coverage Validation  
        Ensure scenarios cover:  
        - **Complete Setup and Master Data scenarios** (following complete patterns)  
        - **Core business process flows** (primary functionality with all setup included)  
        - **Exception handling** (error validation)  
        - **Integration points** (cross-module workflows)  
        - **End-to-end business validation** (complete user journeys)  

        ### **CRITICAL ANTI-PATTERN WARNINGS:**
        ‚ùå **DO NOT** create chunked scenarios like "Vendor creation - Albaik", "Customer creation - Super Almere" as separate incomplete scenarios  
        ‚ùå **DO NOT** miss Warehouse Employees setup in location scenarios  
        ‚ùå **DO NOT** miss Inventory Posting Setup in location scenarios  
        ‚ùå **DO NOT** miss Base Unit of Measure setup in item scenarios  
        ‚ùå **DO NOT** miss template selection steps in master data scenarios  

        ‚úÖ **DO** create complete scenarios that include ALL setup steps from established patterns  
        ‚úÖ **DO** follow the complete location creation pattern with bins, warehouse employees, and inventory posting setup  
        ‚úÖ **DO** follow the complete item creation pattern with UoM, inventory posting group, and tracking setup  
        ‚úÖ **DO** ensure each scenario is executable from start to finish without dependencies  

        ---

        ## Step 3: CSV File Generation  

        ## üíª PowerShell Script (CSV Generator - Structured Format)
        ```powershell
        # PowerShell: Generate TestScenarios CSV following structured format

        param(
            [string]$WorkItemId = "WI0000",
            [string]$WorkItemTitle = "Sample Work Item",
            [string]$DownloadsPath = "$env:USERPROFILE\Downloads",
            [string]$Format = "Standard" # Options: "Standard" or "Comprehensive"
        )

        if ($Format -eq "Standard") {
            $csvPath = Join-Path $DownloadsPath "$($WorkItemId)_TestScenarios.csv"
            
            # Example scenarios following structured format exactly - COMPLETE SCENARIOS
            $scenarios = @(
                [PSCustomObject]@{
                    "Title" = "Warehouse location creation"
                    "Action" = '1. Navigate to "Locations" page.'
                    "Expected Result" = "System displays the Locations page."
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = '2. Click "New" to add a location.'
                    "Expected Result" = "New - Location Card page opens."
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "3. Enter Code = Apt WSWR on the Location Card."
                    "Expected Result" = "System accepts and saves Code = Apt WSWR"
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "4. Enter Name = Apt WSWR on the Location Card."
                    "Expected Result" = "System accepts and saves Name = Apt WSWR."
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = '5. Open "Bins" from the Location Card.'
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "6. Add bin with Code = REC."
                    "Expected Result" = "Bins REC is Created"
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "7. Add bin with Code = SHIP."
                    "Expected Result" = "Bins SHIP is Created"
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "8. Add bin with Code = DRY."
                    "Expected Result" = "Bins DRY is Created"
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "9. Add bin with Code = COOL."
                    "Expected Result" = "Bins COOL is Created"
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "10. Close the Bins page."
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = '11. Set "Require Receive" to true on the Location Card.'
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = '12. Set "Require Shipment" to true on the Location Card.'
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = '13. Set "Bin Mandatory" to true on the Location Card.'
                    "Expected Result" = 'Require Receive, "Require Shipment", and "Bin Mandatory" are set to true.'
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = '14. Set "Receipt Bin Code" to REC.'
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = '15. Set "Shipment Bin Code" to SHIP.'
                    "Expected Result" = 'Receipt Bin Code is set to REC and "Shipment Bin Code" is set to SHIP.'
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = '16. Open "Warehouse Employees" from the Location Card.'
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "17. Add the current user as a warehouse employee."
                    "Expected Result" = "User is added as a warehouse employee for the location."
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "18. Close the Warehouse Employees page."
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = '19. Open "Inventory Posting Setup" from the Location Card.'
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "20. Add Invt. Posting Group Code = RESALE in Inventory Posting Setup."
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = '21. If Inventory Account is empty, use "Suggest Accounts" to populate it.'
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "22. Save and close the Inventory Posting Setup page."
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "23. Close the Location Card."
                    "Expected Result" = "All pages close without error and the location is available for warehouse transactions."
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = "24. Close the Locations page."
                    "Expected Result" = ""
                },
                [PSCustomObject]@{
                    "Title" = ""
                    "Action" = ""
                    "Expected Result" = ""
                }
            )
        } else {
            $csvPath = Join-Path $DownloadsPath "$($WorkItemId)_Comprehensive_TestScenarios.csv"
            
            # Example scenarios with comprehensive format
            $scenarios = @(
                [PSCustomObject]@{
                    "Test Case ID" = "TC01_SETUP_VENDOR"
                    "Test Scenario Title" = "Setup Master Data - Vendor Creation"
                    "Pre-Conditions" = "1. User has Purchase module access`n2. Vendor template configured`n3. Business Central environment ready"
                    "Test Steps" = '1. Navigate to "Vendors" page`n2. Click "New" to add vendor`n3. Select Vendor Template`n4. Enter vendor details`n5. Save vendor record'
                    "Expected Results" = "1. Vendors page opens successfully`n2. New vendor card opens`n3. Template applied correctly`n4. Vendor details accepted`n5. Vendor created and available"
                    "Priority" = "High"
                    "Module/Area" = "Purchase"
                    "BC Version/Feature Reference" = "BC 24.0 Master Data Management"
                },
                [PSCustomObject]@{
                    "Test Case ID" = "TC02_PO_CREATE"
                    "Test Scenario Title" = "Create Purchase Order with Item Tracking"
                    "Pre-Conditions" = "1. Vendor Base Vendor exists`n2. Item Raw Material with lot tracking`n3. Location configured`n4. User has PO creation permissions"
                    "Test Steps" = '1. Navigate to "Purchase Orders" page`n2. Create new Purchase Order`n3. Select Vendor Base Vendor`n4. Add item line with tracking`n5. Release order'
                    "Expected Results" = "1. Purchase Orders page opens`n2. New PO created`n3. Vendor details populate`n4. Item tracking enabled`n5. Order released successfully"
                    "Priority" = "High"
                    "Module/Area" = "Purchase"
                    "BC Version/Feature Reference" = "BC 24.0 Item Tracking"
                }
            )
        }

        # Export to CSV with proper formatting
        $scenarios | Export-Csv -Path $csvPath -NoTypeInformation -Encoding UTF8

        Write-Host "‚úÖ Test Scenarios CSV created following $Format format: $csvPath"
        Write-Host "üìã Generated $($scenarios.Count) test scenario rows aligned with Business Central flows"

        # Display summary
        Write-Host "`nüìä Test Scenario Summary:"
        if ($Format -eq "Standard") {
            $scenarios | Where-Object { $_."Title" -ne "" } | ForEach-Object { Write-Host "  - $($_.'Title')" }
        } else {
            $scenarios | ForEach-Object { Write-Host "  - $($_.'Test Case ID'): $($_.'Test Scenario Title')" }
        }
        ```

        ## Notes  
        - **Strictly follows structured 3-column format** with exact formatting and **COMPLETE SCENARIOS**  
        - **Two output formats available**: Standard (3-column) or Comprehensive (8-column)  
        - **One action per row format** with title populated only for first row  
        - **COMPLETE SCENARIOS ONLY** - no chunking or incomplete scenarios  
        - **ALL base functionalities included** (Warehouse Employees, Inventory Posting Setup, etc.)  
        - **Business Central terminology** aligned with functional QA requirements  
        - **Complete setup scenarios** following established patterns  
        - **Functional QA ready** with clear actions and expected results  
        - **Professional documentation style** suitable for manual execution or automation  
        - **End-to-end comprehensive coverage** with complete scenarios from start to finish  

        ### **FINAL CRITICAL REMINDER:**
        üö´ **NEVER create chunked scenarios** like incomplete examples  
        ‚úÖ **ALWAYS create complete scenarios** like the established patterns  
        ‚úÖ **ALWAYS include ALL setup steps** (Warehouse Employees, Inventory Posting Setup, Bins, UoM, etc.)  
        ‚úÖ **ALWAYS follow complete end-to-end patterns**  

        The generated scenarios must be **executable from start to finish** without dependencies on other scenarios.  

"""


def main():
    """Main function to run the MCP server."""
    print("üöÄ Starting AI Script Generator MCP Server...")
    
    # Ensure AL files are available (download if necessary)
    print("üìÅ Ensuring AL files are available...")
    al_files_path = ensure_al_files()
    print(f"üìÇ AL files path: {al_files_path}")
    
    # Check if we actually have AL files
    if os.path.exists(al_files_path):
        al_files = list(Path(al_files_path).rglob("*.al"))
        print(f"üìÑ Found {len(al_files)} AL files in directory")
        if len(al_files) == 0:
            print("‚ö†Ô∏è  Warning: No AL files found. Repository may not have cloned properly.")
    else:
        print("‚ùå AL files directory does not exist!")
    
    cache_file = os.path.join(PACKAGE_DIR, "al_cache.json")

    # Build cache if needed
    if needs_rebuild(al_files_path, cache_file):
        print("üîÑ Building/rebuilding cache...")
        build_cache(al_files_path, cache_file)
    else:
        print("‚úÖ Cache is up to date")

    mcp.run()


if __name__ == "__main__":
    main()
