{
    "name": "random_fourier_feature_preprocessing",
    "title": "Random Fourier Feature Expansion Preprocessing for Kernel Approximation in XOR Classification",
    "idea": "Introduce a Random Fourier Feature (RFF) mapping as a single preprocessing step to approximate an RBF kernel on the two-dimensional inputs. By projecting inputs into a higher-dimensional trigonometric feature space, the existing linear\u2013ReLU\u2013linear network can linearly separate the XOR pattern without changing its core architecture. Only the preprocessing and the first linear layer\u2019s input dimension need to be adjusted.",
    "implementation_tips": null,
    "principles": "Based on Bochner\u2019s theorem and kernel approximation: Random Fourier Features provide an explicit finite-dimensional embedding that approximates shift-invariant kernels (e.g. RBF), enabling linear models to capture complex non-linear relationships.",
    "research": [
        "https://arxiv.org/abs/0712.2636"
    ],
    "feasibility": 8,
    "time_complexity": "O(N\u00b7D + N\u00b7D\u00b7H) where N=batch size, D=Fourier feature dimension, H=hidden layer width",
    "novelty": 7,
    "assumptions": "Inputs are continuous numeric values in a bounded domain; the chosen kernel bandwidth \u03c3 is representative of input variability; the increased feature dimension D is computationally manageable.",
    "training_data_format": "torch.Tensor of shape (N,2) containing normalized numeric inputs",
    "implementation tips": "1. Choose the number of Fourier features D (e.g. D = 64 or 128) and a kernel bandwidth \u03c3 based on input scale.\n2. In PyTorch, sample a weight matrix W of shape (2, D) from Normal(mean=0, std=1/\u03c3) and a bias vector b of shape (D,) from Uniform(0, 2\u03c0).\n3. Define a preprocessing function: for each input batch X (shape N\u00d72), compute Z = X @ W + b (shape N\u00d7D), then RFF_X = sqrt(2.0/D) * cos(Z).\n4. Replace the original inputs with RFF_X before feeding into the network. Update the first Linear layer from nn.Linear(2, 4) to nn.Linear(D, 4).\n5. Keep the rest of the pipeline (ReLU, Linear(4,1), Sigmoid, BCELoss, Adam) unchanged. Train and tune \u03c3 and D via simple grid search.\n6. For robustness, fix W and b across training and inference to maintain a consistent feature space."
}
