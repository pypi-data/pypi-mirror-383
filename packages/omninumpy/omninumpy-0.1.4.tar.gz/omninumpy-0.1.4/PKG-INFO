Metadata-Version: 2.4
Name: omninumpy
Version: 0.1.4
Summary: Compatibility layer for NumPy 2.x with GPU acceleration support
Home-page: https://github.com/omninumpy/omninumpy
Author: OmniNumPy Contributors
Author-email: Ryan Walters <ryanwalters@gmail.com>
License: BSD-3-Clause
Project-URL: Homepage, https://github.com/ryanswalters/OmniNumpy
Project-URL: Repository, https://github.com/ryanswalters/OmniNumpy
Project-URL: Issues, https://github.com/ryanswalters/OmniNumpy/issues
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: BSD License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.20.0
Provides-Extra: gpu
Requires-Dist: cupy-cuda12x; platform_machine == "x86_64" and extra == "gpu"
Provides-Extra: jax
Requires-Dist: jax[cpu]; extra == "jax"
Requires-Dist: jaxlib; extra == "jax"
Provides-Extra: all
Requires-Dist: cupy-cuda12x; platform_machine == "x86_64" and extra == "all"
Requires-Dist: jax[cpu]; extra == "all"
Requires-Dist: jaxlib; extra == "all"
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-cov; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python



# OmniNumPy (Experimental)

> Stop fighting NumPy version hell. OmniNumPy is a compatibility layer that lets legacy code run on NumPy 2.x while unlocking GPU acceleration with zero refactoring. Drop-in replacement. Backend agnostic. Just works.

---

## ğŸ“œ Credits

This project uses [NumPy](https://numpy.org/), licensed under the BSD 3-Clause License.  
NumPy Â© 2005â€“2025 NumPy Developers. See [LICENSE.txt](https://github.com/numpy/numpy/blob/main/LICENSE.txt) for details.

---

## âš ï¸ Status

- **Experimental**: APIs, wrappers, and behaviors will change often.  
- **Partial coverage**: Only ~20 functions are backend-aware today. Thousands more are untouched.  
- **Testing**: Cross-backend correctness checks exist but arenâ€™t exhaustive.  
- **Performance**: Benchmarks highlight real speedups, but not every op is optimized.  

---

## ğŸš€ Why This Exists

Scientific computing shouldnâ€™t force you into one backend forever. You should be able to:

- Write NumPy-style code.  
- Switch to GPU with Torch or CuPy.  
- Explore JAX with JIT, TPU, and auto-device placement.  
- Keep old libraries alive by restoring missing APIs.  

OmniNumPy proves this vision works â€” even if itâ€™s only partial today.

---

## ğŸ“¦ Installation

```bash
pip install omninumpy


Optional backends:

pip install omninumpy[torch]   # For PyTorch backend
pip install omninumpy[cupy]    # For CuPy backend
pip install omninumpy[jax]     # For JAX backend

ğŸ“– Usage
Basic
import omninumpy as np

a = np.array([1, 2, 3])
b = np.dot(a, a)

Legacy APIs
import omninumpy as np
np.emulate("1.21")

print(np.int)  
scalar = np.asscalar(np.array([42]))

Backend Switching
np.set_backend("torch")
a = np.array([1, 2, 3])   # torch.Tensor

np.set_backend("cupy")
b = np.array([4, 5, 6])   # cupy.ndarray

np.set_backend("jax:gpu")
c = np.array([7, 8, 9])   # JAX array on GPU

ğŸ¯ Goals

Run on top of the latest stable NumPy (â‰¥2.0).

Provide backward compatibility for older NumPy APIs (1.x, 1.21, etc.).

Allow backend swaps (CuPy, Torch, JAX) with zero refactoring.

Minimize breakage in AI/ML libraries pinned to outdated NumPy.

ğŸ› ï¸ Core Components

Base Layer (NumPy â‰¥2.x) â€“ Import and expose modern NumPy.

Legacy Compatibility Layer â€“ Restore np.int, np.float, np.asscalar, etc.

Backend Abstraction Layer â€“ set_backend("numpy" | "torch" | "cupy" | "jax").

Version Emulation Profiles â€“ emulate("1.19"), emulate("1.21"), etc.

Testing Matrix â€“ CI with NumPy 1.19 â†’ 2.x, Torch, Pandas.

Optional Extensions â€“ Auto-detect breaking libs, config file, warnings.

ğŸŒ High-Level Architecture
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚        User Code          â”‚
 â”‚   import omninumpy as np  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Compatibility Layer       â”‚
 â”‚  (shims for old APIs)      â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Backend Abstraction Layer â”‚
 â”‚ set_backend("numpy"/...)  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Version Emulation Profilesâ”‚
 â”‚ emulate("1.19"/"2.x")     â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚     Base NumPy â‰¥ 2.x      â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… Implemented Functions (Preview)
Function	NumPy	Torch	CuPy	JAX
array	âœ…	âœ…	âœ…	âœ…
dot	âœ…	âœ…	âœ…	âœ… (JIT)
matmul	âœ…	âœ…	âœ…	âœ… (JIT)
mean, sum	âœ…	âœ…	âœ…	âœ…
linalg.inv	âœ…	âœ…	âœ…	âœ… (JIT)
linalg.svd	âœ…	âœ…	âœ…	âœ… (JIT)
â€¦	â€¦	â€¦	â€¦	â€¦
âš ï¸ Limitations

Only ~20 core functions backend-aware today.

Most others fall back to NumPy.

JAX JIT applied only to critical ops.

Error handling = explicit (no silent fallback).

## ğŸ”§ Troubleshooting (a.k.a. Install for Humans)

1. Smash the big blue **Code** button at the top.  
2. Download ZIP.  
3. Unzip like itâ€™s 2007.  
4. Open VS Code.  
5. Install Roo or Kilo extension.  
6. Type your incantation, profit.  


ğŸ—ºï¸ Roadmap

Wrap more functions across all backends.

Add strict backend isolation.

Expand linear algebra coverage.

Improve cross-backend tests + benchmarks.

ğŸ“œ License

MIT â€” take any piece, fork it, or bolt it into your own project.

