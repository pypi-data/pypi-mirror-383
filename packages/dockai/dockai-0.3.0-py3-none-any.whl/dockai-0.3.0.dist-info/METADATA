Metadata-Version: 2.4
Name: dockai
Version: 0.3.0
Summary: DockAI ‚Äì AI-powered Docker Log Analysis Tool (CLI + Cloud)
Author: Ahmet Atakan
Author-email: ahmetatakan.tech@gmail.com
License: Apache License 2.0
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: System :: Monitoring
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: click<9.0,>=8.1
Requires-Dist: docker<7.0,>=6.1
Requires-Dist: openai<2.0,>=1.0
Requires-Dist: requests<3.0,>=2.31
Requires-Dist: termcolor<3.0,>=2.0
Requires-Dist: fastapi<1.0,>=0.110
Requires-Dist: uvicorn<1.0,>=0.23
Requires-Dist: stripe<10,>=9
Requires-Dist: python-dotenv<2.0,>=1.0
Requires-Dist: PyJWT<3.0,>=2.0
Provides-Extra: cloud
Requires-Dist: openai<2.0,>=1.0; extra == "cloud"
Requires-Dist: stripe<10,>=9; extra == "cloud"
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: ruff; extra == "dev"
Requires-Dist: pip-tools; extra == "dev"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: license
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# üê≥ DockAI ‚Äì AI-powered Docker Log Analysis Tool (CLI + Cloud)

DockAI is an intelligent CLI tool that analyzes Docker container logs using **Large Language Models (LLMs)**.
It helps developers, DevOps engineers, and system administrators quickly identify issues, summarize logs, and provide actionable insights.

---

## üöÄ Features

* **AI Log Analysis**
  Understands and summarizes logs using LLMs, identifying possible root causes and suggesting solutions.

* **Performance Monitoring (CPU & Memory)**
  Measure container performance in real-time or over a time window using `--perf` or `--instant-perf`.

* **Local & Cloud AI Modes (Ollama + OpenAI)**
  Analyze with a local model (e.g., `llama3`) or cloud-based OpenAI API:

  ```bash
  dockai analyze my-container --mode local
  dockai analyze my-container --mode cloud
  ```

* **Live Container Status**
  Even when no logs are generated, DockAI provides a live summary including container status, restart count, and health.

* **Simple CLI Usage**

  ```bash
  dockai analyze <container-name> --since 15m --tail 3000
  ```

---

## üìä Example Output

```
ü§ñ AI Analysis:
**Summary:** Database connection failed.
**Root Cause:** TCP/IP connection refused.
**Solution:** 
- Restart the database service inside the Docker container.
- Check port accessibility and network configuration.

‚öôÔ∏è Performance
- CPU p95: 0.3% | max: 1.1%
- Mem p95: 12.7%
```

---

## üß† Supported Models

* Local: `Ollama` (e.g., `llama3`, `mistral`, `gemma`)
* Cloud: `OpenAI GPT-4`, `GPT-4o-mini`

### üîß Default Model

By default, DockAI uses:

```bash
DOCKAI_OLLAMA_MODEL = "qwen2.5:7b-instruct"
```

This model offers excellent multilingual support (including Turkish üáπüá∑) and strong technical reasoning for analyzing Docker logs.

To override the model, set an environment variable:

```bash
export DOCKAI_OLLAMA_MODEL="aya:23b"
```

---

## ‚öôÔ∏è Installation

```bash
pip install dockai
```

### üß© Ollama Installation (All Platforms)

#### macOS

```bash
brew install ollama
ollama pull qwen2.5:7b-instruct
```

#### Linux

```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama pull qwen2.5:7b-instruct
```

#### Windows (PowerShell)

```powershell
winget install Ollama.Ollama
ollama pull qwen2.5:7b-instruct
```

> üí° **Tip:** DockAI automatically uses the model defined in the environment variable `DOCKAI_OLLAMA_MODEL` (default: `qwen2.5:7b-instruct`).

---

## üß© Developer Commands

```bash
make build       # build the package
make publish     # publish to PyPI
make testpublish # publish to TestPyPI
```

---

## üßæ License

Apache License 2.0
Copyright (c) 2025 Ahmet Atakan
