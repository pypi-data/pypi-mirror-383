"""
Chat endpoints for SimaCode API.

Provides REST and WebSocket endpoints for AI chat functionality,
including support for human-in-loop confirmation via chat stream.
"""

import json
import re
import logging

try:
    from fastapi import APIRouter, Depends, WebSocket, WebSocketDisconnect, HTTPException
    from fastapi.responses import StreamingResponse
    FASTAPI_AVAILABLE = True
except ImportError:
    FASTAPI_AVAILABLE = False
    APIRouter = None

from ..dependencies import get_simacode_service
from ..models import (
    ChatRequest, ChatResponse, ErrorResponse, StreamingChatChunk,
    AsyncTaskResponse, TaskStatusResponse, TaskProgressUpdate, TaskManagerStatsResponse
)
from ..chat_confirmation import chat_confirmation_manager
from ...core.service import SimaCodeService, ChatRequest as CoreChatRequest
from ...mcp.async_integration import get_global_task_manager, TaskType

logger = logging.getLogger(__name__)

if FASTAPI_AVAILABLE:
    router = APIRouter()
else:
    router = None


@router.post("/", response_model=ChatResponse)
async def chat(
    request: ChatRequest,
    service: SimaCodeService = Depends(get_simacode_service)
) -> ChatResponse:
    """
    Process a chat message with the AI assistant.
    
    Args:
        request: Chat request containing message and optional session ID
        service: SimaCode service instance
        
    Returns:
        AI response
    """
    try:
        # Convert API request to core request
        core_request = CoreChatRequest(
            message=request.message,
            session_id=request.session_id,
            context=request.context,
            stream=False
        )
        
        # Process through service
        response = await service.process_chat(core_request)
        
        if response.error:
            raise HTTPException(status_code=500, detail=response.error)
            
        return ChatResponse(
            content=response.content,
            session_id=response.session_id,
            metadata=response.metadata
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Chat processing error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/stream")
async def chat_stream(
    request: ChatRequest,
    service: SimaCodeService = Depends(get_simacode_service)
):
    """
    å¤„ç†èŠå¤©æµè¯·æ±‚ï¼Œæ”¯æŒç¡®è®¤æµç¨‹
    æŒ‰ç…§è®¾è®¡æ–‡æ¡£å®ç°ç»Ÿä¸€çš„ç¡®è®¤äº¤äº’ä½“éªŒ
    
    Args:
        request: Chat request containing message and optional session ID
        service: SimaCode service instance
        
    Returns:
        Streaming response with chat chunks
    """
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ºç¡®è®¤å“åº”
        if request.message.startswith("CONFIRM_ACTION:"):
            return await handle_confirmation_response(request, service)
        
        # æ­£å¸¸èŠå¤©æµç¨‹
        core_request = CoreChatRequest(
            message=request.message,
            session_id=request.session_id,
            context=request.context,
            stream=True
        )
        
        async def generate_chunks():
            try:
                # è·å–æµå¼å“åº”
                response_gen = await service.process_chat(core_request)
                
                if hasattr(response_gen, '__aiter__'):
                    # æµå¼å“åº”å¤„ç†
                    session_id = request.session_id or "new"
                    async for chunk in response_gen:
                        # å¤„ç†ç¡®è®¤è¯·æ±‚
                        if chunk.startswith("[confirmation_request]"):
                            confirmation_chunk = await handle_confirmation_request(
                                request.session_id, chunk, service
                            )
                            yield f"data: {confirmation_chunk.model_dump_json()}\n\n"
                            
                        else:
                            chunk_data = process_regular_chunk(chunk, session_id)
                            yield f"data: {chunk_data.model_dump_json()}\n\n"
                    
                    # å‘é€å®Œæˆä¿¡å·
                    # å°è¯•è·å–sessionä¿¡æ¯ä»¥ç”Ÿæˆè¯¦ç»†æ‘˜è¦
                    session_info = None
                    try:
                        if session_id and session_id != "new":
                            session_info = await service.get_session_info(session_id)
                    except Exception:
                        pass  # å¿½ç•¥è·å–sessionå¤±è´¥çš„æƒ…å†µ
                    
                    final_chunk = await create_completion_chunk(session_id, session_info, service)
                    yield f"data: {final_chunk.model_dump_json()}\n\n"
                else:
                    # éæµå¼å“åº”ï¼ˆå›é€€ï¼‰
                    fallback_chunk = create_content_chunk(
                        response_gen.content, 
                        response_gen.session_id, 
                        finished=True,
                        metadata=response_gen.metadata
                    )
                    yield f"data: {fallback_chunk.model_dump_json()}\n\n"
                    
            except Exception as e:
                logger.error(f"æµå¼å¤„ç†é”™è¯¯: {e}")
                error_chunk = create_error_chunk(str(e), request.session_id or "error")
                yield f"data: {error_chunk.model_dump_json()}\n\n"
        
        return StreamingResponse(
            generate_chunks(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
        )
        
    except Exception as e:
        logger.error(f"Chat streaming setup error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.websocket("/ws")
async def chat_websocket(
    websocket: WebSocket,
    service: SimaCodeService = Depends(get_simacode_service)
):
    """
    WebSocket endpoint for real-time chat.
    
    Args:
        websocket: WebSocket connection
        service: SimaCode service instance
    """
    await websocket.accept()
    logger.info("WebSocket chat connection established")
    
    try:
        while True:
            # Receive message from client
            data = await websocket.receive_json()
            
            try:
                # Validate message format
                if "message" not in data:
                    await websocket.send_json({
                        "error": "Missing 'message' field",
                        "type": "error"
                    })
                    continue
                
                # Create core request
                core_request = CoreChatRequest(
                    message=data["message"],
                    session_id=data.get("session_id"),
                    context=data.get("context", {}),
                    stream=False
                )
                
                # Process chat request
                response = await service.process_chat(core_request)
                
                if response.error:
                    await websocket.send_json({
                        "error": response.error,
                        "type": "error",
                        "session_id": response.session_id
                    })
                else:
                    await websocket.send_json({
                        "content": response.content,
                        "session_id": response.session_id,
                        "metadata": response.metadata,
                        "type": "response"
                    })
                    
            except Exception as e:
                logger.error(f"WebSocket message processing error: {e}")
                await websocket.send_json({
                    "error": str(e),
                    "type": "error"
                })
                
    except WebSocketDisconnect:
        logger.info("WebSocket chat connection closed")
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        try:
            await websocket.close()
        except:
            pass


# ==================== ç¡®è®¤æµç¨‹è¾…åŠ©å‡½æ•° ====================
# æŒ‰ç…§è®¾è®¡æ–‡æ¡£è§„èŒƒå®ç°

async def handle_confirmation_request(
    session_id: str, 
    chunk: str, 
    service: SimaCodeService
) -> StreamingChatChunk:
    """
    å¤„ç†ç¡®è®¤è¯·æ±‚chunk - æŒ‰ç…§è®¾è®¡æ–‡æ¡£è§„èŒƒå®ç°
    
    Args:
        session_id: ä¼šè¯ID
        chunk: ç¡®è®¤è¯·æ±‚chunkå†…å®¹ æ ¼å¼: [confirmation_request]{json_data}
        service: æœåŠ¡å®ä¾‹
        
    Returns:
        æ ‡å‡†åŒ–çš„ç¡®è®¤è¯·æ±‚StreamingChatChunk
    """
    try:
        # è§£æç¡®è®¤è¯·æ±‚æ•°æ®
        confirmation_data_str = chunk[len("[confirmation_request]"):].strip()
        confirmation_data = json.loads(confirmation_data_str)
        
        # æ³¨æ„ï¼šä¸è¦é‡å¤åˆ›å»ºç¡®è®¤è¯·æ±‚ï¼Œå› ä¸ºReActå¼•æ“å·²ç»åˆ›å»ºè¿‡äº†
        # è¿™é‡Œåªéœ€è¦æ ¼å¼åŒ–ç¡®è®¤æ¶ˆæ¯ç»™å®¢æˆ·ç«¯
        # await chat_confirmation_manager.request_confirmation(
        #     session_id=session_id,
        #     tasks=confirmation_data.get("tasks", []),
        #     timeout_seconds=confirmation_data.get("timeout_seconds", 300)
        # )
        
        # æŒ‰ç…§è®¾è®¡æ–‡æ¡£æ ¼å¼åŒ–ç¡®è®¤æ¶ˆæ¯
        tasks = confirmation_data.get("tasks", [])
        task_descriptions = []
        for task in tasks:
            task_descriptions.append(f"{task.get('index', '-')} {task.get('description', 'æœªçŸ¥ä»»åŠ¡')}")
        
        confirmation_message = f"è¯·ç¡®è®¤æ‰§è¡Œä»¥ä¸‹{len(tasks)}ä¸ªä»»åŠ¡ï¼š\n" + "\n".join(task_descriptions)
        
        # åˆ›å»ºæ ‡å‡†åŒ–çš„ç¡®è®¤è¯·æ±‚chunk
        return StreamingChatChunk(
            chunk=confirmation_message,
            session_id=session_id,
            finished=False,
            chunk_type="confirmation_request",
            confirmation_data=confirmation_data,
            requires_response=True,
            stream_paused=True,
            metadata={
                "total_tasks": len(tasks),
                "risk_level": confirmation_data.get("risk_level", "unknown"),
                "timeout_seconds": confirmation_data.get("timeout_seconds", 300),
                "confirmation_round": confirmation_data.get("confirmation_round", 1)
            }
        )
        
    except Exception as e:
        logger.error(f"Error handling confirmation request: {e}")
        return create_error_chunk(f"ç¡®è®¤è¯·æ±‚å¤„ç†é”™è¯¯: {str(e)}", session_id)


async def handle_confirmation_response(
    request: ChatRequest, 
    service: SimaCodeService
) -> StreamingResponse:
    """
    å¤„ç†ç¡®è®¤å“åº” - æŒ‰ç…§è®¾è®¡æ–‡æ¡£è§„èŒƒå®ç°
    
    Args:
        request: åŒ…å«ç¡®è®¤å“åº”çš„èŠå¤©è¯·æ±‚
        service: æœåŠ¡å®ä¾‹
        
    Returns:
        æµå¼å“åº”
    """
    try:
        # è§£æç¡®è®¤åŠ¨ä½œ - æŒ‰ç…§è®¾è®¡æ–‡æ¡£æ ¼å¼ CONFIRM_ACTION:action:message
        action_part = request.message[len("CONFIRM_ACTION:"):].strip()
        parts = action_part.split(":", 1)
        action = parts[0].strip()
        user_message = parts[1].strip() if len(parts) > 1 else None
        
        session_id = request.session_id or "unknown"
        
        # éªŒè¯åŠ¨ä½œ
        if action not in ["confirm", "modify", "cancel"]:
            raise ValueError(f"æ— æ•ˆçš„ç¡®è®¤åŠ¨ä½œ: {action}")
        
        # æäº¤ç¡®è®¤å“åº”
        success = await chat_confirmation_manager.submit_confirmation(
            session_id, action, user_message
        )
        
        async def generate_response():
            if success:
                # æˆåŠŸå“åº”
                response_chunk = create_confirmation_received_chunk(session_id, action, user_message)
            else:
                # å¤±è´¥å“åº”
                response_chunk = create_error_chunk(
                    "ç¡®è®¤æäº¤å¤±è´¥ï¼Œå¯èƒ½ä¼šè¯å·²è¿‡æœŸæˆ–ä¸å­˜åœ¨å¾…ç¡®è®¤çš„è¯·æ±‚", 
                    session_id
                )
            
            yield f"data: {response_chunk.model_dump_json()}\n\n"
        
        return StreamingResponse(
            generate_response(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache"}
        )
        
    except Exception as e:
        logger.error(f"ç¡®è®¤å“åº”å¤„ç†é”™è¯¯: {e}")
        
        async def error_response():
            error_chunk = create_error_chunk(f"ç¡®è®¤æ ¼å¼é”™è¯¯: {str(e)}", request.session_id or "error")
            yield f"data: {error_chunk.model_dump_json()}\n\n"
        
        return StreamingResponse(
            error_response(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache"}
        )


@router.post("/async", response_model=AsyncTaskResponse)
async def chat_async(
    request: ChatRequest,
    service: SimaCodeService = Depends(get_simacode_service)
) -> AsyncTaskResponse:
    """
    Submit a chat message for asynchronous processing.

    This endpoint is designed for complex chat interactions that may
    trigger long-running ReAct tasks or MCP tool executions.

    Args:
        request: Chat request containing message and optional session ID
        service: SimaCode service instance

    Returns:
        Task submission confirmation with task ID
    """
    try:
        # Convert API request to core request
        core_request = CoreChatRequest(
            message=request.message,
            session_id=request.session_id,
            context=request.context,
            stream=False
        )

        # Check if message requires async processing
        # This could trigger ReAct mode if the message indicates complex tasks
        if not await service._requires_async_chat_processing(core_request):
            # For simple chat, redirect to synchronous processing
            response = await service.process_chat(core_request)
            if response.error:
                raise HTTPException(status_code=500, detail=response.error)

            # Return a "completed" async response for consistency
            return AsyncTaskResponse(
                task_id=f"sync_chat_{response.session_id}",
                status="completed",
                session_id=response.session_id
            )

        # Submit task to async task manager
        task_manager = get_global_task_manager()
        task_id = await task_manager.submit_task(
            task_type=TaskType.CHAT,
            request=core_request
        )

        logger.info(f"Async chat task {task_id} submitted for session {core_request.session_id}")

        return AsyncTaskResponse(
            task_id=task_id,
            status="pending",
            session_id=core_request.session_id
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Async chat task submission error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/tasks/{task_id}", response_model=TaskStatusResponse)
async def get_chat_task_status(
    task_id: str,
    service: SimaCodeService = Depends(get_simacode_service)
) -> TaskStatusResponse:
    """
    Get the status of an async chat task.

    Args:
        task_id: The task identifier returned from /async
        service: SimaCode service instance

    Returns:
        Current task status and metadata
    """
    try:
        # Handle sync task IDs (fake async responses)
        if task_id.startswith("sync_chat_"):
            return TaskStatusResponse(
                task_id=task_id,
                task_type="chat",
                status="completed",
                created_at=0,
                completed_at=0,
                metadata={"sync_task": True}
            )

        task_manager = get_global_task_manager()
        task = await task_manager.get_task_status(task_id)

        if not task:
            raise HTTPException(status_code=404, detail=f"Task {task_id} not found")

        return TaskStatusResponse(
            task_id=task.task_id,
            task_type=task.task_type.value,
            status=task.status.value,
            created_at=task.created_at,
            started_at=task.started_at,
            completed_at=task.completed_at,
            error=task.error,
            metadata=task.metadata or {}
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Chat task status query error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/tasks")
async def get_task_manager_stats(
    service: SimaCodeService = Depends(get_simacode_service)
) -> TaskManagerStatsResponse:
    """
    Get task manager statistics and status.

    Returns:
        Current task manager statistics
    """
    try:
        task_manager = get_global_task_manager()
        stats = task_manager.get_stats()

        return TaskManagerStatsResponse(
            active_tasks=stats["active_tasks"],
            task_breakdown=stats["task_breakdown"]
        )

    except Exception as e:
        logger.error(f"Task manager stats error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.websocket("/ws/async")
async def chat_async_websocket(
    websocket: WebSocket,
    service: SimaCodeService = Depends(get_simacode_service)
):
    """
    WebSocket endpoint for real-time async chat with progress updates.

    Protocol:
    - Client sends: {"message": "...", "session_id": "...", "context": {...}}
    - Server responds with task_id and then streams progress updates
    - Final message contains the complete response

    Args:
        websocket: WebSocket connection
        service: SimaCode service instance
    """
    await websocket.accept()
    logger.info("WebSocket async chat connection established")

    try:
        while True:
            # Receive message from client
            data = await websocket.receive_json()

            try:
                # Validate message format
                if "message" not in data:
                    await websocket.send_json({
                        "error": "Missing 'message' field",
                        "type": "error"
                    })
                    continue

                # Create core request
                core_request = CoreChatRequest(
                    message=data["message"],
                    session_id=data.get("session_id"),
                    context=data.get("context", {}),
                    stream=False
                )

                # Check if message requires async processing
                if not await service._requires_async_chat_processing(core_request):
                    # Execute synchronously for simple chat
                    await websocket.send_json({
                        "type": "sync_execution",
                        "message": "Processing simple chat message synchronously"
                    })

                    response = await service.process_chat(core_request)

                    if response.error:
                        await websocket.send_json({
                            "error": response.error,
                            "type": "error",
                            "session_id": response.session_id
                        })
                    else:
                        await websocket.send_json({
                            "content": response.content,
                            "session_id": response.session_id,
                            "metadata": response.metadata,
                            "type": "response"
                        })
                    continue

                # Submit async task
                task_manager = get_global_task_manager()
                task_id = await task_manager.submit_task(
                    task_type=TaskType.CHAT,
                    request=core_request
                )

                # Send task submission confirmation
                await websocket.send_json({
                    "type": "task_submitted",
                    "task_id": task_id,
                    "session_id": core_request.session_id,
                    "message": "Chat message submitted for async processing"
                })

                # Stream progress updates
                try:
                    async for progress_data in task_manager.get_task_progress_stream(task_id):
                        await websocket.send_json({
                            "type": "progress_update",
                            "task_id": task_id,
                            "progress": progress_data
                        })

                        # Stop streaming after final result
                        if progress_data.get("type") == "final_result":
                            break

                except Exception as e:
                    logger.error(f"Chat progress streaming error: {e}")
                    await websocket.send_json({
                        "type": "stream_error",
                        "task_id": task_id,
                        "error": str(e)
                    })

            except Exception as e:
                logger.error(f"WebSocket async chat processing error: {e}")
                await websocket.send_json({
                    "error": str(e),
                    "type": "error"
                })

    except WebSocketDisconnect:
        logger.info("WebSocket async chat connection closed")
    except Exception as e:
        logger.error(f"WebSocket async chat error: {e}")
        try:
            await websocket.close()
        except:
            pass


def _process_confirmation_request_chunk(chunk: str, session_id: str) -> StreamingChatChunk:
    """
    å¤„ç†ç¡®è®¤è¯·æ±‚chunkçš„ä¸“ç”¨å‡½æ•°

    Args:
        chunk: ç¡®è®¤è¯·æ±‚chunkå†…å®¹ï¼Œæ ¼å¼ä¸º [confirmation_request]{json_data}
        session_id: ä¼šè¯ID

    Returns:
        å¤„ç†åçš„StreamingChatChunk

    Raises:
        æ— å¼‚å¸¸æŠ›å‡ºï¼Œé”™è¯¯æ—¶è¿”å›é”™è¯¯ç±»å‹çš„chunk
    """
    try:
        import json
        confirmation_data_str = chunk[len("[confirmation_request]"):]
        confirmation_data = json.loads(confirmation_data_str)

        # åˆ›å»ºæ­£ç¡®çš„ç¡®è®¤æ¶ˆæ¯ï¼Œæ˜¾ç¤ºå®é™…ä»»åŠ¡æ•°é‡
        tasks = confirmation_data.get("tasks", [])
        task_descriptions = []
        for i, task in enumerate(tasks):
            task_descriptions.append(f"{i+1}. {task.get('description', 'æœªçŸ¥ä»»åŠ¡')}")

        confirmation_message = f"è¯·ç¡®è®¤æ‰§è¡Œä»¥ä¸‹{len(tasks)}ä¸ªä»»åŠ¡ï¼š\n" + "\n".join(task_descriptions)

        return StreamingChatChunk(
            chunk=confirmation_message,
            session_id=session_id,
            finished=False,
            chunk_type="confirmation_request",
            confirmation_data=confirmation_data,  # ä¼ é€’å®Œæ•´çš„æ‰å¹³åŒ–æ•°æ®
            requires_response=True,
            stream_paused=True,
            metadata={
                "total_tasks": len(tasks),
                "risk_level": confirmation_data.get("risk_level", "unknown"),
                "timeout_seconds": confirmation_data.get("timeout_seconds", 300),
                "confirmation_round": confirmation_data.get("confirmation_round", 1)
            }
        )
    except (json.JSONDecodeError, KeyError) as e:
        logger.warning(f"Failed to parse confirmation request chunk: {e}")
        return create_chunk("error", f"ç¡®è®¤è¯·æ±‚æ ¼å¼é”™è¯¯: {chunk}", session_id)


def process_regular_chunk(chunk: str, session_id: str) -> StreamingChatChunk:
    """
    å¤„ç†å¸¸è§„chunk - æŒ‰ç…§è®¾è®¡æ–‡æ¡£è§„èŒƒå®ç°

    Args:
        chunk: chunkå†…å®¹
        session_id: ä¼šè¯ID

    Returns:
        å¤„ç†åçš„StreamingChatChunk
    """
    # è¯†åˆ«chunkç±»å‹ï¼ˆåŸºäºå†…å®¹å‰ç¼€ï¼‰ï¼Œä½†ä¿ç•™å‰ç¼€åœ¨chunkå†…å®¹ä¸­
    if chunk.startswith("[confirmation_request]"):
        return _process_confirmation_request_chunk(chunk, session_id)
    elif chunk.startswith("[task_summary]"):
        return create_chunk("task_summary", chunk, session_id)
    elif chunk.startswith("[progress]"):
        return create_chunk("content", chunk, session_id)
    elif chunk.startswith("âŒ"):
        return create_chunk("error", chunk, session_id)
    elif re.match(r"\[.+\]", chunk):
        return create_chunk("status", chunk, session_id)
    else:
        return create_chunk("content", chunk, session_id)

# ==================== Chunkåˆ›å»ºè¾…åŠ©å‡½æ•° ====================

def create_chunk(chunk_type: str, content: str, session_id: str, **kwargs) -> StreamingChatChunk:
    """åˆ›å»ºæ ‡å‡†åŒ–çš„StreamingChatChunk"""
    return StreamingChatChunk(
        chunk=content,
        session_id=session_id,
        finished=kwargs.get('finished', False),
        chunk_type=chunk_type,
        metadata=kwargs.get('metadata', {}),
        confirmation_data=kwargs.get('confirmation_data'),
        requires_response=kwargs.get('requires_response', False),
        stream_paused=kwargs.get('stream_paused', False)
    )


def create_content_chunk(content: str, session_id: str, finished: bool = False, metadata: dict = None) -> StreamingChatChunk:
    """åˆ›å»ºå†…å®¹chunk"""
    return create_chunk("content", content, session_id, finished=finished, metadata=metadata or {})


def create_error_chunk(error_message: str, session_id: str, reason: str = None) -> StreamingChatChunk:
    """åˆ›å»ºé”™è¯¯chunk"""
    metadata = {"error": True}
    if reason:
        metadata["reason"] = reason
    return create_chunk("error", f"âŒ {error_message}", session_id, finished=True, metadata=metadata)


async def create_completion_chunk(session_id: str, session=None, service=None) -> StreamingChatChunk:
    """åˆ›å»ºå®Œæˆchunk"""
    from ...utils.task_summary import DEFAULT_TASK_SUCCESS_MESSAGE
    
    # å¦‚æœæœ‰sessionä¿¡æ¯ï¼Œå°è¯•ç”Ÿæˆè¯¦ç»†çš„ä»»åŠ¡æ‘˜è¦
    completion_content = DEFAULT_TASK_SUCCESS_MESSAGE
    
    if session and service:
        try:
            # å°è¯•ä»react_serviceç”Ÿæˆæ‘˜è¦
            if hasattr(service, 'react_service'):
                completion_content = await service.react_service.get_task_summary_by_session_id(session_id)
        except Exception:
            # å¦‚æœç”Ÿæˆæ‘˜è¦å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¶ˆæ¯
            pass
    
    return create_chunk(
        "completion",
        f"[completion] {completion_content}",
        session_id,
        finished=True,
        metadata={"stream_completed": True}
    )


def create_confirmation_received_chunk(session_id: str, action: str, user_message: str = None) -> StreamingChatChunk:
    """åˆ›å»ºç¡®è®¤æ¥æ”¶chunk"""
    message = f"ğŸ¤”æŒ‡ä»¤å·²æ”¶åˆ°ï¼Œä»»åŠ¡æ‰§è¡Œä¸­ã€‚æ‚¨å¯ä»¥åœ¨ä»»åŠ¡é¢æ¿æŸ¥çœ‹å®æ—¶è¿›åº¦ã€‚è¯·ç»§ç»­å®‰æ’å…¶ä»–å·¥ä½œã€‚"
    if user_message:
        message += f" - {user_message}"
    
    return create_chunk(
        "confirmation_received",
        message,
        session_id,
        finished=True,
        metadata={
            "action": action,
            "user_message": user_message
        }
    )