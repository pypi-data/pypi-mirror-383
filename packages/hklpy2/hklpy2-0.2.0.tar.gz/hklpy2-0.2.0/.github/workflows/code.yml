name: Unit Tests

on:
  # Triggers the workflow on push or pull request events but only for the main branch
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch: # allow manual triggering

defaults:
  run:
    shell: bash -l {0}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint:
    name: Code style
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v5

      - uses: actions/setup-python@v6
        with:
          python-version: "3.12"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-cache-${{ runner.os }}-py3.12-${{ hashFiles('**/pyproject.toml','**/requirements*.txt') }}

      - name: Install ruff and run
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install ruff
          ruff check .

  tests:
    name: Python ${{ matrix.python-version }}
    needs: lint
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version:
          - "3.10"
          - "3.11"
          - "3.12"
          - "3.13"
          # - "3.14"  # not installable because it requires python_rc =* *, which does not exist
      max-parallel: 5

    steps:
      - uses: actions/checkout@v5

      - name: Cached Python ${{ matrix.python-version }} environment
        uses: mamba-org/setup-micromamba@v2
        with:
          cache-environment: true
          cache-environment-key: env-key-${{ matrix.python-version }}
          condarc: |
            channels:
              - conda-forge
              - nodefaults
            channel-priority: flexible
          environment-name: micromamba-test-env-py-${{ matrix.python-version }}
          create-args: >-
            bson
            hkl
            pyepics
            pytest
            python=${{ matrix.python-version }}
            pyyaml
            ruamel.yaml
            setuptools-scm
            tiled
            yaml

      - name: Cache pip (per matrix)
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-cache-${{ runner.os }}-py${{ matrix.python-version }}-${{ hashFiles('**/pyproject.toml','**/requirements*.txt') }}

      - name: Start EPICS softIoc
        run: |
          set -euo pipefail
          caRepeater &
          softIoc \
            -S \
            -m "P=hklpy2:" \
            -d ./hklpy2/tests/testing.db \
            -x "hklpy2" \
            ./hklpy2/tests/st.cmd &
          echo "Waiting for EPICS IOC to start..."
          sleep 15
          echo "EPICS IOC should be running now."

      - name: Install source and requirements (fast, allow pre)
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install --pre tiled
          pip install --pre -e .[all]

      - name: Diagnostic
        run: |
          micromamba info || true
          micromamba list || true
          micromamba env list || true

      - name: Check on the EPICS IOC
        run: |
          set -euo pipefail
          echo "info hklpy2:wavelength = $(cainfo hklpy2:wavelength)"
          caget hklpy2:BaseVersion
          caget hklpy2:energy.{NAME,VAL,EGU,DESC}
          caget hklpy2:wavelength.{NAME,VAL,EGU,DESC}

      - name: Run tests with pytest & coverage
        shell: bash -l {0}
        run: |
          set -vxeuo pipefail
          mkdir -p reports

          # ensure correct coverage
          python -m pip install --upgrade --force-reinstall coverage

          # run tests under coverage; keep exit code handling so we can still gather reports
          python -m coverage \
            run \
            --concurrency=thread \
            --parallel-mode \
            -m pytest \
              -q \
              --junitxml=reports/junit.xml .

          # combine and report
          python -m coverage combine || true
          python -m coverage xml -i -o coverage.xml || true
          python -m coverage report --precision 3 -m || true

          # check junit for failures
          if [ -f reports/junit.xml ]; then
            if grep -E "failures=\"[1-9][0-9]*\"|errors=\"[1-9][0-9]*\"" reports/junit.xml; then
              echo "Detected test failures or errors in reports/junit.xml"
              exit 1
            fi
          else
            echo "No junit.xml produced; assume pytest failed."
            exit 1
          fi

      - name: Coverage debug
        if: failure() || always()
        run: |
          python -c "import coverage, sys; print('coverage:', getattr(coverage, '__file__', 'no-file'), getattr(coverage, '__version__', 'no-version'))"

      - name: Install (force reinstall) coveralls
        run: python -m pip install --upgrade --force-reinstall coveralls

      - name: Upload test artifacts (junit, coverage)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-reports-${{ matrix.python-version }}
          path: |
            reports/
            .coverage*

      - name: Upload to Coveralls (best-effort)
        if: always()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          COVERALLS_FLAG_NAME: ${{ matrix.test-name }}
          COVERALLS_PARALLEL: true
        run: |
          set -euo pipefail
          coveralls debug || true
          coveralls --service=github || true

  coveralls:
    name: Report unit test coverage to coveralls
    needs: tests
    runs-on: ubuntu-latest
    container: python:3-slim
    steps:
      - name: Install git and coveralls
        run: |
          set -euo pipefail
          apt-get -y update && apt-get install -y git
          python3 -m pip install --no-cache-dir --upgrade pip coveralls

      - name: Finish coveralls
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          coveralls --service=github --finish
