general:
  name: "AWI-ESM-1-1-lr PI Control"
  description: "CMOR configuration for AWIESM 1.1 LR"
  maintainer: "pgierz"
  email: "pgierz@awi.de"
  cmor_version: "CMIP6"
  mip: "CMIP"
  CMIP_Tables_Dir: "/work/ab0246/a270077/SciComp/Projects/pycmor/cmip6-cmor-tables/Tables"
  CV_Dir: "/work/ab0246/a270077/SciComp/Projects/pycmor/cmip6-cmor-tables/CMIP6_CVs/"
pycmor:
  # parallel: True
  warn_on_no_rule: False
  use_flox: True
  dask_cluster: "slurm"
  dask_cluster_scaling_mode: fixed
  fixed_jobs: 1
  # minimum_jobs: 8
  # maximum_jobs: 30
  # You can add your own path to the dimensionless mapping table
  # If nothing is specified here, it will use the built-in one.
rules:
  - name: Dissolved Inorganic Carbon in Seawater
    description: "dissic from REcoM, showing missing units in NetCDF"
    inputs:
      - path: "/work/ab0246/a270077/SciComp/Projects/pymor/examples/03-incorrect-units-in-source-files/model_runs/piControl_LUtrans1850/outdata/recom/"
        pattern: bgc02_fesom_.*.nc
    grid_file: /pool/data/AWICM/FESOM1/MESHES/core/griddes.nc
    mesh_path: /pool/data/AWICM/FESOM1/MESHES/core
    cmor_variable: dissic
    model_variable: "bgc02"
    model_unit: "mmol m-3"
    output_directory: .
    variant_label: r1i1p1f1
    experiment_id: piControl
    source_id: AWI-CM-1-1-HR
    model_component: ocnBgchem
    grid_label: gn
  - name: Seawater Alkalinity
    description: "talk from REcoM, showing missing units in NetCDF"
    inputs:
      - path: "/work/ab0246/a270077/SciComp/Projects/pymor/examples/03-incorrect-units-in-source-files/model_runs/piControl_LUtrans1850/outdata/recom/"
        pattern: bgc03_fesom_.*.nc
    grid_file: /pool/data/AWICM/FESOM1/MESHES/core/griddes.nc
    mesh_path: /pool/data/AWICM/FESOM1/MESHES/core
    cmor_variable: talk
    model_variable: "bgc03"
    model_unit: "mmol m-3"
    output_directory: .
    variant_label: r1i1p1f1
    experiment_id: piControl
    source_id: AWI-CM-1-1-HR
    model_component: ocnBgchem
    grid_label: gn
distributed:
  worker:
    memory:
      target: 0.6 # Target 60% of worker memory usage
      spill: 0.7 # Spill to disk when 70% of memory is used
      pause: 0.8 # Pause workers if memory usage exceeds 80%
      terminate: 0.95 # Terminate workers at 95% memory usage
    resources:
      CPU: 4 # Assign 4 CPUs per worker
    death-timeout: 600 # Worker timeout if no heartbeat (seconds): Keep workers alive for 5 minutes
# SLURM-specific settings for launching workers
jobqueue:
  slurm:
    name: pycmor-worker
    queue: compute # SLURM queue/partition to submit jobs
    account: ab0246 # SLURM project/account name
    cores: 4 # Number of cores per worker
    memory: 128GB # Memory per worker
    walltime: '00:30:00' # Maximum walltime per job
    interface: ib0 # Network interface for communication
    job-extra-directives: # Additional SLURM job options
      - '--exclusive' # Run on exclusive nodes
      - '--nodes=1'
    # Worker template
    worker-extra:
      - "--nthreads"
      - 4
      - "--memory-limit"
      - "128GB"
      - "--lifetime"
      - "25m"
      - "--lifetime-stagger"
      - "4m"
    # How to launch workers and scheduler
    job-cpu: 128
    job-mem: 256GB
    # worker-command: dask-worker
    processes: 4 # Limited by memory per worker!
    # scheduler-command: dask-scheduler
