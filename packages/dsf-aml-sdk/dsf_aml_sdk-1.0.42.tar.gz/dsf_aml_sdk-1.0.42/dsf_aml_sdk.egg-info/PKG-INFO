Metadata-Version: 2.4
Name: dsf-aml-sdk
Version: 1.0.42
Summary: SDK for DSF Adaptive ML with Knowledge Distillation
Home-page: https://github.com/jaimeajl/dsf-aml-sdk
Author: api-dsfuptech
Author-email: contacto@softwarefinanzas.com.co
Keywords: dsf aml ml machine-learning distillation adaptive sdk
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: requests>=2.25.0
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# DSF AML SDK

Reduce ML training data by **70â€“90%** via adaptive evaluation and knowledge distillation.  
Distill a surrogate and run inference **~10Ã— faster** with tiny footprints.

---

## ðŸš€ Why DSF AML?

Traditional ML needs thousands of labels and long training cycles. DSF AML encodes **domain rules** in a lightweight formula and (Pro/Ent) distills them into a **fast surrogate**, letting you ship accurate models with **minimal data** and **lower infrastructure costs**.

---

## ðŸ“š Core Concepts

- **Config-as-rules**: Per-field `default`, `importance`, `sensitivity`, optional `string_floor`
- **Adaptive evaluation**: Compute a normalized score for any item
- **Decision-boundary focus**: Generate/collect data near the threshold
- **Knowledge distillation** (Pro/Ent): Train a linear surrogate for sub-ms inference

> **Non-linear mode (Pro/Ent):** The backend expects  
> `data['adjustments_values'] = { field_name: { adjustment_name: value[-1..1] } }`

---

## ðŸ“¦ Installation

```bash
pip install dsf-aml-sdk
```

Optionally point the SDK to your backend:

```python
import os
from dsf_aml_sdk import AMLSDK

sdk = AMLSDK(
    base_url=os.getenv("DSF_AML_BASE_URL"),  # e.g. https://your-vercel-app.vercel.app
    tier="community"
)
```

---

## ðŸŽ¯ Quick Start

### Community

```python
from dsf_aml_sdk import AMLSDK

sdk = AMLSDK()  # defaults to community tier

config = (sdk.create_config()
    .add_field('model_accuracy',  default=0.95, importance=2.5, sensitivity=2.0)
    .add_field('training_epochs', default=100,  importance=1.8, sensitivity=1.5)
    .add_field('validation_loss', default=0.05, importance=2.2, sensitivity=2.5)
    .add_field('model_name',      default='baseline', importance=1.0, string_floor=0.1)
)

item = {'model_accuracy': 0.96, 'training_epochs': 105, 'validation_loss': 0.048}
res = sdk.evaluate(item, config)
print(f"Score: {res.score:.3f}")
```

### Professional

```python
from dsf_aml_sdk import AMLSDK

sdk = AMLSDK(license_key='PRO-2026-12-31-XXXX', tier='professional')

cfg = (sdk.create_config()
    .add_field('model_accuracy', 0.9, 2.0, 2.0)
    .add_field('training_epochs', 100, 1.8, 1.5)
    .add_field('validation_loss', 0.05, 2.2, 2.5)
)

# Batch evaluation (up to BATCH_MAX_ITEMS; default 1000)
experiments = [
    {'model_accuracy': 0.92, 'training_epochs': 50,  'validation_loss': 0.08},
    {'model_accuracy': 0.95, 'training_epochs': 100, 'validation_loss': 0.05},
]
scores = sdk.batch_evaluate(experiments, cfg)

# Metrics (after at least one evaluate/batch)
metrics = sdk.get_metrics()
```

### Enterprise: Pipeline + Distillation

```python
from dsf_aml_sdk import AMLSDK

sdk = AMLSDK(license_key='ENT-2026-12-31-XXXX', tier='enterprise')

training_data = [
    {'model_accuracy': 0.92, 'training_epochs': 120, 'validation_loss': 0.06},
    {'model_accuracy': 0.88, 'training_epochs':  80, 'validation_loss': 0.07},
    # ...
]

# 1) Identify seeds
seeds = sdk.pipeline_identify_seeds(dataset=training_data, config=cfg, top_k_percent=0.1)

# 2) Generate critical variants
gen = sdk.pipeline_generate_critical(config=cfg, original_dataset=training_data)

# 3) Full cycle
full = sdk.pipeline_full_cycle(dataset=training_data, config=cfg, max_iterations=3)

# 4) Distillation
sdk.distill_train(cfg, samples=1000, batch_size=100, seed=42)
fast_score = sdk.distill_predict(training_data[0], cfg)
artifact = sdk.distill_export()  # Enterprise only
```

---

## ðŸ’¡ Use Cases

### 1. Data Curation: Keep Only What Matters
Retain the **10â€“30% most informative samples** near decision boundaries, discard duplicates and easy cases.

```python
# Start with 10,000 samples
result = sdk.pipeline_full_cycle(dataset=full_training_data, config=config, max_iterations=3)
print(f"Reduced: {len(full_training_data)} â†’ {result['final_size']} samples")
# Typical output: "Reduced: 10000 â†’ 1500 samples" (85% reduction)
```

### 2. Policy Stress Testing: Generate Edge Cases
Create boundary scenarios for testing ML policies (e.g., accuracy vs latency trade-offs).

```python
# Generate critical variants around decision threshold
seeds = sdk.pipeline_identify_seeds(production_data, config, top_k_percent=0.1)
edge_cases = sdk.pipeline_generate_critical(
    config=config,
    original_dataset=production_data,
    epsilon=0.05  # tight band around threshold
)
# Use edge_cases for stress testing your models
```

### 3. Edge Deployment: Sub-millisecond Inference
Deploy a linear surrogate for **<1ms CPU inference** without GPUs.

```python
# Train surrogate from your complex model
sdk.distill_train(config, samples=1000)

# Deploy with minimal footprint
def inference_edge(sample):
    return sdk.distill_predict(sample, config)  # <1ms on CPU

# Benchmark: typically 10-50Ã— faster than original model
```

### 4. Cost Control: 70â€“90% Less Training Data
Evaluate â†’ Reduce â†’ Train pipeline cuts cloud costs dramatically.

```python
# Traditional approach: $1000/month for 100K samples
original_cost = calculate_training_cost(samples=100_000)

# DSF approach: Focus on 10K critical samples
reduced_data = sdk.pipeline_full_cycle(dataset, config)
new_cost = calculate_training_cost(samples=len(reduced_data['final_samples']))

print(f"Cost savings: {(1 - new_cost/original_cost)*100:.0f}%")
# Typical output: "Cost savings: 87%"
```

### Summary
**DSF AML delivers:**
- **Less data**: 70â€“90% reduction while preserving decision boundaries
- **Faster training**: Focus on critical samples only  
- **Synthesis capability**: Generate edge cases from minimal seed data
- **Production-ready**: Partial results handling for serverless environments

---

## â±ï¸ Handling Partial Results (Serverless-friendly)

Long operations may return `status: "partial"` with a cursor and optional partial payload. Re-submit those values to continue without timeouts.

### Critical Generation (Enterprise)

```python
resp = sdk.pipeline_generate_critical(cfg, original_dataset=training_data, k_variants=3)

while isinstance(resp, dict) and resp.get("status") == "partial":
    resp = sdk._make_request("", {
        "action": "pipeline_generate_critical",
        "config": cfg,
        "license_key": sdk.license_key,
        "original_dataset": training_data,
        "cursor": resp.get("cursor", 0),
        "partial_results": resp.get("partial_results", []),
        "partial_metrics": resp.get("partial_metrics", {}),
        "advanced": {"max_seeds_to_process": 8}
    })
```

---

## ðŸ“Š Rate Limits

|      Tier    | Evaluations/Day |               atch Size                 |        Seeds Preview       |
|--------------|-----------------|-----------------------------------------|----------------------------|
| Community    |       100       | âŒ Not available                        | Configurable (default 10) |
| Professional |      10,000     | âœ… Up to BATCH_MAX_ITEMS (default 1000) |         Unlimited         |
| Enterprise   |     Unlimited   | âœ… Up to BATCH_MAX_ITEMS (default 1000) |         Unlimited         |

---

## ðŸ†š Tier Comparison

|             Feature        | Community     | Professional |    Enterprise   |
|----------------------------|---------------|--------------|-----------------|
| Single evaluation          | âœ… (100/day) | âœ… (10k/day) | âœ… (unlimited) |
| Batch evaluation           |      âŒ      |      âœ…      |       âœ…       |
| Performance metrics        |      âŒ      |      âœ…      | âœ… (enhanced)  |
| pipeline_generate_critical |   Demo only   |      âŒ      |    âœ… Full     |
| pipeline_full_cycle        |      âŒ      |      âŒ      |       âœ…       |
| Curriculum learning        |      âŒ      |      âŒ      |       âœ…       |
| Non-linear evaluation      |      âŒ      |      âœ…      |       âœ…       |
| Distillation               |      âŒ      |      âœ…      |       âœ…       |
| Surrogate export           |      âŒ      |      âŒ      |       âœ…       |
| Redis caching              |      âŒ      |      âœ…      |       âœ…       |

---

## ðŸ“– API Reference

### Initialization
```python
AMLSDK(tier='community'|'professional'|'enterprise', license_key=None, base_url=None, timeout=30)
```

### Core Methods
- `evaluate(data, config)` - Single evaluation
- `batch_evaluate(data_points, config)` - Batch processing (Pro/Ent)
- `get_metrics()` - Performance metrics (Pro/Ent)

### Pipeline Methods
- `pipeline_identify_seeds(dataset, config, top_k_percent=0.1)`
- `pipeline_generate_critical(config, original_dataset, **kwargs)` (Enterprise)
- `pipeline_full_cycle(dataset, config, max_iterations=5)` (Enterprise)

### Distillation Methods (Pro/Ent)
- `distill_train(config, samples=1000, batch_size=100)`
- `distill_predict(data, config) -> float`
- `distill_export()` (Enterprise only)

---

## ðŸ”§ Environment Variables

|           Variable         |       Description         | Default |
|----------------------------|---------------------------|---------|
| `CRITICAL_MAX_SECS`        | Time budget per operation |   24s   |
| `REDIS_TIMEOUT_SECS`       | Redis timeout             |   3s    |
| `REDIS_RETRIES`            | Redis retry attempts      |   0     |
| `DISABLE_ADAPTIVE_METRICS` | Skip heavy Redis I/O      |   true  |

---

## ðŸ“ž Support

- **Documentation**: https://docs.dsf-aml.ai
- **Issues**: https://github.com/dsf-aml/sdk/issues
- **Enterprise**: contacto@softwarefinanzas.com.co

---

## ðŸ“„ License

MIT for Community tier. Professional/Enterprise under commercial terms.

Â© 2025 DSF AML SDK â€” Adaptive ML powered by Knowledge Distillation

---

# DSF AML SDK (EspaÃ±ol)

Reduce los datos de entrenamiento ML en **70â€“90%** mediante evaluaciÃ³n adaptativa y destilaciÃ³n de conocimiento.  
Destila un modelo sustituto y ejecuta inferencias **~10Ã— mÃ¡s rÃ¡pido** con huella mÃ­nima.

---

## ðŸš€ Â¿Por quÃ© DSF AML?

El ML tradicional necesita miles de etiquetas y largos ciclos de entrenamiento. DSF AML codifica **reglas del dominio** en una fÃ³rmula ligera y (Pro/Ent) las destila en un **sustituto rÃ¡pido**, permitiendo entregar modelos precisos con **mÃ­nimos datos** y **menores costos de infraestructura**.

---

## ðŸ“š Conceptos Clave

- **ConfiguraciÃ³n como reglas**: Por campo `default`, `importance`, `sensitivity`, opcional `string_floor`
- **EvaluaciÃ³n adaptativa**: Calcula un score normalizado para cualquier elemento
- **Foco en fronteras de decisiÃ³n**: Genera/recolecta datos cerca del umbral
- **DestilaciÃ³n de conocimiento** (Pro/Ent): Entrena un sustituto lineal para inferencia sub-milisegundo

> **Modo no lineal (Pro/Ent):** El backend espera  
> `data['adjustments_values'] = { field_name: { adjustment_name: value[-1..1] } }`

---

## ðŸ“¦ InstalaciÃ³n

```bash
pip install dsf-aml-sdk
```

Opcionalmente apunta el SDK a tu backend:

```python
import os
from dsf_aml_sdk import AMLSDK

sdk = AMLSDK(
    base_url=os.getenv("DSF_AML_BASE_URL"),  # ej: https://tu-app-vercel.vercel.app
    tier="community"
)
```

---

## ðŸŽ¯ Inicio RÃ¡pido

### Community

```python
from dsf_aml_sdk import AMLSDK

sdk = AMLSDK()  # por defecto tier community

config = (sdk.create_config()
    .add_field('model_accuracy',  default=0.95, importance=2.5, sensitivity=2.0)
    .add_field('training_epochs', default=100,  importance=1.8, sensitivity=1.5)
    .add_field('validation_loss', default=0.05, importance=2.2, sensitivity=2.5)
    .add_field('model_name',      default='baseline', importance=1.0, string_floor=0.1)
)

item = {'model_accuracy': 0.96, 'training_epochs': 105, 'validation_loss': 0.048}
res = sdk.evaluate(item, config)
print(f"Score: {res.score:.3f}")
```

### Professional

```python
from dsf_aml_sdk import AMLSDK

sdk = AMLSDK(license_key='PRO-2026-12-31-XXXX', tier='professional')

cfg = (sdk.create_config()
    .add_field('model_accuracy', 0.9, 2.0, 2.0)
    .add_field('training_epochs', 100, 1.8, 1.5)
    .add_field('validation_loss', 0.05, 2.2, 2.5)
)

# EvaluaciÃ³n batch (hasta BATCH_MAX_ITEMS; por defecto 1000)
experimentos = [
    {'model_accuracy': 0.92, 'training_epochs': 50,  'validation_loss': 0.08},
    {'model_accuracy': 0.95, 'training_epochs': 100, 'validation_loss': 0.05},
]
scores = sdk.batch_evaluate(experimentos, cfg)

# MÃ©tricas (despuÃ©s de al menos una evaluaciÃ³n)
metrics = sdk.get_metrics()
```

### Enterprise: Pipeline + DestilaciÃ³n

```python
from dsf_aml_sdk import AMLSDK

sdk = AMLSDK(license_key='ENT-2026-12-31-XXXX', tier='enterprise')

datos_entrenamiento = [
    {'model_accuracy': 0.92, 'training_epochs': 120, 'validation_loss': 0.06},
    {'model_accuracy': 0.88, 'training_epochs':  80, 'validation_loss': 0.07},
    # ...
]

# 1) Identificar semillas
seeds = sdk.pipeline_identify_seeds(dataset=datos_entrenamiento, config=cfg, top_k_percent=0.1)

# 2) Generar variantes crÃ­ticas
gen = sdk.pipeline_generate_critical(config=cfg, original_dataset=datos_entrenamiento)

# 3) Ciclo completo
full = sdk.pipeline_full_cycle(dataset=datos_entrenamiento, config=cfg, max_iterations=3)

# 4) DestilaciÃ³n
sdk.distill_train(cfg, samples=1000, batch_size=100, seed=42)
score_rapido = sdk.distill_predict(datos_entrenamiento[0], cfg)
artifact = sdk.distill_export()  # Solo Enterprise
```

---

## ðŸ’¡ Casos de Uso

### 1. CuraciÃ³n de Datos: Conserva Solo lo Importante
RetÃ©n el **10â€“30% de muestras mÃ¡s informativas** cerca de las fronteras de decisiÃ³n, descarta duplicados y casos fÃ¡ciles.

```python
# Empiezas con 10,000 muestras
result = sdk.pipeline_full_cycle(dataset=datos_completos, config=config, max_iterations=3)
print(f"Reducido: {len(datos_completos)} â†’ {result['final_size']} muestras")
# Salida tÃ­pica: "Reducido: 10000 â†’ 1500 muestras" (85% reducciÃ³n)
```

### 2. Pruebas de EstrÃ©s de PolÃ­ticas: Genera Casos Borde
Crea escenarios frontera para probar polÃ­ticas ML (ej: compromisos precisiÃ³n vs latencia).

```python
# Genera variantes crÃ­ticas alrededor del umbral de decisiÃ³n
seeds = sdk.pipeline_identify_seeds(datos_produccion, config, top_k_percent=0.1)
casos_borde = sdk.pipeline_generate_critical(
    config=config,
    original_dataset=datos_produccion,
    epsilon=0.05  # banda ajustada alrededor del umbral
)
# Usa casos_borde para pruebas de estrÃ©s de tus modelos
```

### 3. Despliegue en Edge: Inferencia Sub-milisegundo
Despliega un sustituto lineal para **inferencia <1ms en CPU** sin GPUs.

```python
# Entrena sustituto desde tu modelo complejo
sdk.distill_train(config, samples=1000)

# Despliega con huella mÃ­nima
def inferencia_edge(muestra):
    return sdk.distill_predict(muestra, config)  # <1ms en CPU

# Benchmark: tÃ­picamente 10-50Ã— mÃ¡s rÃ¡pido que el modelo original
```

### 4. Control de Costos: 70â€“90% Menos Datos de Entrenamiento
El pipeline Evaluar â†’ Reducir â†’ Entrenar reduce dramÃ¡ticamente los costos en la nube.

```python
# Enfoque tradicional: $1000/mes para 100K muestras
costo_original = calcular_costo_entrenamiento(samples=100_000)

# Enfoque DSF: EnfÃ³cate en 10K muestras crÃ­ticas
datos_reducidos = sdk.pipeline_full_cycle(dataset, config)
costo_nuevo = calcular_costo_entrenamiento(samples=len(datos_reducidos['final_samples']))

print(f"Ahorro: {(1 - costo_nuevo/costo_original)*100:.0f}%")
# Salida tÃ­pica: "Ahorro: 87%"
```

### Resumen
**DSF AML entrega:**
- **Menos datos**: ReducciÃ³n del 70â€“90% preservando fronteras de decisiÃ³n
- **Entrenamiento mÃ¡s rÃ¡pido**: Enfoque solo en muestras crÃ­ticas
- **Capacidad de sÃ­ntesis**: Genera casos borde desde datos semilla mÃ­nimos
- **Listo para producciÃ³n**: Manejo de resultados parciales para entornos serverless

---

## â±ï¸ Manejo de Resultados Parciales (Compatible con Serverless)

Las operaciones largas pueden retornar `status: "partial"` con un cursor y payload parcial opcional. Re-envÃ­a esos valores para continuar sin timeouts.

### GeneraciÃ³n CrÃ­tica (Enterprise)

```python
resp = sdk.pipeline_generate_critical(cfg, original_dataset=datos_entrenamiento, k_variants=3)

while isinstance(resp, dict) and resp.get("status") == "partial":
    resp = sdk._make_request("", {
        "action": "pipeline_generate_critical",
        "config": cfg,
        "license_key": sdk.license_key,
        "original_dataset": datos_entrenamiento,
        "cursor": resp.get("cursor", 0),
        "partial_results": resp.get("partial_results", []),
        "partial_metrics": resp.get("partial_metrics", {}),
        "advanced": {"max_seeds_to_process": 8}
    })
```

---

## ðŸ“Š LÃ­mites de Tasa

| Tier         | Evaluaciones/DÃ­a |                  TamaÃ±o Batch               |     Vista Previa Semillas     |
|--------------|------------------|---------------------------------------------|-------------------------------|
| Community    |       100        |               âŒ No disponible              | Configurable (por defecto 10) |
| Professional |      10,000      | âœ… Hasta BATCH_MAX_ITEMS (por defecto 1000) |           Ilimitado           |
| Enterprise   |    Ilimitado     | âœ… Hasta BATCH_MAX_ITEMS (por defecto 1000) |           Ilimitado           |

---

## ðŸ†š ComparaciÃ³n de Tiers

| CaracterÃ­stica             |     Community    |  Professional |   Enterprise   |
|----------------------------|------------------|---------------|----------------|
| EvaluaciÃ³n individual      |    âœ… (100/dÃ­a)  | âœ… (10k/dÃ­a) | âœ… (ilimitado) |
| EvaluaciÃ³n batch           |        âŒ        |       âœ…     |       âœ…       |
| MÃ©tricas de rendimiento    |        âŒ        |       âœ…     | âœ… (mejoradas) |
| pipeline_generate_critical |     Solo demo    |        âŒ    |  âœ… Completo   |
| pipeline_full_cycle        |        âŒ        |       âŒ     |       âœ…       |
| Aprendizaje curricular     |        âŒ        |       âŒ     |       âœ…       |
| EvaluaciÃ³n no lineal       |        âŒ        |       âœ…     |       âœ…       |
| DestilaciÃ³n                |        âŒ        |       âœ…     |       âœ…       |
| Exportar sustituto         |        âŒ        |       âŒ     |       âœ…       |
| Cache Redis                |        âŒ        |       âœ…     |       âœ…       |

---

## ðŸ“– Referencia API

### InicializaciÃ³n
```python
AMLSDK(tier='community'|'professional'|'enterprise', license_key=None, base_url=None, timeout=30)
```

### MÃ©todos Principales
- `evaluate(data, config)` - EvaluaciÃ³n individual
- `batch_evaluate(data_points, config)` - Procesamiento batch (Pro/Ent)
- `get_metrics()` - MÃ©tricas de rendimiento (Pro/Ent)

### MÃ©todos de Pipeline
- `pipeline_identify_seeds(dataset, config, top_k_percent=0.1)`
- `pipeline_generate_critical(config, original_dataset, **kwargs)` (Enterprise)
- `pipeline_full_cycle(dataset, config, max_iterations=5)` (Enterprise)

### MÃ©todos de DestilaciÃ³n (Pro/Ent)
- `distill_train(config, samples=1000, batch_size=100)`
- `distill_predict(data, config) -> float`
- `distill_export()` (Solo Enterprise)

---

## ðŸ”§ Variables de Entorno

| Variable                   |            DescripciÃ³n              | Por Defecto |
|----------------------------|-------------------------------------|-------------|
| `CRITICAL_MAX_SECS`        | Presupuesto de tiempo por operaciÃ³n |     24s     |
| `REDIS_TIMEOUT_SECS`       | Timeout de Redis                    |     3s      |
| `REDIS_RETRIES`            | Reintentos de Redis                 |      0      |
| `DISABLE_ADAPTIVE_METRICS` | Omitir I/O pesado de Redis          |     true    |

---

## ðŸ“ž Soporte

- **DocumentaciÃ³n**: https://docs.dsf-aml.ai
- **Issues**: https://github.com/dsf-aml/sdk/issues
- **Enterprise**: contacto@softwarefinanzas.com.co

---

## ðŸ“„ Licencia

MIT para tier Community. Professional/Enterprise bajo tÃ©rminos comerciales.

Â© 2025 DSF AML SDK â€” ML Adaptativo impulsado por DestilaciÃ³n de Conocimiento
