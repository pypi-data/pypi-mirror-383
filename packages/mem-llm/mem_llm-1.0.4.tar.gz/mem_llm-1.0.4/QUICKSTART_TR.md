# âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§ - Mem-Agent

5 dakikada Mem-Agent'Ä± Ã§alÄ±ÅŸtÄ±rmaya baÅŸlayÄ±n!

## ğŸ¯ AdÄ±m 1: Ollama Kurulumu

### Windows
```bash
# Ollama web sitesinden indirin ve kurun
# https://ollama.ai/download/windows

# Kurulum sonrasÄ± terminal aÃ§Ä±n ve kontrol edin:
ollama --version
```

### Mac/Linux
```bash
# Tek komutla kurulum:
curl https://ollama.ai/install.sh | sh

# Veya Homebrew ile (Mac):
brew install ollama
```

## ğŸš€ AdÄ±m 2: Ollama Servisini BaÅŸlatÄ±n

```bash
# Yeni bir terminal aÃ§Ä±n ve servisi baÅŸlatÄ±n:
ollama serve
```

**Not**: Bu terminal aÃ§Ä±k kalmalÄ±! BaÅŸka bir terminal aÃ§arak devam edin.

## ğŸ“¦ AdÄ±m 3: Model Ä°ndirin

```bash
# Granite4 tiny modelini indirin (yaklaÅŸÄ±k 2.5 GB)
ollama pull granite4:tiny-h

# Ä°ndirme tamamlandÄ±ÄŸÄ±nda modeli kontrol edin:
ollama list
```

Ã‡Ä±ktÄ±da `granite4:tiny-h` gÃ¶rmelisiniz.

## ğŸ”§ AdÄ±m 4: Python BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± YÃ¼kleyin

```bash
# Memory LLM dizinine gidin
cd "Memory LLM"

# Gereksinimleri yÃ¼kleyin
pip install -r requirements.txt

# VEYA geliÅŸtirme modu iÃ§in:
pip install -e .
```

## âš™ï¸ AdÄ±m 4.5: Config DosyasÄ±nÄ± HazÄ±rlayÄ±n (Opsiyonel)

Config dosyasÄ± kullanmadan da baÅŸlayabilirsiniz, ancak geliÅŸmiÅŸ Ã¶zellikler iÃ§in Ã¶nerilir:

```bash
# Ã–rnek config'i kopyalayÄ±n
cp config.yaml.example config.yaml

# Windows iÃ§in:
copy config.yaml.example config.yaml
```

**Basit baÅŸlangÄ±Ã§ config'i (config.yaml):**

```yaml
usage_mode: "personal"

llm:
  model: "granite4:tiny-h"
  base_url: "http://localhost:11434"

memory:
  backend: "json"
```

**ğŸ’¡ Not:** Config kullanmadan da Ã§alÄ±ÅŸÄ±r! Detaylar iÃ§in `docs/CONFIG_GUIDE.md`

## âœ… AdÄ±m 5: Ä°lk Testinizi YapÄ±n

```bash
# Basit Ã¶rneÄŸi Ã§alÄ±ÅŸtÄ±rÄ±n:
python example_simple.py
```

EÄŸer her ÅŸey doÄŸruysa ÅŸÃ¶yle bir Ã§Ä±ktÄ± gÃ¶rmelisiniz:

```
ğŸ¤– Mem-Agent Basit Ã–rnek

âœ… Sistem hazÄ±r!

--- KonuÅŸma 1 ---
ğŸ‘¤: Merhaba, benim adÄ±m Ali
ğŸ¤–: [Bot cevabÄ±]

--- KonuÅŸma 2 ---
ğŸ‘¤: DÃ¼n sana pizza sipariÅŸ etmiÅŸtim
ğŸ¤–: [Bot cevabÄ±]

--- KonuÅŸma 3 ---
ğŸ‘¤: AdÄ±mÄ± hatÄ±rlÄ±yor musun?
ğŸ¤–: [Bot Ali'yi hatÄ±rlayarak cevap verir]
```

## ğŸ‰ AdÄ±m 6: MÃ¼ÅŸteri Hizmetleri Demo

```bash
# GeliÅŸmiÅŸ Ã¶rneÄŸi Ã§alÄ±ÅŸtÄ±rÄ±n:
python example_customer_service.py
```

Bu, tam bir mÃ¼ÅŸteri hizmetleri senaryosunu simÃ¼le eder.

## ğŸ’» Kendi Kodunuzda KullanÄ±m

```python
from mem_agent import MemAgent

# 1. Agent oluÅŸtur
agent = MemAgent(model="granite4:tiny-h")

# 2. Sistem kontrolÃ¼ (opsiyonel ama Ã¶nerilen)
status = agent.check_setup()
if status['status'] != 'ready':
    print("âŒ Hata:", status)
    exit(1)

# 3. KullanÄ±cÄ± ayarla
agent.set_user("kullanici_id")

# 4. Sohbet et
response = agent.chat("Merhaba!")
print(response)

# 5. Metadata ile kayÄ±t
response = agent.chat(
    "SipariÅŸ #12345 nerede?",
    metadata={
        "order_number": "#12345",
        "topic": "sipariÅŸ sorgu"
    }
)
print(response)

# 6. Bellek Ã¶zeti
summary = agent.memory_manager.get_summary("kullanici_id")
print(summary)
```

## ğŸ› Sorun mu YaÅŸÄ±yorsunuz?

### "Connection refused" hatasÄ±
```bash
# Ollama servisinin Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun:
ollama serve

# BaÅŸka bir terminalde test edin:
curl http://localhost:11434/api/tags
```

### "Model not found" hatasÄ±
```bash
# Modeli tekrar indirin:
ollama pull granite4:tiny-h

# Model listesini kontrol edin:
ollama list
```

### Import hatasÄ±
```bash
# DoÄŸru dizinde olduÄŸunuzdan emin olun:
cd "Memory LLM"

# BaÄŸÄ±mlÄ±lÄ±klarÄ± tekrar yÃ¼kleyin:
pip install -r requirements.txt
```

## ğŸ“š Sonraki AdÄ±mlar

1. âœ… `README.md` dosyasÄ±nÄ± okuyun - DetaylÄ± API dokÃ¼mantasyonu
2. âœ… `example_simple.py` kodunu inceleyin - Basit Ã¶rnekler
3. âœ… `example_customer_service.py` kodunu inceleyin - Ä°leri seviye Ã¶rnekler
4. âœ… Kendi use case'iniz iÃ§in Ã¶zelleÅŸtirin

## ğŸ¯ Ã–nerilen KullanÄ±m Ã–rnekleri

### 1. Chatbot OluÅŸturma
```python
agent = MemAgent()
agent.set_user("chat_user")

while True:
    user_input = input("Siz: ")
    if user_input.lower() == 'Ã§Ä±kÄ±ÅŸ':
        break
    
    response = agent.chat(user_input)
    print(f"Bot: {response}")
```

### 2. MÃ¼ÅŸteri Destek Sistemi
```python
def handle_support_ticket(user_id, message, ticket_no):
    agent = MemAgent()
    agent.set_user(user_id)
    
    response = agent.chat(
        message,
        metadata={
            "ticket": ticket_no,
            "timestamp": datetime.now().isoformat()
        }
    )
    
    return response
```

### 3. KiÅŸisel Asistan
```python
agent = MemAgent()
agent.set_user("personal_user")

# KullanÄ±cÄ± tercihlerini kaydet
agent.update_user_info({
    "name": "Ali",
    "preferences": {
        "language": "Turkish",
        "notification_time": "09:00"
    }
})

# Daha sonra bu bilgileri kullan
response = agent.chat("BugÃ¼n ne yapmam gerek?")
```

## ğŸ”— FaydalÄ± Linkler

- ğŸ“– [Tam DokÃ¼mantasyon](README.md)
- ğŸŒ [Ollama Resmi Site](https://ollama.ai/)
- ğŸ’¬ [GitHub Issues](https://github.com/yourusername/mem-agent/issues)

---

**BaÅŸarÄ±lar!** ğŸ‰

Herhangi bir sorunla karÅŸÄ±laÅŸÄ±rsanÄ±z README.md dosyasÄ±ndaki "Sorun Giderme" bÃ¶lÃ¼mÃ¼ne bakÄ±n.

