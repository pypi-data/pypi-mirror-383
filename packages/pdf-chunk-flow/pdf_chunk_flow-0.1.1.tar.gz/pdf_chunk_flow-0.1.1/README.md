# PDF Chunk Flow

[![CI](https://github.com/facuvegaingenieer/pdf_chunk_flow/workflows/CI/badge.svg)](https://github.com/facuvegaingenieer/pdf_chunk_flow/actions)
[![PyPI version](https://badge.fury.io/py/pdf-chunk-flow.svg)](https://badge.fury.io/py/pdf-chunk-flow)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code Coverage](https://codecov.io/gh/facuvegaingenieer/pdf_chunk_flow/branch/main/graph/badge.svg)](https://codecov.io/gh/facuvegaingenieer/pdf_chunk_flow)

**PDF Chunk Flow** es un pipeline ETL (Extract, Transform, Load) profesional diseÃ±ado para procesar documentos PDF, dividirlos en chunks optimizados para embeddings y almacenarlos eficientemente en formato Parquet.

Ideal para aplicaciones de RAG (Retrieval-Augmented Generation), bÃºsqueda semÃ¡ntica, y procesamiento de documentos a gran escala.

## ğŸš€ CaracterÃ­sticas

- **ğŸ“¥ Extract**: Descarga PDFs desde URLs con manejo robusto de errores
- **âš™ï¸ Transform**: 
  - ExtracciÃ³n de texto con `pypdf`
  - DivisiÃ³n en chunks con overlap configurable
  - Optimizado para embeddings de 768 dimensiones (BERT, Sentence-Transformers)
  - Almacenamiento eficiente en formato Parquet con compresiÃ³n Snappy
- **âœ… Load**: 
  - ValidaciÃ³n exhaustiva de datos (7 checks de calidad)
  - VerificaciÃ³n de integridad
  - GeneraciÃ³n de estadÃ­sticas
- **ğŸ“Š Logging completo**: Trazabilidad end-to-end de todo el proceso
- **ğŸ§ª Tests**: 23+ tests unitarios con cobertura >90%
- **ğŸ”„ CI/CD**: GitHub Actions configurado para tests y publicaciÃ³n automÃ¡tica

## ğŸ“¦ InstalaciÃ³n

### Desde PyPI (cuando estÃ© publicado)

```bash
pip install pdf-chunk-flow
```

### Desde el repositorio

```bash
git clone https://github.com/facuvegaingenieer/pdf_chunk_flow.git
cd pdf_chunk_flow
pip install -e .
```

### Para desarrollo

```bash
git clone https://github.com/facuvegaingenieer/pdf_chunk_flow.git
cd pdf_chunk_flow
pip install -e ".[dev]"
```

## ğŸ¯ Uso RÃ¡pido

### Forma simple (recomendada)

```python
from main import MacroEtlPdfChunks

# Pipeline completo con una sola funciÃ³n
result = MacroEtlPdfChunks("https://ejemplo.com/documento.pdf")

if result:
    print(f"âœ… Archivo procesado: {result}")
else:
    print("âŒ Error en el procesamiento")
```

### Uso desde Airflow

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
from main import MacroEtlPdfChunks

def process_pdf(**context):
    pdf_url = context['params']['pdf_url']
    result = MacroEtlPdfChunks(pdf_url)
    
    if not result:
        raise Exception(f"Failed to process PDF: {pdf_url}")
    
    return result

with DAG(
    'pdf_processing',
    start_date=datetime(2025, 1, 1),
    schedule_interval='@daily',
) as dag:
    
    process_task = PythonOperator(
        task_id='process_pdf',
        python_callable=process_pdf,
        params={'pdf_url': 'https://ejemplo.com/documento.pdf'},
    )
```

### Pipeline completo (uso avanzado)

```python
from extract.extract import pdf_extractor_instance
from tranform.transform import pdf_transformer_instance
from load.load import parquet_loader_instance

# Usar las instancias pre-configuradas
pdf_path = pdf_extractor_instance.extract("https://ejemplo.com/documento.pdf")
parquet_path = pdf_transformer_instance.transform(pdf_path)
final_path = parquet_loader_instance.load(parquet_path)

print(f"âœ… Archivo procesado: {final_path}")
```

### Ejemplo con URL del Banco Macro

```python
from extract.extract import pdf_extractor
from tranform.transform import pdf_transformer
from load.load import parquet_loader

# URL sin extensiÃ³n .pdf
url = "https://www.macro.com.ar/1517360615001"

# Pipeline completo
extractor = pdf_extractor()
pdf_path = extractor.extract(url)
# â†’ Resultado: pdf/1517360615001.pdf

transformer = pdf_transformer(chunk_size=600, chunk_overlap=100)
parquet_path = transformer.transform(pdf_path)
# â†’ Resultado: parquet/1517360615001.parquet

loader = parquet_loader()
final_path = loader.load(parquet_path)
# â†’ Resultado: parquet_chunk/1517360615001.parquet
```

### Uso modular

```python
# Solo extraer PDF
from extract.extract import pdf_extractor

extractor = pdf_extractor(pdf_folder="mis_pdfs")
pdf_path = extractor.extract("https://ejemplo.com/documento.pdf")

# Solo transformar PDF existente
from tranform.transform import pdf_transformer

transformer = pdf_transformer(
    chunk_size=800,       # Personalizar tamaÃ±o
    chunk_overlap=150,    # Personalizar overlap
    output_folder="chunks"
)
parquet_path = transformer.transform("mi_documento.pdf")

# Solo validar parquet
from load.load import parquet_loader

loader = parquet_loader(output_folder="validated")
result = loader.load("mi_archivo.parquet")
```

## ğŸ“Š Estructura de Datos

Los chunks generados incluyen la siguiente metadata en formato Parquet:

| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| `chunk_id` | int | ID Ãºnico secuencial del chunk |
| `chunk_text` | str | Contenido del chunk |
| `chunk_size` | int | TamaÃ±o en caracteres |
| `start_position` | int | PosiciÃ³n inicial en el texto original |
| `end_position` | int | PosiciÃ³n final en el texto original |
| `has_overlap` | bool | Indica si tiene overlap con el chunk anterior |
| `timestamp` | str | Timestamp de creaciÃ³n (ISO 8601) |

### Ejemplo de datos

```python
import pandas as pd

df = pd.read_parquet("parquet_chunk/documento.parquet")
print(df.head())
```

```
   chunk_id  chunk_text                   chunk_size  start_position  end_position  has_overlap  timestamp
0         0  Contenido del primer chunk...        600               0           600        False  2025-10-13T...
1         1  ...parte del anterior mÃ¡s...         600             500          1100         True  2025-10-13T...
2         2  ...continuaciÃ³n con overlap         600            1000          1600         True  2025-10-13T...
```

## ğŸ¨ ConfiguraciÃ³n Ã“ptima para Embeddings

### Para BERT-base / Sentence-Transformers (768 dims)

```python
transformer = pdf_transformer(
    chunk_size=600,        # â‰ˆ180-240 tokens
    chunk_overlap=100      # â‰ˆ30-40 tokens de overlap
)
```

### Para modelos con lÃ­mite de 512 tokens

```python
transformer = pdf_transformer(
    chunk_size=500,        # â‰ˆ150-200 tokens
    chunk_overlap=100      # Mantener contexto
)
```

### Para modelos con contexto largo (>1024 tokens)

```python
transformer = pdf_transformer(
    chunk_size=1000,       # â‰ˆ300-400 tokens
    chunk_overlap=150      # Mayor overlap para mejor contexto
)
```

## ğŸ“ Estructura del Proyecto

```
pdf_chunk_flow/
â”œâ”€â”€ extract/              # MÃ³dulo de extracciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ extract.py       # Descarga de PDFs
â”œâ”€â”€ tranform/            # MÃ³dulo de transformaciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ transform.py     # Chunking y Parquet
â”œâ”€â”€ load/                # MÃ³dulo de carga/validaciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ load.py          # ValidaciÃ³n y copia
â”œâ”€â”€ contracts/           # Interfaces abstractas
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ contracts.py     # ABCs para ETL
â”œâ”€â”€ tests/               # Tests unitarios
â”‚   â”œâ”€â”€ test_extract.py
â”‚   â”œâ”€â”€ test_transform.py
â”‚   â”œâ”€â”€ test_load.py
â”‚   â””â”€â”€ conftest.py
â”œâ”€â”€ .github/workflows/   # CI/CD
â”‚   â”œâ”€â”€ ci.yml          # Tests automÃ¡ticos
â”‚   â”œâ”€â”€ publish.yml     # PublicaciÃ³n a PyPI
â”‚   â””â”€â”€ release.yml     # CreaciÃ³n de releases
â”œâ”€â”€ main.py             # Script de ejemplo
â”œâ”€â”€ pyproject.toml      # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ requirements.txt    # Dependencias
â”œâ”€â”€ README.md          # Este archivo
â”œâ”€â”€ LICENSE            # Licencia MIT
â””â”€â”€ .gitignore         # Archivos ignorados
```

## ğŸ§ª Tests

Ejecutar todos los tests:

```bash
pytest tests/
```

Con cobertura:

```bash
pytest tests/ --cov --cov-report=html
```

Tests especÃ­ficos:

```bash
pytest tests/test_extract.py -v
pytest tests/test_transform.py -v
pytest tests/test_load.py -v
```

### Cobertura actual

- **Extract**: 95%
- **Transform**: 92%
- **Load**: 96%
- **Total**: 94%

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de entorno

```bash
# Opcional: configurar carpetas por defecto
export PDF_FOLDER="mis_pdfs"
export PARQUET_FOLDER="mis_parquets"
export PARQUET_CHUNK_FOLDER="chunks_validados"
```

### Logging personalizado

```python
import logging

# Configurar nivel de logging
logging.basicConfig(
    level=logging.DEBUG,  # DEBUG, INFO, WARNING, ERROR
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

## ğŸ“ˆ Roadmap

- [x] Pipeline ETL bÃ¡sico
- [x] Tests unitarios
- [x] CI/CD con GitHub Actions
- [x] DocumentaciÃ³n completa
- [ ] PublicaciÃ³n en PyPI
- [ ] Soporte para mÃºltiples formatos (DOCX, TXT, HTML)
- [ ] Procesamiento paralelo de mÃºltiples PDFs
- [ ] CLI (Command Line Interface)
- [ ] IntegraciÃ³n con bases de datos vectoriales
- [ ] Docker container
- [ ] Dashboard de monitoreo

## ğŸ¤ Contribuir

Â¡Las contribuciones son bienvenidas! Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### GuÃ­a de desarrollo

```bash
# Clonar el repositorio
git clone https://github.com/facuvegaingenieer/pdf_chunk_flow.git
cd pdf_chunk_flow

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar en modo desarrollo
pip install -e ".[dev]"

# Ejecutar tests
pytest tests/ -v

# Verificar cobertura
pytest tests/ --cov --cov-report=html
```

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¤ Autor

**Facundo Vega**

- GitHub: [@facuvegaingenieer](https://github.com/facuvegaingenieer)
- Email: facundo.vega1234@gmail.com

## ğŸ™ Agradecimientos

- [pypdf](https://github.com/py-pdf/pypdf) - ExtracciÃ³n de texto de PDFs
- [pandas](https://pandas.pydata.org/) - ManipulaciÃ³n de datos
- [pyarrow](https://arrow.apache.org/docs/python/) - Formato Parquet
- [pytest](https://pytest.org/) - Framework de testing

## ğŸ“ Changelog

### [0.1.0] - 2025-10-13

#### AÃ±adido
- Pipeline ETL completo (Extract, Transform, Load)
- Soporte para chunking con overlap
- ValidaciÃ³n exhaustiva de parquets
- 23+ tests unitarios
- CI/CD con GitHub Actions
- DocumentaciÃ³n completa
- Logging end-to-end

## ğŸ”— Enlaces Ãštiles

- [DocumentaciÃ³n de PyPI](https://pypi.org/project/pdf-chunk-flow/)
- [Issues](https://github.com/facuvegaingenieer/pdf_chunk_flow/issues)
- [Pull Requests](https://github.com/facuvegaingenieer/pdf_chunk_flow/pulls)
- [Changelog](https://github.com/facuvegaingenieer/pdf_chunk_flow/releases)

---

**Â¿Te gusta el proyecto? Â¡Dale una â­ en [GitHub](https://github.com/facuvegaingenieer/pdf_chunk_flow)!**

