\label{sec:Conclude}

%Conclusions go here.
%% MAJOR POINT: Summarize paper
% POINT: Rationale, again
In the era of multimessenger astronomy, rapid and robust inference about candidate compact binary gravitational wave
events will be a critical science product for LIGO, as  colleagues with other instruments  perform followup and
coincident observations \cite{LIGO-2013-WhitePaper-CoordinatedEMObserving}.  
% POINT: Summary: code (see abstract)
Motivated by the need for speed, we have introduced an alternative, highly-parallelizable architecture for compact
binary parameter estimation.   
%   
First, by using a mode decomposition  ($h_{lm}$) to represent each physically distinct source and by
prefiltering the data against those modes, we can efficiently evaluate the likelihood for generic source positions and
orientations, independent of waveform length or generation time.   
% 
Second, by integrating over all observer-dependent (extrinsic) parameters and by using a purely Monte Carlo
integration strategy, we can efficiently \emph{parallelize} our calculation over the intrinsic and extrinsic space.  
%
Third, to target specific intrinsic (and extrinsic) parameters for further investigation, we ingest information provided
by the searches and \BS{}: the trigger masses and estimated sky position.  
% POINT: Conclusion: Code is fast
Using standard time-domain waveforms in a production environment, we can already fully process one event in less than 1 hour, using roughly $1000$ cores in parallel,
producing posteriors and evidence with reproducibly small statistical errors (i.e., $\lesssim 1\%$ for both).  
%
As our code has bounded runtime, almost independent of the starting frequency for the signal, a nearly-unchanged strategy could
 estimate NS-NS parameters in the aLIGO era.  

As an additional advantage,  our approach  produces both a posterior distribution and  a very accurate likelihood versus extrinsic parameters.  Unlike MCMC and nested-sampling codes, we can trivially \emph{reweight} our results, allowing the user to
reprocess the posterior using any user-specified intrinsic-parameter prior.  
%
As a result, our approach \emph{also} trivially enables several other calculations of great practical interest:
reanalysis given alternative astrophysical priors;  simutaneous analysis of multiple events, adapting the ``prior''
intrinsic (mass, tide \cite{2014arXiv1402.5156W,2013PhRvD..88d4042R}, cosmological parameter \cite{2010ApJ...725..496N,2012PhRvD..85b3535T,2012PhRvL.108i1101M}) distribution to reproduce multiple observations; and simultaneous independent constraints from
multimessenger observations. 

%% MAJOR POINT: Why this is a big deal
% POINT: Implications: Fast performance on BNS, with minimal additional cost at low frequency
%       Identified in LIGO white paper/PE technical page as high-priority



%% MAJOR POINT: Explicit dimensionality as weakness. 
%   - demonstrate being aware of other projects in PE
%   - demonstrate team player : useful for targeted goals
%   - but also demonstrate we have a plan -- this is *not* a dead end, and we *can* work with reduced-order modeling
While the alternative architecture proposed here is efficient and highly parallelizable over extrinsic parameters,
all \emph{other}  parameters are (currently) suboptimally explored.  
For example, the concrete algorithm described and implemented here adopts a \emph{fixed, low-resolution} grid to sample
 two mass dimensions.  
%
While the method described here should generalize to a few additional dimensions, substantial computational resources or
additional architectural changes (and fast waveform generation) would be needed to apply a similar technique to many higher-dimensional problems being addressed with Markov
Chain or nested sampling codes, including testing GR; self-consistent data, noise,  and glitch models;  and self-consistent
electromagnetic and gravitational wave parameter estimation.   
%% MAJOR POINT: Connect to other active projects  -- we are not an island
% POINT: Big picture
That said,  several methods have been proposed for rapid waveform interpolation, including SVD and reduced-order
methods.  In the long run, we  anticipate being able to perform Monte Carlo integration over intrinsic dimensions as
well, without being forced  to adopt the relatively ad-hoc intrinsic/extrinsic split presented here.  
%By contrast, by accelerating waveform generation, other strategies like reduced-order-quadrature may eventually accelerate
%conventional strategies by a comparable factor, allowing rapid analysis of these and other problems.    
%

% POINT: Playing well with others
To provide a complete proof-of-principle illustration of our algorithm, we developed an independent production-ready
code.  That said,  the standard \textsc{lalinference} parameter estimation library in general and existing parameter
estimation codes (\textsc{lalinference\_mcmc} and \textsc{lalinference\_nest}) could  implement some or all of the
low-level and algorithmic changes we describe.  For example, MCMC codes could implement our $h_{lm}$-based likelihood,
then de-facto
 marginalize over all extrinsic parameters by strongly favoring jumps at fixed intrinsic parameters ($\lambda$).
Any  implementation which provides accurate marginalized probabilities (e.g., $L_{\rm red}$) can be parallelized across parameter
space.  
%
% POINT: Recognize
%
We hope  that by combining paradigms and consolidating code, future parameter estimation
strategies can reach extremely low latencies, ideally of order a few minutes, when advanced detectors reach design sensitivity. 
