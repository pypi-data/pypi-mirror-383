# Modern CI workflow using uv for fast, reliable dependency management
name: TESTS Talk2KnowledgeGraphs

on:
  pull_request:
    branches: [main]
    paths:
      - "aiagents4pharma/talk2knowledgegraphs/**"
      - "pyproject.toml"
      - "uv.lock"
  workflow_dispatch:

env:
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  NVIDIA_API_KEY: ${{ secrets.NVIDIA_API_KEY }}

jobs:
  # Code quality checks
  quality-checks:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Install uv
        uses: astral-sh/setup-uv@v6

      - name: Set up Python
        run: uv python install 3.12

      - name: Install dependencies
        run: uv sync --frozen --extra dev

      - name: Run pylint
        run: uv run pylint aiagents4pharma/talk2knowledgegraphs

      - name: Run ruff linting
        run: uv run ruff check aiagents4pharma/talk2knowledgegraphs

      - name: Run bandit security scan
        run: uv run bandit -c pyproject.toml -r aiagents4pharma/talk2knowledgegraphs

      - name: Run bandit security scan with JSON output for SonarCloud
        run: |
          uv run bandit -c pyproject.toml -r aiagents4pharma/talk2knowledgegraphs -f json -o bandit-report.json || true
        continue-on-error: true

      - name: Run pylint with JSON output for SonarCloud
        run: |
          uv run pylint aiagents4pharma/talk2knowledgegraphs --output-format=json --reports=no > pylint-report.json || true
        continue-on-error: true

      - name: Upload quality reports for SonarCloud
        uses: actions/upload-artifact@v4
        with:
          name: quality-reports-talk2knowledgegraphs
          path: |
            pylint-report.json
            bandit-report.json
          retention-days: 1

  # Cross-platform testing matrix
  test-matrix:
    name: Tests
    needs: quality-checks
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-15, windows-latest]
        python-version: ["3.12"]

    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Install uv
        uses: astral-sh/setup-uv@v6

      - name: Set up Python ${{ matrix.python-version }}
        run: uv python install ${{ matrix.python-version }}

      - name: Install dependencies
        run: uv sync --frozen

      # Ollama setup for Ubuntu
      - name: Setup Ollama (Ubuntu)
        if: matrix.os == 'ubuntu-latest'
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          export PATH="/usr/local/bin:$PATH"
          echo "/usr/local/bin" >> $GITHUB_PATH
          ollama serve &
          sleep 10

      # Ollama setup for macOS
      - name: Setup Ollama (macOS)
        if: matrix.os == 'macos-15'
        run: |
          brew install ollama
          ollama serve &
          sleep 10

      # Ollama setup for Windows
      - name: Setup Ollama (Windows)
        if: matrix.os == 'windows-latest'
        shell: bash
        run: |
          curl -L https://ollama.com/download/ollama-windows-amd64.zip -o ollama-windows-amd64.zip
          mkdir -p ollama_dir
          powershell -command "Expand-Archive -Path ollama-windows-amd64.zip -DestinationPath ollama_dir -Force"
          ls -la ollama_dir/
          chmod +x ollama_dir/*
          export PATH="$PWD/ollama_dir:$PATH"
          echo "$PWD/ollama_dir" >> $GITHUB_PATH
          ./ollama_dir/ollama.exe serve &
          sleep 15

      # Pull Ollama models
      - name: Pull Ollama models (Ubuntu/macOS)
        if: matrix.os == 'ubuntu-latest' || matrix.os == 'macos-15'
        run: |
          ollama pull llama3.2:1b
          ollama pull nomic-embed-text

      - name: Pull Ollama models (Windows)
        if: matrix.os == 'windows-latest'
        shell: bash
        run: |
          export PATH="$PWD/ollama_dir:$PATH"
          ./ollama_dir/ollama.exe pull llama3.2:1b
          ./ollama_dir/ollama.exe pull nomic-embed-text

      - name: Verify Ollama setup (Ubuntu/macOS)
        if: matrix.os == 'ubuntu-latest' || matrix.os == 'macos-15'
        run: |
          ollama list

      - name: Verify Ollama setup (Windows)
        if: matrix.os == 'windows-latest'
        shell: bash
        run: |
          export PATH="$PWD/ollama_dir:$PATH"
          ./ollama_dir/ollama.exe list

      - name: Run tests with coverage
        run: |
          uv run coverage run --include=aiagents4pharma/talk2knowledgegraphs/* -m pytest --cache-clear aiagents4pharma/talk2knowledgegraphs/tests/

      - name: Generate coverage report
        run: |
          uv run coverage report -m
          uv run coverage xml

      - name: Check coverage threshold
        shell: bash
        run: |
          TOTAL_COVERAGE=$(uv run coverage report -m | awk 'END {print int($NF)}')
          if [[ $TOTAL_COVERAGE -ne 100 ]]; then
            echo "Code coverage is not 100%. Please check the coverage report."
            exit 1
          fi

      - name: Upload coverage to Codecov
        if: matrix.os == 'ubuntu-latest'
        uses: codecov/codecov-action@v5
        with:
          file: ./coverage.xml
          flags: talk2knowledgegraphs
          name: talk2knowledgegraphs-coverage
          token: ${{ secrets.CODECOV_TOKEN }}
          fail_ci_if_error: false

      - name: Upload test reports for SonarCloud
        if: matrix.os == 'ubuntu-latest'
        uses: actions/upload-artifact@v4
        with:
          name: test-reports-talk2knowledgegraphs
          path: |
            coverage.xml
          retention-days: 1
