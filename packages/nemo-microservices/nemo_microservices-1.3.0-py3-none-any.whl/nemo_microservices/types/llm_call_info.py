# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from typing import Dict, Optional

from .._models import BaseModel

__all__ = ["LlmCallInfo"]


class LlmCallInfo(BaseModel):
    id: Optional[str] = None
    """The unique prompt identifier."""

    completion: Optional[str] = None
    """The completion generated by the LLM."""

    completion_tokens: Optional[int] = None
    """The number of output tokens."""

    duration: Optional[float] = None
    """The duration in seconds."""

    finished_at: Optional[float] = None
    """The timestamp for when the LLM call finished."""

    llm_model_name: Optional[str] = None
    """The name of the model use for the LLM call."""

    prompt: Optional[str] = None
    """The prompt that was used for the LLM call."""

    prompt_tokens: Optional[int] = None
    """The number of input tokens."""

    raw_response: Optional[Dict[str, object]] = None
    """The raw response received from the LLM.

    May contain additional information, e.g. logprobs.
    """

    started_at: Optional[float] = None
    """The timestamp for when the LLM call started."""

    task: Optional[str] = None
    """The internal task that made the call."""

    total_tokens: Optional[int] = None
    """The total number of used tokens."""
