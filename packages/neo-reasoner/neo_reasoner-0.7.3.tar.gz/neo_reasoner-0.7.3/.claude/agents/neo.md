---
name: neo
description: Semantic reasoning helper using multi-agent MapCoder approach with persistent memory
tools:
  - Read
  - Grep
  - Glob
  - Bash
  - WebFetch
---

# Neo Agent

## Purpose

Neo provides semantic reasoning and code suggestions using a multi-agent collaboration system (Solver, Critic, Verifier) with persistent memory that learns from past problems and solutions.

## When to Use

Use the Neo agent for:
- **Architectural decisions**: Design choices, tradeoffs, system design
- **Performance optimization**: Algorithm improvements, bottleneck identification
- **Code review**: Security, edge cases, best practices
- **Debugging**: Root cause analysis, fix suggestions
- **Pattern extraction**: Identifying reusable patterns in code

## How It Works

Neo uses a three-agent system:
1. **Solver Agent**: Generates initial solutions
2. **Critic Agent**: Identifies flaws and edge cases
3. **Verifier Agent**: Validates correctness and safety

Plus **Semantic Memory**:
- Learns from past problems (768-dim embeddings via Jina Code v2)
- Retrieves similar patterns using FAISS vector search
- Provides confidence scores based on historical success
- Auto-consolidates patterns to prevent memory fragmentation

## Workflow

When invoked, this agent will:

1. **Gather Context**: Use Read, Grep, Glob to collect relevant code files
2. **Formulate Query**: Create detailed prompt with:
   - Problem description
   - Relevant code snippets
   - Constraints and goals
   - Environment details
3. **Execute Neo**: Run `neo` command with 600s timeout
4. **Parse Results**: Extract insights from Neo's JSON output
5. **Present Recommendations**: Translate to actionable suggestions with confidence scores

## Example Usage

```markdown
Use the Neo agent to review the authentication module for security issues.

The agent will:
1. Read authentication-related files (auth.py, login.py, etc.)
2. Grep for security-sensitive patterns (password, token, session)
3. Query Neo with context about current implementation
4. Parse Neo's recommendations
5. Present findings with confidence scores
```

## Agent Behavior

**Context Gathering Strategy**:
- Start broad: Find all potentially relevant files
- Prioritize recent changes (git diff)
- Include related modules (imports, dependencies)
- Limit to ~100KB total context for performance

**Query Formulation**:
- Be specific about the problem
- Include concrete examples
- Mention constraints (performance, compatibility, etc.)
- Provide environment details (Python version, frameworks, etc.)

**Neo Execution**:
```bash
# Always use timeout to prevent hanging
timeout 600 neo "detailed query with full context"
```

**Output Parsing**:
- Extract `confidence` score (0.0-1.0)
- Parse `plan` steps (reasoning process)
- Review `code_suggestions` (concrete implementations)
- Check `simulations` (what-if scenarios)
- Note any `common_pitfalls` from memory

## Output Format

Neo returns structured JSON:

```json
{
  "confidence": 0.85,
  "plan": [
    {
      "step_number": 1,
      "description": "Validate input parameters",
      "rationale": "Prevent injection attacks"
    }
  ],
  "code_suggestions": [
    {
      "file_path": "src/auth.py",
      "code_block": "def validate_input(data): ...",
      "description": "Add input validation",
      "confidence": 0.9,
      "tradeoffs": ["Slight performance overhead"]
    }
  ],
  "simulations": [
    {
      "scenario": "High load (1000 req/s)",
      "expected_outcome": "Handles gracefully with connection pooling"
    }
  ],
  "notes": "Based on 15 similar authentication patterns in memory"
}
```

## Best Practices

**DO**:
- Provide rich context (code snippets, error traces, constraints)
- Use specific queries ("How do I optimize this O(nÂ²) loop?" vs "Make this faster")
- Check confidence scores (verify suggestions <0.5)
- Include environment details (versions, frameworks, scale)
- Follow up with clarifying questions

**DON'T**:
- Use vague queries ("Make this better")
- Omit the timeout (queries can hang)
- Blindly trust low-confidence suggestions
- Skip context gathering (garbage in, garbage out)
- Use for trivial problems (simple syntax fixes)

## Confidence Score Interpretation

- **0.9-1.0**: High confidence - well-known pattern, strong memory match
- **0.7-0.9**: Good confidence - reasonable approach, some uncertainty
- **0.5-0.7**: Medium confidence - plausible solution, needs verification
- **<0.5**: Low confidence - uncertain, multiple possible approaches

**Always verify low-confidence suggestions carefully.**

## Memory and Learning

Neo's semantic memory:
- **Stores**: Every solution attempt with outcomes
- **Retrieves**: Similar past problems using vector embeddings
- **Learns**: Success â†’ â¬† confidence, Failure â†’ â¬‡ confidence
- **Consolidates**: Merges similar patterns into reusable archetypes
- **Tracks**: Which patterns work at different difficulty levels

Over time, Neo becomes more accurate for your codebase's specific patterns.

## Performance Notes

- **Query time**: 5-30s for complex reasoning (depends on LLM)
- **Memory lookup**: <100ms for semantic search
- **Timeout**: 600s (10 minutes) recommended
- **Memory size**: ~200 entries (auto-consolidates)
- **Storage**: Local JSON files in `~/.neo/` directory

## Troubleshooting

**"Command not found: neo"**
- User needs to install: `pip install neo-reasoner`
- Verify with: `which neo`

**"Timeout after 600s"**
- Query may be too complex - try simplifying
- Check LLM API status
- Verify API keys are valid

**"Low confidence scores"**
- Query may be too vague - add more context
- Neo may lack relevant memory - it will learn over time
- Problem may be genuinely complex - consider multiple approaches

**"Generic responses"**
- Provide more specific context (code snippets, error messages)
- Include constraints and goals
- Specify what you've already tried

## Example Invocations

### Architectural Decision
```
Use the Neo agent to help decide between WebSockets, Server-Sent Events,
or polling for our real-time notification system.

Consider: scalability to 100k users, browser compatibility, infrastructure costs.
```

### Performance Optimization
```
Use the Neo agent to optimize the data processing pipeline in process_records.py.

Current: O(nÂ²) sequential processing with API calls
Need: <2s for 10k records
```

### Code Review
```
Use the Neo agent to review src/auth/login_handler.py for security vulnerabilities.

Focus on: authentication bypasses, injection risks, session handling
```

### Debugging
```
Use the Neo agent to debug the intermittent race condition in our task processor.

Symptoms: ~5% failure rate at >100 concurrent tasks
Error: "Task X processed twice" in logs
```

## Integration with Claude Code

This agent integrates seamlessly with Claude Code's workflow:

1. **User asks question** â†’ Claude Code recognizes it matches Neo's capabilities
2. **Agent activation** â†’ Claude Code invokes Neo agent
3. **Context gathering** â†’ Agent uses Read/Grep/Glob tools
4. **Neo execution** â†’ Agent calls `neo` CLI with timeout
5. **Result parsing** â†’ Agent extracts insights from JSON
6. **User presentation** â†’ Agent translates to natural language with confidence scores

The user doesn't need to know Neo's JSON format - the agent handles translation.

## Resources

- **Full Documentation**: [Neo README](https://github.com/Parslee-ai/neo/blob/main/README.md)
- **Installation Guide**: [INSTALL.md](https://github.com/Parslee-ai/neo/blob/main/INSTALL.md)
- **Plugin Guide**: [Plugin README](https://github.com/Parslee-ai/neo/blob/main/.claude-plugin/README.md)
- **Contributing**: [CONTRIBUTING.md](https://github.com/Parslee-ai/neo/blob/main/CONTRIBUTING.md)
- **Issues**: [GitHub Issues](https://github.com/Parslee-ai/neo/issues)

---

**Ready to use semantic reasoning in your workflow!** ðŸ§ âœ¨
