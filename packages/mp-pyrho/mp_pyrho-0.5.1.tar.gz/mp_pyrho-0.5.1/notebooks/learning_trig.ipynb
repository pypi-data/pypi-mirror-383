{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level imports\n",
    "from typing import Optional\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Fourier data.\n",
    "\n",
    "Many properties of periodic systems are analyzed in reciprocal using the Fourier Transform of the data.\n",
    "The Goal of this notebook is to see if standard convolutional neural networks (CNN) architectures can be used to learn frequency-dependent properties from periodic data.\n",
    "Since the frequency-dependent properties are usually more decipherable (at least by humans) in reciprocal space, we will also see if examining the Fourier representation of the data in reciprocal space can help the the learning process in any meaningful way.\n",
    "\n",
    "As a contrived example we will assume each function is made up of a sum of randomly shifted and scaled sine waves periodic in the interval $[0,1]$ \n",
    "\n",
    "$$ f(x) = \\sum_{n}  c_n  \\sin(2 \\pi n (x - \\mu_{n})) $$\n",
    "\n",
    "Use randomized periodic data in 1D, we will try to learn a fictitious *energy* function defined as the sum of weighted sum of the sine waves frequencies squared.\n",
    "\n",
    "$$ E = \\sum_{n}  c_n^2  n ^ 2 $$\n",
    "\n",
    "This is reminiscent of the energy function of a particle in a box, where the energy is proportional to the square of the frequency of the sine wave.\n",
    "$$ E_n = \\frac{\\hbar^2 \\pi^2 n^2}{2 m L^2} $$\n",
    "\n",
    "We will see how well a CNN can learn this energy function from the periodic grid data alone and how much adding the Fourier representation of the data helps the process.\n",
    "Note that our situation is a bit more complex than the particle in a box, since we are allowing the sine waves to be shifted so the boundary condition is not longer constrained to zero at the domain boundaries.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly generated 1D data\n",
    "\n",
    "Let's first write a function that creates the $f(x)$ functions above after providing a set of parameters $c_n$ and and the x-shifts $x_{0,n}$.\n",
    "We can test the output of the function using the following parameters:\n",
    "$$ c_0 = 1,\\, c_1 = 2,\\, c_2 = 3 $$\n",
    "$$ \\mu_0 = 0.2,\\, \\mu_1 = 0.4,\\, \\mu_2 = 0.6 $$\n",
    "And plot the functions on top of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trig_function(coeff: list[float], mu: list[float]):\n",
    "    \"\"\"Return a trigonometric function of x.\n",
    "\n",
    "    c0 + c1 * sin(2 * pi * (x - μ_1)) + c2 * sin(4 * pi * (x - μ_2)) + ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coeff :\n",
    "        The coefficients c0, c1, c2, ...\n",
    "    μ_i :\n",
    "        The μ_i in the above formula.  Note that the first μ_0 is assumed \n",
    "        does not affect the output of the function.\n",
    "    \"\"\"\n",
    "    def func(x):\n",
    "        res = np.zeros_like(x)\n",
    "        for m, (c, x0n) in enumerate(zip(coeff, mu)):\n",
    "            res += c * np.cos(2 * np.pi * m * (x - x0n))\n",
    "        return res\n",
    "    return func\n",
    "\n",
    "# Test it in a plot\n",
    "x = np.linspace(0, 1, 100)\n",
    "func = get_trig_function([1,2,3], [0.2, 0.4, 0.6])\n",
    "plt.plot(x, func(x))\n",
    "plt.plot(x, 1 + 2 * np.cos(2 * np.pi * (x - 0.4)) + 3 * np.cos(4 * np.pi * (x - 0.6)), \"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random 1 D function\n",
    "def gen1D(\n",
    "    xx: npt.ArrayLike, \n",
    "    range_c: list[tuple[float, float]], \n",
    "    range_mu: list[tuple[float, float]],\n",
    "    targe_func: Optional[callable]  = None,\n",
    "    max_iter=1000):\n",
    "    \"\"\"Generate a random 1D function.\n",
    "    \n",
    "    Args:\n",
    "        xx: x values for the grid\n",
    "        range_c: range of coefficients\n",
    "        range_mu: range of μ\n",
    "        targe_func: a function that takes the list of \n",
    "            `c` and `mu` parameters and returns a scalar.\n",
    "        rand_angles: if True, randomize the phase of the FFT \n",
    "            for small (< 0.1 % of max) Fourier coefficients.\n",
    "        max_iter: maximum number of iterations to try to generate a function\n",
    "\n",
    "    Returns:\n",
    "        Data: stacked function, fft absolute value, fft phase\n",
    "        target: energy\n",
    "    \"\"\"\n",
    "    for _ in range(max_iter):\n",
    "        # generate random parameters\n",
    "        c = [np.random.uniform(*r) for r in range_c]\n",
    "        mu = [np.random.uniform(*r) for r in range_mu]\n",
    "        \n",
    "        # get the \"energy\"\n",
    "        if targe_func is None:\n",
    "            targe_func = lambda c, mu: np.sum([c * n**2 for n, c in enumerate(c)])\n",
    "        energy = targe_func(c, mu)\n",
    "        \n",
    "        # get the gridded output\n",
    "        f = get_trig_function(c, mu)\n",
    "        yy = f(xx)\n",
    "        fft_yy = np.fft.fftshift(np.fft.fft(yy))\n",
    "        fft_abs = np.abs(fft_yy)\n",
    "        fft_arg = np.angle(fft_yy)\n",
    "        \n",
    "        mask_small_abs = fft_abs < 1E-3 * np.max(fft_abs)\n",
    "        fft_arg[mask_small_abs] = np.random.uniform(-np.pi, np.pi, size=np.sum(mask_small_abs))\n",
    "        # Make sure the output is float32 to make it work with pytorch\n",
    "        yield np.stack([yy, fft_abs, fft_arg]).astype(np.float32), np.array([energy]).astype(np.float32)\n",
    "\n",
    "# DataSet \n",
    "class DS1D(torch.utils.data.IterableDataset):\n",
    "    \"\"\"A 1D dataset.\"\"\"\n",
    "    def __init__(self, x_max, gen1d_kwargs: dict = None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.x_max = x_max\n",
    "        self.xx = np.linspace(0, self.x_max, 512)\n",
    "        self.fft_xx = np.fft.fftshift(np.fft.fftfreq(self.xx.size, self.xx[1] - self.xx[0]))\n",
    "        self.gen1d_kwargs = gen1d_kwargs or {}\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # return from generator\n",
    "        yield from gen1D(xx = self.xx, **self.gen1d_kwargs)\n",
    "\n",
    "range_c = [(-1, 1),(-1, 1),(-1, 1),]\n",
    "range_mu = [(0.2, 0.5),(0.2, 0.5),(0.2, 0.5),]\n",
    "train_ds = DS1D(x_max=1, range_c=range_c, range_mu=range_mu, max_iter=10000)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=128)\n",
    "ex, ey = next(iter(train_dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy  = ex[42, 0, :]\n",
    "fft_abs = ex[42, 1, :]\n",
    "fft_arg = ex[42, 2, :]\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 10))\n",
    "ax1.plot(train_ds.xx, yy); ax1.set_title(\"yy\")\n",
    "ax2.stem(train_ds.fft_xx, fft_abs); \n",
    "ax3.plot(train_ds.fft_xx, fft_arg);\n",
    "ax1.text(0.9, 0.9, \"real_space\", transform=ax1.transAxes, ha=\"center\", va=\"top\", fontdict={\"size\": 20})\n",
    "ax2.text(0.9, 0.9, \"fft_abs\", transform=ax2.transAxes, ha=\"center\", va=\"top\", fontdict={\"size\": 20})\n",
    "ax3.text(0.9, 0.9, \"fft_arg\", transform=ax3.transAxes, ha=\"center\", va=\"top\", fontdict={\"size\": 20})\n",
    "ax2.set(xlim=(-10, 10)); ax3.set(xlim=(-10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class CNN1D(pl.LightningModule):\n",
    "    def __init__(self, nchan: int):\n",
    "        super().__init__()\n",
    "        # use gpus if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # First set of Conv->ReLU->MaxPool layers\n",
    "        self.nchan = nchan\n",
    "        \n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(self.nchan, 32, kernel_size=7),\n",
    "            torch.nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # Second set of Conv->ReLU->MaxPool layers\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(32, 32, kernel_size=7, stride=1, padding=1),\n",
    "            torch.nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.out = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3968, 128),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.Linear(64, 16),\n",
    "            torch.nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_in: torch.Tensor):\n",
    "        # only use the first channel\n",
    "        x = x_in[:, 0:self.nchan, :]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "        # output\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Use Adam optimizer.\"\"\"\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.mse_loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.mse_loss(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return {'loss': loss, 'log': {'train_loss': loss}}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.mse_loss(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "# instantiate model\n",
    "model = CNN1D(nchan=3)\n",
    "\n",
    "# A + B * sin(m * x)\n",
    "train_ds = DS1D(x_max=1, range_c=range_c, range_mu=range_mu, max_iter=1000)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64)\n",
    "test_ds = DS1D(x_max=1, range_c=range_c, range_mu=range_mu, max_iter=1000)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=64, drop_last=True)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100)\n",
    "trainer.fit(model, train_dl, test_dl);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = DS1D(x_max=1, range_c=range_c, range_mu=range_mu, max_iter=1000)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=5, drop_last=True)\n",
    "ex, ey = next(iter(test_dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(ex), ey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ex[1,1,200:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jjjjjjj16384 / 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import IterableDataset, get_worker_info\n",
    "import math\n",
    "\n",
    "class MyIterableDataset(IterableDataset):\n",
    "    '''This dataset is copied from PyTorch docs.'''\n",
    "    def __init__(self, start, end):\n",
    "        super(MyIterableDataset).__init__()\n",
    "        assert end > start, \"this example code only works with end >= start\"\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "    \n",
    "    def __iter__(self):\n",
    "        iter_start = self.start\n",
    "        iter_end = self.end\n",
    "        return iter(range(iter_start, iter_end))\n",
    "\n",
    "ds = MyIterableDataset(0, 10)\n",
    "dl = DataLoader(train_ds, batch_size=32)\n",
    "print(len(next(iter(dl)))) # should give 4, but gives 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[*iter(ds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(0, 1, 512)\n",
    "yy = np.linspace(0, 1, 512)\n",
    "XX, YY = np.meshgrid(xx, yy, indexing=\"ij\")\n",
    "plt.imshow(f1(XX, YY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrho.pgrid import PGrid\n",
    "pgrid = PGrid(grid_data=f1(XX, YY), lattice=[[1, 0], [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg2 = pgrid.get_transformed(sc_mat=[[2, 0], [0, 2]], origin=(0, 0), grid_out=(512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get randomly oriented square lattice\n",
    "def get_random_square_lattice(side_length, uc_lattice):\n",
    "    \"\"\"Return a random square lattice.\"\"\"\n",
    "    theta = np.random.uniform(0, 2 * np.pi)\n",
    "    cube_latt = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]]) * side_length\n",
    "    # return the cube lattice in terms of the unit cell lattice\n",
    "    return np.dot(cube_latt, np.linalg.inv(uc_lattice))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_random_square_lattice(1.5, np.eye(2))\n",
    "pg2 = pgrid.get_transformed(sc_mat=res, origin=(0, 0), grid_out=(512, 512))\n",
    "plt.imshow(pg2.grid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     res = get_random_square_lattice(1.5, np.eye(2))\n",
    "#     pg2 = pgrid.get_transformed(sc_mat=res, origin=(0, 0), grid_out=(512, 512))\n",
    "#     res = get_random_square_lattice(2.0, np.eye(2))\n",
    "#     pg2 = pgrid.get_transformed(sc_mat=res, origin=(0, 0), grid_out=(512, 512))\n",
    "#     fres = np.abs(np.fft.fft2(pg2.grid_data))\n",
    "#     fres = np.fft.fftshift(fres)\n",
    "#     width = 10\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 7))\n",
    "#     ax1.imshow(fres[256-width:256+width, 256-width:256+width], vmin=0, vmax=3E4)\n",
    "#     ax2.imshow(pg2.grid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl:\n",
    "    print(len(batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 7))\n",
    "# ax1.plot(xx, f)\n",
    "# ax2.plot(xx_fourier, ff)\n",
    "# ax2.set_xlim(-15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "class CNN1D(torch.nn.Module):\n",
    "    # define all the layers used in model\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool1d(2, 2)\n",
    "        self.fc1 = torch.nn.Linear(32 * 256, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 3)\n",
    "        self.dropout = torch.nn.Dropout(0.25)\n",
    "\n",
    "    # define the forward pass\n",
    "    def forward(self, x):\n",
    "        # one conv layer\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # second conv layer\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # flatten\n",
    "        x = x.view(-1, 32 * 256)\n",
    "        # dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # first dense layer\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        # second dense layer\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    # define training step"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bash function that accepts a setting i.e. SETTING=1 and replaces the setting in a given file.\n",
    "If the setting is not found, it will be appended to the end of the file.\n",
    "```bash\n",
    "function set_setting {\n",
    "    SETTING=$1\n",
    "    FILE=$2\n",
    "    if grep -q $SETTING $FILE; then\n",
    "        sed -i \"s/$SETTING.*/$SETTING/\" $FILE\n",
    "    else\n",
    "        echo $SETTING >> $FILE\n",
    "    fi\n",
    "}\n",
    "```\n",
    "\n",
    "script that accepts `-s` or `--setting` followed by the file name.\n",
    "```bash\n",
    "#!/bin/bash\n",
    "function set_setting {\n",
    "    SETTING=$1\n",
    "    VALUE=$2\n",
    "    FILE=$3\n",
    "    if grep -q $SETTING $FILE; then\n",
    "        sed -i \"s/$SETTING.*/$SETTING = $VALUE/\" $FILE\n",
    "    else\n",
    "        echo $SETTING >> $FILE\n",
    "    fi\n",
    "}\n",
    "\n",
    "SETTING=$1\n",
    "VALUE=$2\n",
    "FILE=$3\n",
    "\n",
    "set_setting $SETTING $FILE\n",
    "```\n",
    "\n",
    "```bash\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp",
   "language": "python",
   "name": "mp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d6ae331a7941ec26e1f71fb3e3784fd6821e9558b545b35bff0f95d1fd9faf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
