{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7775ea91-20e8-4bcf-88ec-d991ec47fd27",
   "metadata": {},
   "source": [
    "# Roving oddball\n",
    "\n",
    "Here we will follow the methods section from [Canales-Johnson et al. (2021)](https://doi.org/10.1523/JNEUROSCI.0367-21.2021). We chose this because it's recent research, because it was one of the first hits on Scopus, and because it's open access. We will go over this section bit by bit and recreate the stimuli.\n",
    "\n",
    "Here's the relevant section:\n",
    "\n",
    "> \"We adopted a roving oddball paradigm (Cowan et al., 1993; Haenschel et al., 2005; Garrido et al., 2008). The trains of 3, 5, or 11 repetitive single tones of 20 different frequencies (250–6727 Hz with intervals of one-quarter octave) were pseudorandomly presented. Tones were identical within each tone train but differed between tone trains (Fig. 1A). Because tone trains followed on from one another continuously, the first tone of a train was considered to be an unexpected deviant tone, because it was of a different frequency than that of the preceding train. The final tone was considered to be an expected standard tone because it was preceded by several repetitions of this same tone. To avoid analytical artifacts stemming from differences in the number of standard and deviant stimuli, we considered only the last tone of a train as standard. There were 240 changes from standard to deviant tones in a single recording session. Pure sinusoidal tones lasted 64 ms (7 ms rise/fall), and stimulus onset asynchrony was 503 ms. Stimulus presentation was controlled by MATLAB (MathWorks) using the Psychophysics Toolbox extensions (Brainard, 1997; Pelli, 1997; Kleiner et al., 2007). Tones were presented through two audio speakers (Fostex) with an average intensity of 60 dB SPL around the ear of the animal.\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "44324624",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Imports and random number generator\n",
    "-----------------------------------\n",
    "Before we start, let's import the necessary classes from *thebeat* and *NumPy*, and make a :py:class:`numpy.random.Generator` object with a seed. If you are not familiar with *NumPy* random generators and they confuse you, please refer to the `NumPy manual <https://numpy.org/doc/stable/reference/random/index.html#random-sampling-numpy-random>`_.\n",
    "\n",
    "We use a chosen `seed <https://en.wikipedia.org/wiki/Random_seed>`_ so you we will get the same output as we."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58808a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thebeat import Sequence, SoundStimulus, SoundSequence\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efed48",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# We suppress warnings, but let's hide that to avoid confusion\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bf6281b",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Summary\n",
    "-------\n",
    "\n",
    "    \"The trains of 3, 5, or 11 repetitive single tones of 20 different frequencies (250–6727 Hz with intervals of one-quarter octave) were pseudorandomly presented. Tones were identical within each tone train but differed between tone trains (Fig. 1A). [. . .] Pure sinusoidal tones lasted 64 ms (7 ms rise/fall), and stimulus onset asynchrony was 503 ms.\"\n",
    "\n",
    "    \n",
    "So, we create 20 stimuli with the given frequencies, and make trains with them that are either 3, 5, or 11 tones long.\n",
    "\n",
    "*********"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfcbf8db",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Creating the Sequences\n",
    "----------------------\n",
    "Most of the time, it's conceptually the easiest to start with the :py:class:`~thebeat.core.Sequence` object(s). Here, there will be three (with 3, 5, and 11 events). The sequences are isochronous and the inter-onset interval is 503 milliseconds.\n",
    "\n",
    "Importantly, we will want to be able to join the sequences together at the end so we get one long train of sounds. Normally, a sequence of 3 events will have 2 inter-onset intervals (IOIs). Why that is we'll quickly visualize by plotting a simple sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Sequence.generate_isochronous(n_events=3, ioi=500)\n",
    "seq.plot_sequence(figsize=(4, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb15a90",
   "metadata": {},
   "source": [
    "As you can see, the IOIs are the intervals *between* the events, meaning that for *n* events we have *n-1* IOIs.\n",
    "\n",
    "If we were to join sequences like these together, the final sound of a sequence and the first sound of the next sequence would coincide. To fix this, we can use the ``end_with_interval=True`` flag.\n",
    "\n",
    "So let's create the sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_3 = Sequence.generate_isochronous(n_events=3, ioi=503, end_with_interval=True)\n",
    "seq_5 = Sequence.generate_isochronous(n_events=5, ioi=503, end_with_interval=True)\n",
    "seq_11 = Sequence.generate_isochronous(n_events=11, ioi=503, end_with_interval=True)\n",
    "# And add them to a list we'll call sequences\n",
    "sequences = [seq_3, seq_5, seq_11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a05a3",
   "metadata": {},
   "source": [
    "Now, these sequences look like this, and can thus be joined together later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_3.plot_sequence(figsize=(4, 2));"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6390d59d",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Creating the stimuli\n",
    "--------------------\n",
    "Next, we'll create the :py:class:`~thebeat.core.SoundStimulus` objects, which will contain the sounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an array that contains the 20 frequencies we'll use. We'll use numpy.linspace for that.\n",
    "freqs = np.linspace(start=250, stop=6727, num=20)\n",
    "print(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16abdfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over those frequencies, and create a list with generated SoundStimulus sound objects\n",
    "stimuli = []\n",
    "for freq in freqs:\n",
    "    stim = SoundStimulus.generate(freq=freq, duration_ms=64, onramp_ms=7, offramp_ms=7)\n",
    "    stimuli.append(stim)\n",
    "\n",
    "# We now have a list of Stimulus objects. Remember that they all have different frequencies\n",
    "print(stimuli)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c781a6ce",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Creating the SoundSequences\n",
    "---------------------------\n",
    "We will now create :py:class:`~thebeat.core.SoundSequence` objects, which will basically be the trials.\n",
    "\n",
    "So, following the method section we need to combine the 20 stimuli we created above with the 3 different sequences, i.e. 60 combinations. That's easily done using a nested for-loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a740544",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = []\n",
    "\n",
    "for seq in sequences:\n",
    "    for stim in stimuli:\n",
    "        trial = SoundSequence(stim, seq)\n",
    "        trials.append(trial)\n",
    "\n",
    "# Confirm there's 60:\n",
    "print(f\"We have {len(trials)} trials\")\n",
    "\n",
    "# Let's plot one of the trials to see what they look like:\n",
    "trials[2].plot_waveform();"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef3322b1",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Creating the trains\n",
    "-------------------\n",
    "Finally, we shuffle all combinations and join them using the plus operator to form one (very) long train of trials. For this example, we are not going to create a train using all trials; that would be a bit too long to plot or save etc. So we here only join the first 10 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1878122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the trials (we created the rng object all the way at the beginning of this tutorial)\n",
    "rng.shuffle(trials)\n",
    "\n",
    "# Initialize the train by getting the first Sequence\n",
    "train = trials[0]\n",
    "\n",
    "# Then we add to that train the next 9\n",
    "for i in range(1,10):\n",
    "    train = train + trials[i]\n",
    "\n",
    "# Let's see what it looks like\n",
    "train.plot_sequence(title=\"Stimulus train event plot\", figsize=(12, 2));\n",
    "train.plot_waveform(title=\"Stimulus train waveform\", figsize=(12, 2));\n",
    "\n",
    "# If you want, you can save the wav or play it (both of which we'll not do here)\n",
    "\n",
    "#train.write_wav('train.wav')\n",
    "#train.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can listen to the sound here. You can ignore this code, it's only for this website.\n",
    "# In your Python editor you would simply use train.play()\n",
    "from IPython.display import Audio\n",
    "Audio(data=train.samples, rate=train.fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f981d",
   "metadata": {},
   "source": [
    "## Code summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thebeat.core import Sequence, SoundStimulus, SoundSequence\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=123)\n",
    "\n",
    "seq_3 = Sequence.generate_isochronous(n_events=3, ioi=503, end_with_interval=True)\n",
    "seq_5 = Sequence.generate_isochronous(n_events=5, ioi=503, end_with_interval=True)\n",
    "seq_11 = Sequence.generate_isochronous(n_events=11, ioi=503, end_with_interval=True)\n",
    "sequences = [seq_3, seq_5, seq_11]\n",
    "\n",
    "freqs = np.linspace(start=250, stop=6727, num=20)\n",
    "\n",
    "trials = []\n",
    "\n",
    "for seq in sequences:\n",
    "    for stim in stimuli:\n",
    "        trial = SoundSequence(stim, seq)\n",
    "        trials.append(trial)\n",
    "\n",
    "rng.shuffle(trials)\n",
    "\n",
    "train = trials[0]\n",
    "for i in range(1, 60):\n",
    "    train = train + trials[i]\n",
    "\n",
    "#train.write_wav('train.wav')\n",
    "#train.play()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Metagegevens bewerken",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
