{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computation\n",
    "\n",
    "This notebook describes how to use LightCurveLynx to perform parallel computation. \n",
    "\n",
    "The core simulation function of the model can take a `concurrent.futures.Executor` object and use that to distribute the computation over multiple processes. This object can be a built in parallelization method, such as `ThreadPoolExecutor` or `ProcessPoolExecutor`, or other libraries, such as Dask.\n",
    "\n",
    "Each process will load a full version of all the data, so they may be memory intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcurvelynx.astro_utils.passbands import PassbandGroup\n",
    "from lightcurvelynx.models.basic_models import ConstantSEDModel\n",
    "from lightcurvelynx.obstable.opsim import OpSim\n",
    "from lightcurvelynx.simulate import simulate_lightcurves\n",
    "\n",
    "# Usually we would not hardcode the path to the passband files, but for this demo we will use a relative path\n",
    "# to the test data directory so that we do not have to download the files.\n",
    "table_dir = \"../../tests/lightcurvelynx/data/passbands\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite Data\n",
    "\n",
    "We start by loading the standard information that we need for any simulation:\n",
    "\n",
    "  * An `ObsTable` that includes the surveyâ€™s pointing and noise information.\n",
    "  * A `PassbandGroup` for that survey.\n",
    "\n",
    "We start by creating a toy survey that includes pointings at two locations (0.0, 10.0) and (180.0, -10.0) in the \"g\" and \"r\" bands and loading the passband group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata1 = {\n",
    "    \"time\": [0.0, 1.0, 2.0, 3.0],\n",
    "    \"ra\": [0.0, 0.0, 180.0, 180.0],\n",
    "    \"dec\": [10.0, 10.0, -10.0, -10.0],\n",
    "    \"filter\": [\"g\", \"r\", \"g\", \"r\"],\n",
    "    \"zp\": [5.0, 6.0, 7.0, 8.0],\n",
    "    \"seeing\": [1.12, 1.12, 1.12, 1.12],\n",
    "    \"skybrightness\": [20.0, 20.0, 20.0, 20.0],\n",
    "    \"exptime\": [29.2, 29.2, 29.2, 29.2],\n",
    "    \"nexposure\": [2, 2, 2, 2],\n",
    "}\n",
    "obstable1 = OpSim(obsdata1)\n",
    "\n",
    "passband_group1 = PassbandGroup.from_preset(\n",
    "    preset=\"LSST\",\n",
    "    table_dir=table_dir,\n",
    "    filters=[\"g\", \"r\", \"i\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Next we create a model from which to simulate observations. We define a model and its parameters as we would with any other simulation.  Here we use a constant SED model (same value for all times and wavelengths). We place the object at (0.0, 10.0) so it is observed by some of the pointings from each survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConstantSEDModel(brightness=100.0, t0=0.0, ra=0.0, dec=10.0, redshift=0.0, node_label=\"my_star\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "\n",
    "The only change in running the simulation in parallel is that we create a `ProcessPoolExecutor` object and pass that to the simulation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    results = simulate_lightcurves(\n",
    "        model=model,\n",
    "        num_samples=10_000,\n",
    "        obstable=obstable1,\n",
    "        passbands=passband_group1,\n",
    "        obstable_save_cols=[\"zp_nJy\"],\n",
    "        executor=executor,\n",
    "        batch_size=100,\n",
    "    )\n",
    "\n",
    "print(f\"Generated {len(results)} light curves\")\n",
    "print(results[\"lightcurve\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not provide an executor object, but rather a number of jobs, we automatically create and manage the `ProcessPoolExecutor`. Here we run the simulation on 4 processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simulate_lightcurves(\n",
    "    model=model,\n",
    "    num_samples=10_000,\n",
    "    obstable=obstable1,\n",
    "    passbands=passband_group1,\n",
    "    obstable_save_cols=[\"zp_nJy\"],\n",
    "    num_jobs=4,\n",
    "    batch_size=100,\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(results)} light curves\")\n",
    "print(results[\"lightcurve\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask\n",
    "\n",
    "We can parallelize the computation via Dask by using dask.distributed.\n",
    "\n",
    "**Note:** Dask is not installed by default, so users will need to install dask (`pip install dask`) to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import dask.distributed\n",
    "\n",
    "    with dask.distributed.Client() as client:\n",
    "        results = simulate_lightcurves(\n",
    "            model=model,\n",
    "            num_samples=100,\n",
    "            obstable=obstable1,\n",
    "            passbands=passband_group1,\n",
    "            obstable_save_cols=[\"zp_nJy\"],\n",
    "            executor=client,\n",
    "        )\n",
    "    print(f\"Generated {len(results)} light curves\")\n",
    "    print(results[\"lightcurve\"][0])\n",
    "except ImportError:\n",
    "    print(\"Dask is not installed, skipping Dask example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray\n",
    "\n",
    "We can parallelize the computation via Ray by using ray.util.multiprocessing.Pool \n",
    "\n",
    "**Note:** Ray is not installed by default, so users will need to install dask (`pip install -U \"ray[default]\"`) to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import ray\n",
    "    from ray.util.multiprocessing import Pool\n",
    "\n",
    "    with Pool(processes=4) as executor:\n",
    "        results = simulate_lightcurves(\n",
    "            model=model,\n",
    "            num_samples=100,\n",
    "            obstable=obstable1,\n",
    "            passbands=passband_group1,\n",
    "            obstable_save_cols=[\"zp_nJy\"],\n",
    "            executor=executor,\n",
    "        )\n",
    "    print(f\"Generated {len(results)} light curves\")\n",
    "    print(results[\"lightcurve\"][0])\n",
    "\n",
    "    ray.shutdown()\n",
    "except ImportError:\n",
    "    print(\"Ray is not installed, skipping Ray example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to Files\n",
    "\n",
    "Depending on the size of the simulated results, you might not want to load the full set into memory as a single table. The `simulate_lightcurves` has a function to save each shard (the result of each process) to a unique file. Instead of returning the NestedFrames, the function returns the list of file paths containing the data. Users can then analyze or load these later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = simulate_lightcurves(\n",
    "    model=model,\n",
    "    num_samples=10_000,\n",
    "    obstable=obstable1,\n",
    "    passbands=passband_group1,\n",
    "    num_jobs=4,\n",
    "    batch_size=1000,\n",
    "    obstable_save_cols=[\"zp_nJy\"],\n",
    "    output_file_path=\"./scratch/nb_results.parquet\",\n",
    ")\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the results are broken up into ten different files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overhead\n",
    "\n",
    "As with any distributed computation, there will be per-batch overhead. All of the input data (model, obstable, etc.) are pickled and sent to the new processes. It takes time to pack and unpack this information. So care must be taken to ensure the parallelization is worth it.\n",
    "\n",
    "The user can provide a `batch_size` parameter to control the target batch size for each process. This allows the user to ensure that each process has enough data to be worth it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightcurvelynx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
