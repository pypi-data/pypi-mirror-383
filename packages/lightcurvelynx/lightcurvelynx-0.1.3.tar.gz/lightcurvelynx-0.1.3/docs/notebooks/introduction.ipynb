{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "LightCurveLynx is a package for large-scale, time-domain forward-modeling of astronomical light curve data. Simulations incorporate realistic effects, including survey cadence, dust extinction, and instrument noise models. LightCurveLynx is designed to enable user extensibility, such as adding new models, effects, and instruments, while ensuring scalability.\n",
    "\n",
    "In this tutorial, we discuss the overall flow of LightCurveLynx and how to use it to run simulations. The goal is to get a new user started and allow them to explore the package.\n",
    "\n",
    "Later tutorials cover topics in more depth, including:\n",
    "  - Sampling Parameters (sampling.ipynb) - Provides an introduction to parameters and how they are sampled within a simulation run.\n",
    "  - Adding new model types (adding_models.ipynb) - Provides a more in-depth discussion of ``BasePhysicalModel``, ``BandfluxModel``, and ``SEDModel`` subclasses and how to add new models.\n",
    "  - Add new effect types (addings_effects.ipynb) - Provides a discussion of the ``EffectModel`` class, how it is used, and how to create new subclasses.\n",
    "  - Working directly with passbands (passband-demo.ipynb)\n",
    "  - Working directly with ObsTables / Rubin OpSims (opsim_notebook.ipynb)\n",
    "\n",
    "## Program Flow\n",
    "\n",
    "LightCurveLynx generates synthetic light curves using the flow shown in the illustration below. A `BasePhysicalModel` and information about the parameter distributions is used to sample the models. These are combined with information from an `ObsTable`, such as a Rubin `OpSim`, to generate sample flux densities at a given set of times and wavelengths (or passbands), accounting for effects such as redshift. The simulator also applies other relevant effects to the rest frame flux densities (e.g. dust extinction) and the observer frame flux densities (detector noise). At the end the code outputs a series of samples.\n",
    "\n",
    "![The simulation flow](../_static/lightcurvelynx-intro.png \"The simulation flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "All light curves are generated from model objects that are a subclass of the `BasePhysicalModel` class. These model objects provide mechanisms for:\n",
    "  - Sampling their parameters from given distributions,\n",
    "  - Generating flux densities at given times and wavelengths (or passbands), and\n",
    "  - Applying noise and other effects to the observations.\n",
    "\n",
    "A major goal of LightCurveLynx is to be easily extensible so that users can create and analyze their own models. See the `adding_models.ipynb` notebook for examples of how to add a new type of models.\n",
    "\n",
    "Each \"sample\" of the data consists of a new sampling of the model's parameters and a generation of flux densities from those parameters. Thus, when a user generates a hundred samples, they are generating 100 light curves from 100 sample objects. For a detailed description of how sampling works, see the `sampling.ipynb` notebook.\n",
    "\n",
    "We can demonstrate this simulation flow using `SinWaveModel`, a toy model that generates fluxes using a sin wave. The `SinWaveModel` object uses multiple parameters to generate its flux, so we need to speccify how to set these. For some parameters we may have a fixed value, such as a brightness of 100.0. But in most simulations we will want to values of the parameters themselves to vary. We can set these from other nodes (any object that generates or uses parameters). Below we set two of the model's parameters (`frequency` and `t0`) from uniform distributions and two (`RA` and `dec`) are chosen from a Gaussian that matches the toy survey information we will load later in this notebook.\n",
    "\n",
    "LightCurveLynx provides tools for generating parameters from a range of models and distributions. For example we can sample (RA, dec) directly from the survey data itself. For more information on how to define the parameter settings, see the `sampling.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcurvelynx.math_nodes.np_random import NumpyRandomFunc\n",
    "from lightcurvelynx.models.basic_models import SinWaveModel\n",
    "\n",
    "model = SinWaveModel(\n",
    "    brightness=2000.0,\n",
    "    amplitude=200.0,\n",
    "    frequency=NumpyRandomFunc(\"uniform\", low=0.01, high=0.1),\n",
    "    t0=NumpyRandomFunc(\"uniform\", low=0.0, high=10.0),\n",
    "    ra=NumpyRandomFunc(\"normal\", loc=200.5, scale=0.01),\n",
    "    dec=NumpyRandomFunc(\"normal\", loc=-50.0, scale=0.01),\n",
    "    node_label=\"sin_wave_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the models, such as `SinWaveModel`, to generate flux densities from the sampled input parameters. We can manually evalute a model using the `evaluate_sed()` function where we provide the wavelengths and times to sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "times = np.arange(100.0)\n",
    "wavelengths = np.array([7000.0])\n",
    "fluxes = model.evaluate_sed(times, wavelengths)\n",
    "\n",
    "plt.plot(times, fluxes)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Flux\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of the simulation software is that we can generate a large number of light curves from a distribution of models. We start by using a `BasePhysicalModel` object's `sample_parameters` function to sample the parameters that can create this distribution of objects. \n",
    "\n",
    "Let's start with generating 5 sample objects. We save the samples in a `GraphState` object. Users will not need to deal with this object directly, but it can be used to peek at the underlying parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = model.sample_parameters(num_samples=3)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most users will not need to interact directly with the `GraphState` object, but at a very high level it can be viewed as a nested dictionary where parameters are indexed by two levels. First, a node label tells the code which Python object is storing the parameter. This level of identification is necessary to allow different stages to use parameters with the same name. Second, the parameter name maps to its stored values.\n",
    "\n",
    "Each (node name, parameter name) combination corresponds to a list of sample values for that parameter. Parameters are sampled together so that the i-th entires of each parameter represent a single, mutually consistent sampling of parameter space. For example you may want to generate all the parameters for a Type Ia supernova given information about the host galaxy. For a lot more detail see the `GraphState` section in the `sampling.ipynb` notebook. For now it is sufficient to know that `state` is tracking the sampled parameters.\n",
    "\n",
    "By passing the sampled state into `evaluate_sed()` we can generate multiple light curves (one for each sample) at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = model.evaluate_sed(times, wavelengths, state)\n",
    "\n",
    "plt.plot(times, fluxes[0, :], color=\"blue\")\n",
    "plt.plot(times, fluxes[1, :], color=\"green\")\n",
    "plt.plot(times, fluxes[2, :], color=\"red\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Flux\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effects\n",
    "\n",
    "Users can add effects to their physical model objects to account for real world aspects such as noise and dust extinction. For more detail on effects, including how to define your own, see the `adding_effects.ipynb` notebook.\n",
    "\n",
    "Note: Detector noise and redshift are not added effects, but rather automatically applied. Redshift effects are applied to SED-type models only based on the object's `redshift` parameter. Detector noise is applied to all model types from the `ObsTable` information (see the `ObsTable` section below for more details).\n",
    "\n",
    "For this demo, we add a simple white noise effect to the model (rest frame). For real simulations we would want to add a range of effects, such as dust extinction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcurvelynx.effects.white_noise import WhiteNoise\n",
    "\n",
    "# Create the white noise effect.\n",
    "white_noise = WhiteNoise(white_noise_sigma=10.0)\n",
    "model.add_effect(white_noise)\n",
    "\n",
    "# Evaluate the model with white noise applied (a single sample).\n",
    "flux = model.evaluate_sed(times, wavelengths)\n",
    "plt.plot(times, flux)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Flux\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ObsTable and Passbands\n",
    "\n",
    "To generate a reasonable simulation we need to provide instrument and survey information. We use two classes `ObsTable` and `PassbandGroup` to load and work with this information.\n",
    "\n",
    "### OpSim\n",
    "\n",
    "The `ObsTable` object is used to store survey information, including pointings and weather conditions.  In this notebook we use a specific subclass, `OpSim`, which models Rubin's simulated operations database. For more detail on the `OpSim` class, its capabilities, and how to work with it, see the `opsim_notebook.ipynb` notebook.\n",
    "\n",
    "The `OpSim` class is also used to extract information about the detector for modeling detector noise.\n",
    "\n",
    "For this demo we load a small example database included with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcurvelynx.obstable.opsim import OpSim\n",
    "\n",
    "opsim_file = \"../../tests/lightcurvelynx/data/opsim_shorten.db\"\n",
    "ops_data = OpSim.from_db(opsim_file)\n",
    "\n",
    "print(f\"Loaded an opsim database with {len(ops_data)} entries.\")\n",
    "print(f\"Columns: {ops_data.columns}\")\n",
    "print(f\"Time range: [{ops_data['time'].min()}, {ops_data['time'].max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassbandGroup\n",
    "\n",
    "The `PassbandGroup` object provides a mechanism for loading and applying the instrument’s passband information. Users can manually specify the passband values, load from given files, or load from a preset (which will download the files if needed). For more detail on the `PassbandGroup` class, see the `passband-demo.ipynb` notebook.\n",
    "\n",
    "For this demo, we load in the preset LSST filters. When loading from a preset, we provide the option to specify the directory in which the cached passbands are stored. We use a test data directory in this notebook, but in many cases you will want to use `data/passbands/` from the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcurvelynx.astro_utils.passbands import PassbandGroup\n",
    "\n",
    "# Use a (possibly older) cached version of the passbands to avoid downloading them.\n",
    "table_dir = \"../../tests/lightcurvelynx/data/passbands\"\n",
    "passband_group = PassbandGroup.from_preset(preset=\"LSST\", table_dir=table_dir)\n",
    "print(passband_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the simulations\n",
    "\n",
    "The simulation itself is run using a call to the `simulate_lightcurves()` function. This function will perform the parameter sampling, query the model, and apply any effects. It applies both types of effects (as described in the \"Effects\" section) and detector noise (as described in the \"ObsTable\" section).\n",
    "\n",
    "We redefine the model to use a `t0` that is consistent with the MJDs in the survey.\n",
    "\n",
    "The data from `simulate_lightcurves()` is returned as a [nested-pandas dataframe](https://github.com/lincc-frameworks/nested-pandas) for easy analysis. Each row corresponds to a single sampled object. The nested columns include the time series information for the light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcurvelynx.simulate import simulate_lightcurves\n",
    "\n",
    "model = SinWaveModel(\n",
    "    brightness=2000.0,\n",
    "    amplitude=200.0,\n",
    "    frequency=NumpyRandomFunc(\"uniform\", low=0.01, high=0.1),\n",
    "    t0=60796.0,\n",
    "    ra=NumpyRandomFunc(\"normal\", loc=200.5, scale=0.01),\n",
    "    dec=NumpyRandomFunc(\"normal\", loc=-50.0, scale=0.01),\n",
    "    node_label=\"sin_wave_model\",\n",
    ")\n",
    "\n",
    "lightcurves = simulate_lightcurves(\n",
    "    model,  # The model to simulate (including effects).\n",
    "    1_000,  # The number of light curves to simulate.\n",
    "    ops_data,  # The survey information.\n",
    "    passband_group,  # The passband information.\n",
    ")\n",
    "print(lightcurves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drill down into a single row of the results (e.g. sample number 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lightcurves.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and view the light curve for that sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lightcurves.iloc[0].lightcurve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown each row in the `lightcurves` table includes all the information for that sample and an embedded table containing the object's lightcurve according to the survey strategy.\n",
    "\n",
    "We can use this information to plot the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcurvelynx.utils.plotting import plot_lightcurves\n",
    "\n",
    "lc = lightcurves[\"lightcurve\"][0]\n",
    "plot_lightcurves(\n",
    "    lc[\"flux\"],\n",
    "    lc[\"mjd\"],\n",
    "    fluxerrs=lc[\"fluxerr\"],\n",
    "    filters=lc[\"filter\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing the Underlying Model\n",
    "\n",
    "All of the information needed to reconstruct each sample’s model is included as a (flattened) dictionary in the results’ “params” column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lightcurves[\"params\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert those flattened dictionaries back to the `GraphState` objects (which allows us to replay the simulation) using `from_dict` for a single state or `from_list` for multiple states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcurvelynx.graph_state import GraphState\n",
    "\n",
    "state_0 = GraphState.from_dict(lightcurves[\"params\"][0])\n",
    "print(\"First sample: \", state_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation tools also have a function to generate the noise free light curves in each band over a given set of times. This returns a dictionary of filter name to band fluxes at each time. We extend the light curve out beyond the two sampled points to give a better idea of the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcurvelynx.simulate import compute_single_noise_free_lightcurve\n",
    "\n",
    "noise_free_lcs = compute_single_noise_free_lightcurve(\n",
    "    model,\n",
    "    state_0,\n",
    "    passband_group,\n",
    "    rest_frame_phase_min=-10.0,  # 10 days before t0\n",
    "    rest_frame_phase_max=40.0,  # 40 days after t0\n",
    "    rest_frame_phase_step=0.5,  # 2 samples per day\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the noise free curves as a background line when plotting the light curves, using the `underlying_model` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_0 = lightcurves[\"lightcurve\"][0]\n",
    "plot_lightcurves(\n",
    "    lc_0[\"flux\"],\n",
    "    lc_0[\"mjd\"],\n",
    "    fluxerrs=lc_0[\"fluxerr\"],\n",
    "    filters=lc_0[\"filter\"],\n",
    "    underlying_model=noise_free_lcs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data\n",
    "\n",
    "We can save the results of a simulation using nested-pandas `to_parquet` function. This will save the entire result set in a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "scratch_dir = Path(\"./scratch\")\n",
    "scratch_dir.mkdir(exist_ok=True)\n",
    "\n",
    "lightcurves.to_parquet(scratch_dir / \"simulated_lightcurves.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since individual light curves, such as `lc_0` above, are stored in pandas frames, we can save them individually using any of panda's built-in functions.\n",
    "\n",
    "We can also output the simulation results as a [LSDB](https://docs.lsdb.io/en/latest/index.html) `Catalog`. These catalogs can be read in and analyzed by the LSDB tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcurvelynx.utils.io_utils import write_results_as_hats\n",
    "\n",
    "write_results_as_hats(scratch_dir / \"lsdb_dir\", lightcurves, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This tutorial barely scratches the surface on what LightCurveLynx can do and how it operates. The goal is to provide an overview. Interested users are encouraged to explore the other tutorial notebooks or reach out directly to the team."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightcurvelynx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
