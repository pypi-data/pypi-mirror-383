
@article{oconnor_optimal_2022,
	title = {Optimal {Transport} for {Stationary} {Markov} {Chains} via {Policy} {Iteration}},
	volume = {23},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v23/21-0519.html},
	abstract = {We study the optimal transport problem for pairs of stationary finite-state Markov chains, with an emphasis on the computation of optimal transition couplings. Transition couplings are a constrained family of transport plans that capture the dynamics of Markov chains. Solutions of the optimal transition coupling (OTC) problem correspond to alignments of the two chains that minimize long-term average cost. We establish a connection between the OTC problem and Markov decision processes, and show that solutions of the OTC problem can be obtained via an adaptation of policy iteration. For settings with large state spaces, we develop a fast approximate algorithm based on an entropy-regularized version of the OTC problem, and provide bounds on its per-iteration complexity. We establish a stability result for both the regularized and unregularized algorithms, from which a statistical consistency result follows as a corollary. We validate our theoretical results empirically through a simulation study, demonstrating that the approximate algorithm exhibits faster overall runtime with low error. Finally, we extend the setting and application of our methods to hidden Markov models, and illustrate the potential use of the proposed algorithms in practice with an application to computer-generated music.},
	number = {45},
	urldate = {2023-11-27},
	journal = {Journal of Machine Learning Research},
	author = {O'Connor, Kevin and McGoff, Kevin and Nobel, Andrew B.},
	year = {2022},
	pages = {1--52},
}

@article{yi_alignment_2024,
  title={Alignment and comparison of directed networks via transition couplings of random walks},
  author={Yi, Bongsoo and O'Connor, Kevin and McGoff, Kevin and Nobel, Andrew B},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  pages={qkae085},
  year={2024},
  publisher={Oxford University Press UK}
}

@misc{cole_alignment_2025,
	title = {Alignment of Continuous Brain Connectivity},
	url = {http://arxiv.org/abs/2503.15830},
	doi = {10.48550/arXiv.2503.15830},
	abstract = {Brain networks are typically represented by adjacency matrices, where each node corresponds to a brain region. In traditional brain network analysis, nodes are assumed to be matched across individuals, but the methods used for node matching often overlook the underlying connectivity information. This oversight can result in inaccurate node alignment, leading to inflated edge variability and reduced statistical power in downstream connectivity analyses. To overcome this challenge, we propose a novel framework for registering high resolution continuous connectivity ({ConCon}), defined as a continuous function on a product manifold space specifically, the cortical surface capturing structural connectivity between all pairs of cortical points. Leveraging {ConCon}, we formulate an optimal diffeomorphism problem to align both connectivity profiles and cortical surfaces simultaneously. We introduce an efficient algorithm to solve this problem and validate our approach using data from the Human Connectome Project ({HCP}). Results demonstrate that our method substantially improves the accuracy and robustness of connectome-based analyses compared to existing techniques.},
	number = {{arXiv}:2503.15830},
	publisher = {{arXiv}},
	author = {Cole, Martin and Xiang, Yang and Consagra, Will and Srivastava, Anuj and Qiu, Xing and Zhang, Zhengwu},
	urldate = {2025-07-03},
	date = {2025-03-20},
	eprinttype = {arxiv},
	eprint = {2503.15830 [stat]},
	keywords = {Statistics - Applications, Statistics - Computation, Statistics - Methodology},
	file = {Preprint PDF:/Users/jhineman/Zotero/storage/XMXGYVZ5/Cole et al. - 2025 - Alignment of Continuous Brain Connectivity.pdf:application/pdf},
}

@misc{calo_bisimulation_2024,
	title = {Bisimulation Metrics are Optimal Transport Distances, and Can be Computed Efficiently},
	url = {http://arxiv.org/abs/2406.04056},
	doi = {10.48550/arXiv.2406.04056},
	abstract = {We propose a new framework for formulating optimal transport distances between Markov chains. Previously known formulations studied couplings between the entire joint distribution induced by the chains, and derived solutions via a reduction to dynamic programming ({DP}) in an appropriately defined Markov decision process. This formulation has, however, not led to particularly efficient algorithms so far, since computing the associated {DP} operators requires fully solving a static optimal transport problem, and these operators need to be applied numerous times during the overall optimization process. In this work, we develop an alternative perspective by considering couplings between a flattened version of the joint distributions that we call discounted occupancy couplings, and show that calculating optimal transport distances in the full space of joint distributions can be equivalently formulated as solving a linear program ({LP}) in this reduced space. This {LP} formulation allows us to port several algorithmic ideas from other areas of optimal transport theory. In particular, our formulation makes it possible to introduce an appropriate notion of entropy regularization into the optimization problem, which in turn enables us to directly calculate optimal transport distances via a Sinkhorn-like method we call Sinkhorn Value Iteration ({SVI}). We show both theoretically and empirically that this method converges quickly to an optimal coupling, essentially at the same computational cost of running vanilla Sinkhorn in each pair of states. Along the way, we point out that our optimal transport distance exactly matches the common notion of bisimulation metrics between Markov chains, and thus our results also apply to computing such metrics, and in fact our algorithm turns out to be significantly more efficient than the best known methods developed so far for this purpose.},
	number = {{arXiv}:2406.04056},
	publisher = {{arXiv}},
	author = {Calo, Sergio and Jonsson, Anders and Neu, Gergely and Schwartz, Ludovic and Segovia-Aguas, Javier},
	urldate = {2025-07-03},
	date = {2024-06-11},
	eprinttype = {arxiv},
	eprint = {2406.04056 [cs]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
	file = {Preprint PDF:/Users/jhineman/Zotero/storage/FR3V8AW4/Calo et al. - 2024 - Bisimulation Metrics are Optimal Transport Distanc.pdf:application/pdf;Snapshot:/Users/jhineman/Zotero/storage/ZJAIXZFC/2406.html:text/html},
}

@misc{brugere_distances_2024,
	title = {Distances for Markov Chains, and Their Differentiation},
	url = {http://arxiv.org/abs/2302.08621},
	doi = {10.48550/arXiv.2302.08621},
	abstract = {(Directed) graphs with node attributes are a common type of data in various applications and there is a vast literature on developing metrics and efficient algorithms for comparing them. Recently, in the graph learning and optimization communities, a range of new approaches have been developed for comparing graphs with node attributes, leveraging ideas such as the Optimal Transport ({OT}) and the Weisfeiler-Lehman ({WL}) graph isomorphism test. Two state-of-the-art representatives are the {OTC} distance proposed in (O'Connor et al., 2022) and the {WL} distance in (Chen et al., 2022). Interestingly, while these two distances are developed based on different ideas, we observe that they both view graphs as Markov chains, and are deeply connected. Indeed, in this paper, we propose a unified framework to generate distances for Markov chains (thus including (directed) graphs with node attributes), which we call the Optimal Transport Markov ({OTM}) distances, that encompass both the {OTC} and the {WL} distances. We further introduce a special one-parameter family of distances within our {OTM} framework, called the discounted {WL} distance. We show that the discounted {WL} distance has nice theoretical properties and can address several limitations of the existing {OTC} and {WL} distances. Furthermore, contrary to the {OTC} and the {WL} distances, our new discounted {WL} distance can be differentiated after a entropy-regularization similar to the Sinkhorn distance, making it suitable to use in learning frameworks, e.g., as the reconstruction loss in a graph generative model.},
	number = {{arXiv}:2302.08621},
	publisher = {{arXiv}},
	author = {Brugère, Tristan and Wan, Zhengchao and Wang, Yusu},
	urldate = {2025-07-03},
	date = {2024-02-16},
	eprinttype = {arxiv},
	eprint = {2302.08621 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/jhineman/Zotero/storage/LILX829J/Brugère et al. - 2024 - Distances for Markov Chains, and Their Differentia.pdf:application/pdf},
}

@misc{peyre_computational_2020,
	title = {Computational Optimal Transport},
	url = {http://arxiv.org/abs/1803.00567},
	doi = {10.48550/arXiv.1803.00567},
	abstract = {Optimal transport ({OT}) theory can be informally described using the words of the French mathematician Gaspard Monge (1746-1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in {OT} cast that problem as that of comparing two probability distributions, two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a "global" cost to every such transport, using the "local" consideration of how much it costs to move a grain of sand from one place to another. Recent years have witnessed the spread of {OT} in several fields, thanks to the emergence of approximate solvers that can scale to sizes and dimensions that are relevant to data sciences. Thanks to this newfound scalability, {OT} is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), computer vision and graphics (for shape manipulation) or machine learning (for regression, classification and density fitting). This short book reviews {OT} with a bias toward numerical methods and their applications in data sciences, and sheds lights on the theoretical properties of {OT} that make it particularly useful for some of these applications.},
	number = {{arXiv}:1803.00567},
	publisher = {{arXiv}},
	author = {Peyré, Gabriel and Cuturi, Marco},
	urldate = {2025-07-03},
	date = {2020-03-18},
	eprinttype = {arxiv},
	eprint = {1803.00567 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {Preprint PDF:/Users/jhineman/Zotero/storage/C9LLSLID/Peyré and Cuturi - 2020 - Computational Optimal Transport.pdf:application/pdf;Snapshot:/Users/jhineman/Zotero/storage/TW3IJZUH/1803.html:text/html},
}

@article{flamary_pot_2021,
	title = {{POT}: Python Optimal Transport},
	volume = {22},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v22/20-451.html},
	shorttitle = {{POT}},
	abstract = {Optimal  transport  has  recently  been  reintroduced  to  the  machine  learning  community thanks in part to novel efficient optimization procedures allowing for medium to large scale applications.  We propose a Python toolbox that implements several key optimal transport ideas  for  the  machine  learning  community.   The  toolbox  contains  implementations  of  a number  of  founding  works  of  {OT}  for  machine  learning  such  as  Sinkhorn  algorithm  and Wasserstein barycenters, but also provides generic solvers that can be used for conducting novel fundamental research.  This toolbox, named {POT} for Python Optimal Transport, is open source with an {MIT} license.},
	pages = {1--8},
	number = {78},
	journaltitle = {Journal of Machine Learning Research},
	author = {Flamary, Rémi and Courty, Nicolas and Gramfort, Alexandre and Alaya, Mokhtar Z. and Boisbunon, Aurélie and Chambon, Stanislas and Chapel, Laetitia and Corenflos, Adrien and Fatras, Kilian and Fournier, Nemo and Gautheron, Léo and Gayraud, Nathalie T. H. and Janati, Hicham and Rakotomamonjy, Alain and Redko, Ievgen and Rolet, Antoine and Schutz, Antony and Seguy, Vivien and Sutherland, Danica J. and Tavenard, Romain and Tong, Alexander and Vayer, Titouan},
	urldate = {2025-07-03},
	date = {2021},
	file = {Full Text PDF:/Users/jhineman/Zotero/storage/AY4V53FS/Flamary et al. - 2021 - POT Python Optimal Transport.pdf:application/pdf;Source Code:/Users/jhineman/Zotero/storage/IHFTGBE2/POT.html:text/html},
}

@report{hagberg_exploring_2008,
	title = {Exploring network structure, dynamics, and function using {NetworkX}},
	url = {https://www.osti.gov/biblio/960616},
	abstract = {{NetworkX} is a Python language package for exploration and analysis of networks and network algorithms. The core package provides data structures for representing many types of networks, or graphs, including simple graphs, directed graphs, and graphs with parallel edges and self loops. The nodes in {NetworkX} graphs can be any (hashable) Python object and edges can contain arbitrary data; this flexibility mades {NetworkX} ideal for representing networks found in many different scientific fields. In addition to the basic data structures many graph algorithms are implemented for calculating network properties and structure measures: shortest paths, betweenness centrality, clustering, and degree distribution and many more. {NetworkX} can read and write various graph formats for eash exchange with existing data, and provides generators for many classic graphs and popular graph models, such as the Erdoes-Renyi, Small World, and Barabasi-Albert models, are included. The ease-of-use and flexibility of the Python programming language together with connection to the {SciPy} tools make {NetworkX} a powerful tool for scientific computations. We discuss some of our recent work studying synchronization of coupled oscillators to demonstrate how {NetworkX} enables research in the field of computational networks.},
	number = {{LA}-{UR}-08-05495; {LA}-{UR}-08-5495},
	institution = {Los Alamos National Laboratory ({LANL}), Los Alamos, {NM} (United States)},
	author = {Hagberg, Aric and Swart, Pieter J. and Schult, Daniel A.},
	urldate = {2025-07-03},
	date = {2008-01-01},
	file = {Full Text PDF:/Users/jhineman/Zotero/storage/NGFG3PX6/Hagberg et al. - 2008 - Exploring network structure, dynamics, and functio.pdf:application/pdf},
}

@software{landrum_rdkitrdkit_2025,
	title = {rdkit/rdkit: 2025\_03\_4 (Q1 2025) Release},
	url = {https://zenodo.org/records/15773589},
	shorttitle = {rdkit/rdkit},
	publisher = {Zenodo},
	author = {Landrum, Greg and Tosco, Paolo and Kelley, Brian and Rodriguez, Ricardo and Cosgrove, David and Vianello, Riccardo and sriniker and Gedeck, Peter and Jones, Gareth and Kawashima, Eisuke and {NadineSchneider} and Nealschneider, Dan and Dalke, Andrew and Swain, Matt and Cole, Brian and tadhurst-cdd and Turk, Samo and Savelev, Aleksandr and Vaucher, Alain and Wójcikowski, Maciej and Take, Ichiru and Walker, Rachel and Scalfani, Vincent F. and Faara, Hussein and Ujihara, Kazuya and Probst, Daniel and Maeder, Niels and Monat, Jeremy and Lehtivarjo, Juuso and godin, guillaume},
	urldate = {2025-07-03},
	date = {2025-06-30},
	doi = {10.5281/zenodo.15773589},
	file = {Snapshot:/Users/jhineman/Zotero/storage/52EPCR3N/15773589.html:text/html},
}

@article{pedregosa_scikit-learn_2011,
	title = {Scikit-learn: Machine Learning in Python},
	volume = {12},
	url = {https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html},
	pages = {2825--2830},
	journaltitle = {Journal of Machine Learning Research},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	date = {2011},
}

@software{yi_austinyinetotc_2023,
	title = {austinyi/{NetOTC}},
	url = {https://github.com/austinyi/NetOTC},
	author = {Yi, Bongsoo},
	urldate = {2025-07-03},
	date = {2023-10-25},
	note = {original-date: 2022-12-22T15:50:28Z},
}

@software{oconnor_oconnor-kevinotc_2022,
	title = {oconnor-kevin/{OTC}},
	url = {https://github.com/oconnor-kevin/OTC},
	author = {O'Connor, Kevin},
	urldate = {2025-07-03},
	date = {2022-10-03},
	note = {original-date: 2021-05-11T23:31:29Z},
}

@misc{krekel_pytest_2004,
	title = {pytest 8.3},
	url = {https://github.com/pytest-dev/pytest},
	author = {Krekel, Holger and Oliveira, Bruno and Pfannschmidt, Ronny and Bruynooghe, Floris and Laugher, Brianna and Bruhin, Florian},
	date = {2004},
}
