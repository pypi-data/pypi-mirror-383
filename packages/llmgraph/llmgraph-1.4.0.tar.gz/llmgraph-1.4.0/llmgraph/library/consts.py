package_name = "llmgraph"
version = "1.4.0"
prompts_yaml_location = "prompts.yaml"

default_llm_model = "gpt-5-mini"
default_llm_temp = 1.0  # For gpt-5 models only temperature=1 is supported
default_output_folder = "./_output/"
