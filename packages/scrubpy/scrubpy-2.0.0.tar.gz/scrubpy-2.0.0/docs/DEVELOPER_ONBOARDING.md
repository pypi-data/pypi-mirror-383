# ðŸš€ ScrubPy Developer Onboarding Guide

> **Welcome to ScrubPy!** This comprehensive guide will get you from zero to contributing in 30 minutes.

## ðŸ“‹ Table of Contents
- [Quick Setup](#quick-setup)
- [Project Architecture](#project-architecture)
- [Development Workflow](#development-workflow)
- [Code Organization](#code-organization)
- [Key Concepts](#key-concepts)
- [Testing Guidelines](#testing-guidelines)
- [Common Tasks](#common-tasks)

---

## ðŸ Quick Setup

### 1. Prerequisites
```bash
# Required
- Python 3.8+ 
- Git
- 4GB+ RAM (for large file processing)

# Optional but Recommended  
- VS Code with Python extension
- Ollama (for LLM features)
- Docker (for isolated testing)
```

### 2. Clone & Install
```bash
git clone https://github.com/Dhanushranga1/scrubpy.git
cd scrubpy
pip install -r requirements.txt
```

### 3. Verify Installation
```bash
# Test all interfaces work
python main.py --help
python main.py --cli
python -c "from scrubpy.core import load_dataset; print('âœ… Core imports work')"
python -m pytest tests/ -v  # Run tests if available
```

### 4. First Run
```bash
# Try the web interface
python main.py
# Open http://localhost:8501 and upload sample_data.csv

# Try CLI interface  
python main.py --cli
# Select sample_data.csv and explore features
```

---

## ðŸ—ï¸ Project Architecture

### High-Level Structure
```
scrubpy/
â”œâ”€â”€ ðŸŽ® Entry Points
â”‚   â”œâ”€â”€ __main__.py          # Package entry (python -m scrubpy)
â”‚   â”œâ”€â”€ main.py              # Multi-interface launcher
â”‚   â””â”€â”€ setup.py             # Package configuration
â”‚
â”œâ”€â”€ ðŸ§  Core Engine (scrubpy/)
â”‚   â”œâ”€â”€ core.py              # Data cleaning operations
â”‚   â”œâ”€â”€ quality_analyzer.py  # Quality assessment engine
â”‚   â”œâ”€â”€ column_insights.py   # Smart column analysis  
â”‚   â”œâ”€â”€ smart_imputation.py  # ML-based missing value handling
â”‚   â””â”€â”€ profiling.py         # Dataset profiling
â”‚
â”œâ”€â”€ ðŸŽ¨ User Interfaces
â”‚   â”œâ”€â”€ enhanced_cli.py      # Modern CLI (Typer-based)
â”‚   â”œâ”€â”€ cli.py               # Legacy CLI (Rich-based)
â”‚   â”œâ”€â”€ web_app.py           # Streamlit web interface
â”‚   â”œâ”€â”€ enhanced_web_app.py  # Advanced web features
â”‚   â””â”€â”€ chat_assistant.py    # AI conversation interface
â”‚
â”œâ”€â”€ ðŸ¤– AI Integration
â”‚   â”œâ”€â”€ llm_utils.py         # LLM client and utilities
â”‚   â””â”€â”€ chat_assistant.py    # Conversational interface
â”‚
â”œâ”€â”€ ðŸ”§ Advanced Features
â”‚   â”œâ”€â”€ template_system.py   # Reusable cleaning workflows
â”‚   â”œâ”€â”€ advanced_text_cleaning.py  # Phone/email/address cleaning
â”‚   â”œâ”€â”€ large_file_handler.py     # Memory-efficient processing
â”‚   â””â”€â”€ enhanced_file_handler.py  # Excel multi-sheet support
â”‚
â”œâ”€â”€ ðŸ“Š Analysis & Reporting
â”‚   â”œâ”€â”€ eda_analysis.py      # Exploratory data analysis
â”‚   â”œâ”€â”€ smart_eda.py         # PDF report generation
â”‚   â””â”€â”€ export_profiling_report.py  # Quality reports
â”‚
â””â”€â”€ ðŸ§ª Testing
    â”œâ”€â”€ test_imports.py      # Import validation
    â”œâ”€â”€ test_enhanced_features.py  # New features testing
    â””â”€â”€ test_llm_integration.py   # AI features testing
```

### Data Flow Architecture
```
ðŸ“¥ Input Sources
  â”œâ”€â”€ CSV Files
  â”œâ”€â”€ Excel (Multi-sheet) 
  â”œâ”€â”€ Large Files (>1GB)
  â””â”€â”€ Direct DataFrame

      â¬‡ï¸

ðŸ” Analysis Pipeline
  â”œâ”€â”€ Dataset Profiling (profiling.py)
  â”œâ”€â”€ Column Insights (column_insights.py)  
  â”œâ”€â”€ Quality Assessment (quality_analyzer.py)
  â””â”€â”€ Pattern Detection (AI-powered)

      â¬‡ï¸

ðŸ§¹ Cleaning Engine (core.py)
  â”œâ”€â”€ Missing Value Handling
  â”œâ”€â”€ Duplicate Detection
  â”œâ”€â”€ Outlier Removal
  â”œâ”€â”€ Text Standardization
  â”œâ”€â”€ Type Conversion
  â””â”€â”€ Custom Transformations

      â¬‡ï¸

ðŸŽ¯ Output & Reports
  â”œâ”€â”€ Cleaned Dataset
  â”œâ”€â”€ Quality Reports (PDF/Text)
  â”œâ”€â”€ EDA Reports (PDF with plots)
  â”œâ”€â”€ Cleaning Templates (YAML)
  â””â”€â”€ Code Generation (Python)
```

---

## ðŸ’¼ Development Workflow

### Branching Strategy
```bash
main          # Production-ready code
â”œâ”€â”€ phase-3   # Current development (AI features)
â”œâ”€â”€ feature/* # New feature development
â”œâ”€â”€ fix/*     # Bug fixes  
â””â”€â”€ docs/*    # Documentation updates
```

### Development Process
1. **Create Feature Branch**
   ```bash
   git checkout -b feature/awesome-new-feature
   ```

2. **Make Changes** following our [Code Standards](#code-standards)

3. **Test Locally**
   ```bash
   python -m pytest tests/
   python main.py --cli  # Manual testing
   ```

4. **Update Documentation** if needed

5. **Submit Pull Request** with clear description

### Code Standards
```python
# âœ… Good: Clear function names and docstrings
def analyze_missing_patterns(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Analyze patterns in missing data across columns.
    
    Args:
        df: Input DataFrame to analyze
        
    Returns:
        Dict containing missing data insights and recommendations
    """
    pass

# âœ… Good: Type hints and error handling
def load_dataset(filepath: Union[str, Path]) -> Optional[pd.DataFrame]:
    try:
        return pd.read_csv(filepath)
    except Exception as e:
        logger.error(f"Failed to load {filepath}: {e}")
        return None
```

---

## ðŸ“š Key Concepts

### 1. Column Insights System
**Purpose**: Automatically detect what each column represents
```python
from scrubpy.column_insights import get_column_insights

# Analyzes column names, data patterns, and values
insights = get_column_insights(df)
# Returns: role predictions, data types, quality metrics
```

### 2. Quality Assessment Engine  
**Purpose**: Comprehensive data quality scoring
```python
from scrubpy.quality_analyzer import SmartDataQualityAnalyzer

analyzer = SmartDataQualityAnalyzer(df)
report = analyzer.analyze_all()
# Returns: issues list, quality score, recommendations
```

### 3. Template System
**Purpose**: Reusable cleaning workflows
```python
from scrubpy.template_system import TemplateManager

manager = TemplateManager()
template = manager.load_template("customer_data")
cleaned_df = manager.apply_template(df, template)
```

### 4. Smart Imputation
**Purpose**: AI-powered missing value handling
```python
from scrubpy.smart_imputation import SmartImputer

imputer = SmartImputer(df)
# Uses multiple strategies: statistical, ML, pattern-based
cleaned_df = imputer.impute_all()
```

---

## ðŸŽ¯ Common Development Tasks

### Adding a New Cleaning Operation

1. **Add Core Function** (`scrubpy/core.py`)
   ```python
   def my_new_cleaning_operation(df: pd.DataFrame, **kwargs) -> pd.DataFrame:
       """Your new cleaning operation"""
       # Implementation here
       return df
   ```

2. **Add to CLI Menu** (`scrubpy/enhanced_cli.py`)
   ```python
   # Add to cleaning_operations menu
   @app.command()
   def my_operation():
       """CLI command for your operation"""
       pass
   ```

3. **Add to Web Interface** (`web_app.py`)
   ```python
   # Add to Streamlit sidebar
   if st.sidebar.button("My Operation"):
       result = my_new_cleaning_operation(df)
       st.success("Operation completed!")
   ```

4. **Add Tests** (`test_enhanced_features.py`)
   ```python
   def test_my_new_operation():
       """Test your new operation"""
       test_df = pd.DataFrame({"col": [1, 2, 3]})
       result = my_new_cleaning_operation(test_df)
       assert len(result) == 3  # Your assertions
   ```

### Adding a New Template

1. **Create YAML Template** (`templates/my_template.yaml`)
   ```yaml
   name: "My Data Template"
   description: "Template for my specific data type"
   operations:
     - type: "drop_missing"
       columns: ["important_col"]
     - type: "standardize_text" 
       columns: ["name_col"]
   ```

2. **Test Template** 
   ```python
   from scrubpy.template_system import TemplateManager
   manager = TemplateManager()
   template = manager.load_template("my_template")
   ```

### Integrating New AI Features

1. **Extend LLM Utils** (`scrubpy/llm_utils.py`)
   ```python
   class MyAIFeature:
       def analyze_data(self, df: pd.DataFrame) -> str:
           """Your AI analysis logic"""
           return self.llm_client.query("Analyze this data...")
   ```

2. **Add to Chat Interface** (`scrubpy/chat_assistant.py`)
   ```python
   # Add new command handling
   if "analyze patterns" in user_input.lower():
       feature = MyAIFeature()
       response = feature.analyze_data(self.df)
   ```

---

## ðŸ§ª Testing Strategy

### Test Categories
1. **Import Tests** (`test_imports.py`)
   - Verify all modules import correctly
   - Check dependency availability

2. **Feature Tests** (`test_enhanced_features.py`) 
   - Test specific functionality
   - Edge cases and error handling

3. **Integration Tests** (`test_llm_integration.py`)
   - End-to-end workflows
   - Interface integration

### Running Tests
```bash
# All tests
python -m pytest tests/ -v

# Specific test file
python test_imports.py

# Test with coverage
python -m pytest --cov=scrubpy tests/
```

---

## ðŸš¨ Common Pitfalls & Solutions

### Import Issues
**Problem**: `ModuleNotFoundError: No module named 'scrubpy'`
```bash
# Solution: Add to Python path
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
# Or use relative imports within package
```

### Memory Issues with Large Files
**Problem**: Out of memory with large datasets
```python
# Solution: Use chunked processing
from scrubpy.large_file_handler import LargeFileHandler
handler = LargeFileHandler(chunk_size=10000)
```

### LLM Connection Issues  
**Problem**: AI features not working
```bash
# Check Ollama is running
ollama serve
ollama pull mistral

# Or use alternative provider in config
```

---

## ðŸ“– Next Steps

1. **Read**: [API Reference](API_REFERENCE.md) for detailed function documentation
2. **Study**: [Architecture Deep Dive](ARCHITECTURE.md) for system internals  
3. **Practice**: Start with small bug fixes or feature enhancements
4. **Contribute**: Check our [Issues](https://github.com/Dhanushranga1/scrubpy/issues) for good first contributions

---

## ðŸ’¬ Getting Help

- **Documentation**: Check existing `.md` files in repo
- **Code Examples**: Look at test files for usage patterns
- **Issues**: Create GitHub issue for bugs or questions
- **Discussions**: Use GitHub Discussions for general questions

**Happy Coding! ðŸŽ‰**