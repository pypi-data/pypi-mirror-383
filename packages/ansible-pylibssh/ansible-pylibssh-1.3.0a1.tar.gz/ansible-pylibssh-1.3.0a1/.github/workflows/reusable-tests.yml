---

name: â™² ðŸ§ª

on:  # yamllint disable-line rule:truthy
  workflow_call:
    inputs:
      python-version:
        required: true
        type: string
      runner-vm-os:
        required: true
        type: string
      dist-type:
        required: true
        type: string
      yolo:
        required: true
        type: string
      dists-artifact-name:
        description: Workflow artifact name containing dists
        required: true
        type: string
      cython-tracing:
        description: Whether to build Cython modules with line tracing
        default: '0'
        required: false
        type: string
      source-tarball-name:
        description: Sdist filename wildcard
        required: true
        type: string
      cache-key-files:
        description: Dependency files cache
        required: true
        type: string
      release-requested:
        description: Flag whether this is CI run is a release request
        default: 'false'
        required: false
        type: string
    secrets:
      codecov-token:
        description: Mandatory token for uploading to Codecov
        required: true

env:
  FORCE_COLOR: 1  # Request colored output from CLI tools supporting it
  MYPY_FORCE_COLOR: 1  # MyPy's color enforcement
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  PIP_NO_PYTHON_VERSION_WARNING: 1
  PIP_NO_WARN_SCRIPT_LOCATION: 1
  PROJECT_NAME: ansible-pylibssh
  PY_COLORS: 1  # Recognized by the `py` package, dependency of `pytest`
  TOX_PARALLEL_NO_SPINNER: 1
  TOX_TESTENV_PASSENV: >-  # Make tox-wrapped tools see color requests
    FORCE_COLOR
    MYPY_FORCE_COLOR
    NO_COLOR
    PY_COLORS
    PYTEST_THEME
    PYTEST_THEME_MODE
  TOX_VERSION: tox


jobs:
  test-linux:
    name: >-
      ðŸ ${{ inputs.python-version }}@${{ inputs.runner-vm-os }}
      |
      ${{ inputs.dist-type }} dist
    runs-on: ${{ inputs.runner-vm-os }}

    timeout-minutes: 7

    continue-on-error: >-
      ${{
          (
            fromJSON(inputs.release-requested)
            && !fromJSON(inputs.yolo)
          ) && true || false
      }}

    env:
      ANSIBLE_PYLIBSSH_CYTHON_TRACING: ${{ inputs.cython-tracing }}
      TOXENV: py

    steps:
    - name: Disable dpkg triggers to speed up apt
      if: >-
        runner.os == 'Linux'
      # yamllint disable rule:line-length
      run: |
        INITRAMFS_CONF="/etc/initramfs-tools/update-initramfs.conf"
        DPKG_TRIGGERS="/var/lib/dpkg/triggers/File"

        if [ -e $INITRAMFS_CONF ]; then
            sudo sed -i 's/yes/no/g' $INITRAMFS_CONF
        fi
        echo 'set man-db/auto-update false' | sudo debconf-communicate >/dev/null
        sudo dpkg-reconfigure man-db

        if [ -e $DPKG_TRIGGERS ]; then
            sudo sed '/fontconfig/d' -i $DPKG_TRIGGERS
            sudo sed '/install-info/d' -i $DPKG_TRIGGERS
            sudo sed '/mime/d' -i $DPKG_TRIGGERS
            sudo sed '/hicolor-icon-theme/d' -i $DPKG_TRIGGERS
        fi

        echo "force-unsafe-io" | sudo tee -a /etc/dpkg/dpkg.cfg.d/force-unsafe-io

        if [ -a /usr/bin/eatmydata ]; then
          echo "eatmydata available"
          echo -e '#!/bin/sh\nexec eatmydata /usr/bin/dpkg $@' | sudo tee /usr/local/bin/dpkg && sudo chmod +x /usr/local/bin/dpkg
          echo -e '#!/bin/sh\nexec eatmydata /usr/bin/apt $@' | sudo tee /usr/local/bin/apt && sudo chmod +x /usr/local/bin/apt
          echo -e '#!/bin/sh\nexec eatmydata /usr/bin/apt-get $@' | sudo tee /usr/local/bin/apt-get && sudo chmod +x /usr/local/bin/apt-get
        fi
      # yamllint enable rule:line-length
    - name: Install build toolchain and openssl headers on Linux
      if: >-
        inputs.dist-type == 'source' &&
        runner.os == 'Linux'
      run: sudo apt update && sudo apt install build-essential libssl-dev
    - name: Install libssh and openssl headers on macOS
      if: >-
        runner.os == 'macOS'
      run: brew install libssh
    - name: Install catchsegv and libssh headers on Linux for cythonize+coverage
      if: >-
        runner.os == 'Linux'
      run: sudo apt update && sudo apt install glibc-tools libssh-dev
    - name: Switch ðŸ to v${{ inputs.python-version }}
      id: python-install
      uses: actions/setup-python@v5.3.0
      with:
        python-version: ${{ inputs.python-version }}

    - name: Retrieve the project source from an sdist inside the GHA artifact
      uses: re-actors/checkout-python-sdist@release/v2
      with:
        source-tarball-name: ${{ inputs.source-tarball-name }}
        workflow-artifact-name: ${{ inputs.dists-artifact-name }}

    - name: Figure out if the interpreter ABI is stable
      id: py-abi
      run: |
        from os import environ
        from pathlib import Path
        from sys import version_info

        FILE_APPEND_MODE = 'a'

        is_stable_abi = version_info.releaselevel == 'final'

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(
                'is-stable-abi={is_stable_abi}'.
                format(is_stable_abi=str(is_stable_abi).lower()),
                file=outputs_file,
            )
      shell: python
    - name: >-
        Calculate Python interpreter version hash value
        for use in the cache key
      if: fromJSON(steps.py-abi.outputs.is-stable-abi)
      id: calc-cache-key-py
      run: |
        from hashlib import sha512
        from os import environ
        from pathlib import Path
        from sys import version

        FILE_APPEND_MODE = 'a'

        hash = sha512(version.encode()).hexdigest()

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f'py-hash-key={hash}', file=outputs_file)
      shell: python
    - name: Set up pip cache
      if: fromJSON(steps.py-abi.outputs.is-stable-abi)
      uses: actions/cache@v4
      with:
        path: >-
          ${{
              runner.os == 'Linux'
              && '~/.cache/pip'
              || '~/Library/Caches/pip'
          }}
        key: >-
          ${{ runner.os }}-pip-${{
          steps.calc-cache-key-py.outputs.py-hash-key }}-${{
          inputs.cache-key-files }}
        restore-keys: |
          ${{ runner.os }}-pip-${{
            steps.calc-cache-key-py.outputs.py-hash-key
          }}-
          ${{ runner.os }}-pip-
          ${{ runner.os }}-

    - name: Upgrade pip with `requires_python`
      run: >-
        python -m
        pip install
        --user
        --upgrade
        --force-reinstall
        pip-with-requires-python
    - name: Install tox
      run: >-
        python -m
        pip install
        --user
        '${{ env.TOX_VERSION }}'

    - name: Download all the dists
      uses: actions/download-artifact@v4
      with:
        pattern: ${{ needs.pre-setup.outputs.dists-artifact-name }}*
        path: dist/
        merge-multiple: true

    - name: Determine pre-compiled compatible wheel
      env:
        # NOTE: When `pip` is forced to colorize output piped into `jq`,
        # NOTE: the latter can't parse it. So we're overriding the color
        # NOTE: preference here via https://no-color.org.
        # NOTE: Setting `FORCE_COLOR` to any value (including 0, an empty
        # NOTE: string, or a "YAML null" `~`) doesn't have any effect and
        # NOTE: `pip` (through its verndored copy of `rich`) treats the
        # NOTE: presence of the variable as "force-color" regardless.
        #
        # NOTE: This doesn't actually work either, so we'll resort to unsetting
        # NOTE: in the Bash script.
        # NOTE: Ref: https://github.com/Textualize/rich/issues/2622
        NO_COLOR: 1
      if: inputs.dist-type == 'binary'
      id: wheel-file
      run: >
        echo -n path= | tee -a "${GITHUB_OUTPUT}"


        unset FORCE_COLOR


        python
        -X utf8
        -u -I
        -m pip install
        --find-links=./dist
        --no-index
        '${{ env.PROJECT_NAME }}'
        --force-reinstall
        --no-color
        --no-deps
        --only-binary=:all:
        --dry-run
        --report=-
        --quiet
        | jq --raw-output .install[].download_info.url
        | sed -e 's#^file://##' -e 's#%2B#+#'
        | tee -a "${GITHUB_OUTPUT}"
      shell: bash

    - name: >-
        Pre-populate tox env:
        ${{ env.TOXENV }}
      run: >-
        python -m
        tox
        --parallel auto
        --parallel-live
        --skip-missing-interpreters false
        --installpkg '${{
          inputs.dist-type == 'binary'
          && steps.wheel-file.outputs.path
          || format('dist/{0}', inputs.source-tarball-name)
        }}'
        --notest

    - name: Configure tox to run pytest under catchsegv
      if: runner.os == 'Linux'
      run: |
        from __future__ import print_function
        import os
        with open(os.environ['GITHUB_ENV'], 'a') as env_file:
            env_file.write('CATCHSEGV_BINARY=catchsegv\n')
      shell: python

    - name: Run the testing
      run: >-
        python -m
        tox
        --parallel auto
        --parallel-live
        --skip-missing-interpreters false
        -qq
    - name: Produce markdown test summary from JUnit
      if: always()
      uses: test-summary/action@v2.4
      with:
        paths: .test-results/pytest/results.xml
    - name: Re-run the failing tests with maximum verbosity
      if: failure()
      run: >-  # `exit 1` makes sure that the job remains red with flaky runs
        python -m
        tox
        --parallel auto
        --parallel-live
        --skip-missing-interpreters false
        -vvvvv
        --skip-pkg-install
        --
        --no-cov -vvvvv --lf
        && exit 1
      shell: bash
    - name: Send coverage data to Codecov
      uses: codecov/codecov-action@v5.1.2
      with:
        files: .test-results/pytest/cov.xml
        flags: >-
          CI-GHA,
          OS-${{
            runner.os
          }},
          VM-${{
            inputs.runner-vm-os
          }},
          Py-${{
            steps.python-install.outputs.python-version
          }}
        token: ${{ secrets.codecov-token }}

...
