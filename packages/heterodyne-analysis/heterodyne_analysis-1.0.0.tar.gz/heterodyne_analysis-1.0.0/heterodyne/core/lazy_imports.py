"""
Advanced Lazy Loading System for Heavy Dependencies
==================================================

Optimized lazy loading implementation specifically designed for scientific computing
packages with heavy dependencies like NumPy, SciPy, Numba, and Matplotlib.

This module provides enterprise-grade lazy loading patterns to minimize startup time
and memory footprint while maintaining full functionality.

Authors: Wei Chen, Hongrui He
Institution: Argonne National Laboratory
"""

import importlib
import logging
import threading
from collections.abc import Callable
from contextlib import contextmanager
from typing import Any
from typing import TypeVar

# Thread-safe lazy loading
_IMPORT_LOCK = threading.RLock()
_IMPORT_CACHE: dict[str, Any] = {}

# Performance tracking
_IMPORT_TIMES: dict[str, float] = {}
_IMPORT_SUCCESS: dict[str, bool] = {}

logger = logging.getLogger(__name__)

F = TypeVar("F", bound=Callable[..., Any])


class LazyImportError(ImportError):
    """Custom exception for lazy import failures."""


class HeavyDependencyLoader:
    """
    Advanced lazy loader for heavy scientific computing dependencies.

    Features:
    - Thread-safe loading with caching
    - Performance monitoring and timing
    - Graceful degradation for optional dependencies
    - Memory-efficient weak references
    - Startup overhead minimization
    """

    def __init__(
        self,
        module_name: str,
        attribute: str | None = None,
        fallback: Any = None,
        required: bool = True,
    ):
        """
        Initialize heavy dependency loader.

        Parameters
        ----------
        module_name : str
            Name of module to import
        attribute : str | None
            Specific attribute to extract from module
        fallback : Any
            Fallback value if import fails (for optional dependencies)
        required : bool
            Whether this dependency is required for core functionality
        """
        self.module_name = module_name
        self.attribute = attribute
        self.fallback = fallback
        self.required = required
        self._cached_object = None
        self._load_attempted = False
        self._load_time = 0.0

        # Create cache key
        self._cache_key = f"{module_name}::{attribute}" if attribute else module_name

    def __call__(self, *args, **kwargs):
        """Call the loaded object."""
        obj = self._get_object()
        if obj is None:
            if self.required:
                raise LazyImportError(
                    f"Required dependency '{self.module_name}' failed to load"
                )
            return self.fallback

        if callable(obj):
            return obj(*args, **kwargs)
        return obj

    def __getattr__(self, name: str):
        """Get attribute from loaded object."""
        obj = self._get_object()
        if obj is None:
            if self.required:
                raise LazyImportError(
                    f"Required dependency '{self.module_name}' failed to load"
                )
            if hasattr(self.fallback, name):
                return getattr(self.fallback, name)
            raise AttributeError(
                f"'{self.__class__.__name__}' has no attribute '{name}'"
            )

        return getattr(obj, name)

    def _get_object(self) -> Any:
        """Thread-safe object retrieval with caching."""
        if self._cached_object is not None:
            return self._cached_object

        with _IMPORT_LOCK:
            # Double-check pattern
            if self._cached_object is not None:
                return self._cached_object

            # Check global cache first
            if self._cache_key in _IMPORT_CACHE:
                self._cached_object = _IMPORT_CACHE[self._cache_key]
                return self._cached_object

            # Perform actual import
            self._load_dependency()
            return self._cached_object

    def _load_dependency(self) -> None:
        """Load the dependency with performance monitoring."""
        if self._load_attempted:
            return

        self._load_attempted = True

        try:
            import sys
            import time

            start_time = time.perf_counter()

            logger.debug(f"Loading heavy dependency: {self.module_name}")

            # Special handling for test environments where modules are disabled
            # Check if module is explicitly disabled (common pattern: sys.modules['module'] = None)
            if (
                self.module_name in sys.modules
                and sys.modules[self.module_name] is None
            ):
                raise ImportError(
                    f"Module '{self.module_name}' is disabled in test environment"
                )

            # Import the module
            if self.module_name.startswith("."):
                module = importlib.import_module(self.module_name, package="heterodyne")
            else:
                module = importlib.import_module(self.module_name)

            # Additional check: ensure the imported module is not None
            # (can happen in test environments)
            if module is None:
                raise ImportError(f"Module '{self.module_name}' imported as None")

            # Extract specific attribute if requested
            if self.attribute:
                obj = getattr(module, self.attribute)
            else:
                obj = module

            # Final check: ensure the object is not None
            if obj is None and self.fallback is None:
                raise ImportError(
                    f"Attribute '{self.attribute}' in '{self.module_name}' is None"
                )

            # Cache the result
            self._cached_object = obj
            _IMPORT_CACHE[self._cache_key] = obj

            # Record performance metrics
            load_time = time.perf_counter() - start_time
            self._load_time = load_time
            _IMPORT_TIMES[self._cache_key] = load_time
            _IMPORT_SUCCESS[self._cache_key] = True

            logger.debug(f"Successfully loaded {self.module_name} in {load_time:.4f}s")

        except ImportError as e:
            _IMPORT_SUCCESS[self._cache_key] = False

            if self.required:
                logger.error(
                    f"Failed to load required dependency '{self.module_name}': {e}"
                )
                raise LazyImportError(
                    f"Required dependency '{self.module_name}' failed to load"
                ) from e
            logger.warning(
                f"Optional dependency '{self.module_name}' not available: {e}"
            )
            self._cached_object = self.fallback

        except Exception as e:
            _IMPORT_SUCCESS[self._cache_key] = False
            logger.error(f"Unexpected error loading '{self.module_name}': {e}")

            if self.required:
                raise LazyImportError(f"Failed to load '{self.module_name}'") from e
            self._cached_object = self.fallback

    @property
    def is_available(self) -> bool:
        """Check if dependency is available without triggering import."""
        if self._cache_key in _IMPORT_SUCCESS:
            return _IMPORT_SUCCESS[self._cache_key]

        # Special handling for test environments where modules are disabled
        import sys

        if self.module_name in sys.modules and sys.modules[self.module_name] is None:
            return False

        # Quick availability check without full import
        try:
            spec = importlib.util.find_spec(self.module_name)
            return spec is not None
        except (ImportError, ValueError):
            return False

    @property
    def load_time(self) -> float:
        """Get load time for performance monitoring."""
        return self._load_time


class BatchDependencyLoader:
    """
    Batch loader for multiple related dependencies.

    Optimizes loading of related scientific computing packages by batching
    import operations and minimizing overhead.
    """

    def __init__(self, dependencies: dict[str, dict[str, Any]]):
        """
        Initialize batch loader.

        Parameters
        ----------
        dependencies : dict[str, dict[str, Any]]
            Dictionary mapping dependency names to their configurations
        """
        self.dependencies = dependencies
        self.loaders: dict[str, HeavyDependencyLoader] = {}
        self._create_loaders()

    def _create_loaders(self) -> None:
        """Create individual loaders for each dependency."""
        for name, config in self.dependencies.items():
            self.loaders[name] = HeavyDependencyLoader(**config)

    def get(self, name: str) -> Any:
        """Get a dependency by name."""
        if name not in self.loaders:
            raise KeyError(f"Dependency '{name}' not configured")
        return self.loaders[name]._get_object()

    def load_all(self) -> dict[str, Any]:
        """Load all dependencies and return results."""
        results = {}
        for name, loader in self.loaders.items():
            try:
                results[name] = loader._get_object()
            except LazyImportError:
                results[name] = None
        return results

    @property
    def availability_report(self) -> dict[str, bool]:
        """Get availability report for all dependencies."""
        return {name: loader.is_available for name, loader in self.loaders.items()}


# Pre-configured scientific computing dependencies
SCIENTIFIC_DEPENDENCIES = {
    "numpy": {
        "module_name": "numpy",
        "required": True,
    },
    "scipy": {
        "module_name": "scipy",
        "required": False,
    },
    "scipy_optimize": {
        "module_name": "scipy.optimize",
        "required": False,
    },
    "scipy_stats": {
        "module_name": "scipy.stats",
        "required": False,
    },
    "numba": {
        "module_name": "numba",
        "required": False,
    },
    "numba_jit": {
        "module_name": "numba",
        "attribute": "jit",
        "required": False,
        # No-op decorator that works both as @jit and @jit(...)
        "fallback": lambda *args, **kwargs: (
            args[0] if (args and callable(args[0])) else (lambda f: f)
        ),
    },
    "matplotlib": {
        "module_name": "matplotlib",
        "required": False,
    },
    "matplotlib_pyplot": {
        "module_name": "matplotlib.pyplot",
        "required": False,
    },
    "cvxpy": {
        "module_name": "cvxpy",
        "required": False,
    },
    "psutil": {
        "module_name": "psutil",
        "required": False,
    },
}

# Global batch loader for scientific dependencies
scientific_deps = BatchDependencyLoader(SCIENTIFIC_DEPENDENCIES)

# Convenient access to common dependencies
numpy = scientific_deps.get("numpy")
scipy = scientific_deps.get("scipy")
scipy_optimize = scientific_deps.get("scipy_optimize")
numba = scientific_deps.get("numba")
matplotlib = scientific_deps.get("matplotlib")
cvxpy = scientific_deps.get("cvxpy")


@contextmanager
def import_timing():
    """Context manager for timing import operations."""
    import time

    start_time = time.perf_counter()
    try:
        yield
    finally:
        end_time = time.perf_counter()
        logger.info(f"Import operation took {end_time - start_time:.4f}s")


def get_import_performance_report() -> dict[str, Any]:
    """
    Get comprehensive performance report for all imports.

    Returns
    -------
    dict[str, Any]
        Performance metrics including load times and success rates
    """
    total_imports = len(_IMPORT_TIMES)
    successful_imports = sum(_IMPORT_SUCCESS.values())
    total_load_time = sum(_IMPORT_TIMES.values())

    report = {
        "summary": {
            "total_imports": total_imports,
            "successful_imports": successful_imports,
            "failed_imports": total_imports - successful_imports,
            "success_rate": (
                successful_imports / total_imports if total_imports > 0 else 0.0
            ),
            "total_load_time": total_load_time,
            "average_load_time": (
                total_load_time / total_imports if total_imports > 0 else 0.0
            ),
        },
        "individual_imports": {
            key: {
                "load_time": _IMPORT_TIMES.get(key, 0.0),
                "success": _IMPORT_SUCCESS.get(key, False),
            }
            for key in set(_IMPORT_TIMES.keys()) | set(_IMPORT_SUCCESS.keys())
        },
        "slowest_imports": sorted(
            _IMPORT_TIMES.items(), key=lambda x: x[1], reverse=True
        )[:5],
    }

    return report


def preload_critical_dependencies() -> None:
    """
    Preload critical dependencies in background.

    This can be called during application startup to warm up
    the most commonly used dependencies.
    """
    critical_deps = ["numpy", "scipy_optimize"]

    for dep_name in critical_deps:
        try:
            scientific_deps.get(dep_name)
            logger.debug(f"Preloaded critical dependency: {dep_name}")
        except LazyImportError:
            logger.warning(f"Failed to preload critical dependency: {dep_name}")


def clear_import_cache() -> None:
    """Clear the import cache for testing purposes."""
    global _IMPORT_CACHE, _IMPORT_TIMES, _IMPORT_SUCCESS
    with _IMPORT_LOCK:
        _IMPORT_CACHE.clear()
        _IMPORT_TIMES.clear()
        _IMPORT_SUCCESS.clear()

        # Also reset all loader instances in scientific_deps
        for loader in scientific_deps.loaders.values():
            loader._cached_object = None
            loader._load_attempted = False
            loader._load_time = 0.0


# Backward compatibility aliases
lazy_numpy = numpy
lazy_scipy = scipy
lazy_matplotlib = matplotlib
