{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Embeddings in FireProx\n",
    "\n",
    "This notebook demonstrates how to work with vector embeddings in FireProx using the `FireVector` class.\n",
    "\n",
    "## Important Limitations\n",
    "\n",
    "**Firestore Emulator Does NOT Support Vector Embeddings**\n",
    "\n",
    "- Vector embeddings are a production-only feature\n",
    "- The Firestore emulator will reject any operations involving vectors\n",
    "- All examples in this notebook require a real Firestore instance\n",
    "- See [GitHub Issue #7216](https://github.com/firebase/firebase-tools/issues/7216)\n",
    "\n",
    "**Vector Constraints**:\n",
    "- Maximum 2048 dimensions per vector\n",
    "- Vectors cannot be nested inside arrays or maps\n",
    "- Vectors must be at the top level of a document field\n",
    "\n",
    "## What are Vector Embeddings?\n",
    "\n",
    "Vector embeddings are numerical representations of data (text, images, etc.) that capture semantic meaning. They enable:\n",
    "- Semantic search (find similar documents)\n",
    "- Clustering and classification\n",
    "- Recommendation systems\n",
    "- Question answering\n",
    "\n",
    "FireProx provides the `FireVector` class to wrap Firestore's native Vector type with a Pythonic interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**Note**: These examples will fail with the emulator. You must use a real Firestore project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import firestore\n",
    "\n",
    "from fire_prox import AsyncFireProx, FireProx, FireVector\n",
    "\n",
    "# Initialize clients (PRODUCTION ONLY - will not work with emulator)\n",
    "project_id = 'your-project-id'  # Replace with your actual project ID\n",
    "\n",
    "# Synchronous client\n",
    "sync_client = firestore.Client(project=project_id)\n",
    "db = FireProx(sync_client)\n",
    "\n",
    "# Asynchronous client\n",
    "async_client = firestore.AsyncClient(project=project_id)\n",
    "async_db = AsyncFireProx(async_client)\n",
    "\n",
    "print(\"✓ Connected to production Firestore\")\n",
    "print(\"⚠️  Remember: Vector embeddings DO NOT work with the emulator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 1: Creating and Storing Vectors (Sync)\n",
    "\n",
    "Create a `FireVector` from a list of floats and store it in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a collection for documents with embeddings\n",
    "documents = db.collection('semantic_documents')\n",
    "\n",
    "# Create a simple 3-dimensional embedding\n",
    "doc1 = documents.new()\n",
    "doc1.title = \"Introduction to Machine Learning\"\n",
    "doc1.content = \"Machine learning is a subset of artificial intelligence...\"\n",
    "doc1.embedding = FireVector([0.12, 0.45, 0.78])  # Simple 3D embedding\n",
    "\n",
    "# Save to Firestore\n",
    "doc1.save(doc_id='ml_intro')\n",
    "\n",
    "print(f\"✓ Saved document with {doc1.embedding.dimensions}-dimensional embedding\")\n",
    "print(f\"  Title: {doc1.title}\")\n",
    "print(f\"  Embedding: {doc1.embedding.to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 2: Reading Vectors from Firestore (Sync)\n",
    "\n",
    "FireProx automatically converts native Firestore Vectors to `FireVector` objects when reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the document back\n",
    "retrieved = db.doc('semantic_documents/ml_intro')\n",
    "retrieved.fetch()\n",
    "\n",
    "# Access the vector - automatically converted to FireVector\n",
    "print(f\"Document: {retrieved.title}\")\n",
    "print(f\"Embedding type: {type(retrieved.embedding)}\")\n",
    "print(f\"Dimensions: {retrieved.embedding.dimensions}\")\n",
    "print(f\"Values: {retrieved.embedding.to_list()}\")\n",
    "\n",
    "# You can iterate over the vector\n",
    "print(\"\\nVector values:\")\n",
    "for i, value in enumerate(retrieved.embedding):\n",
    "    print(f\"  Dimension {i}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 3: Working with Higher-Dimensional Embeddings\n",
    "\n",
    "Real-world embeddings typically have many more dimensions (e.g., 384, 768, 1536 dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Create a document with a realistic 384-dimensional embedding\n",
    "# (typical for models like sentence-transformers/all-MiniLM-L6-v2)\n",
    "doc2 = documents.new()\n",
    "doc2.title = \"Deep Learning Fundamentals\"\n",
    "doc2.content = \"Deep learning uses neural networks with multiple layers...\"\n",
    "\n",
    "# Generate a random 384-dimensional embedding (in practice, use a real model)\n",
    "embedding_384d = [random.random() for _ in range(384)]\n",
    "doc2.embedding = FireVector(embedding_384d)\n",
    "\n",
    "doc2.save(doc_id='dl_fundamentals')\n",
    "\n",
    "print(f\"✓ Saved document with {doc2.embedding.dimensions}-dimensional embedding\")\n",
    "print(f\"  First 5 dimensions: {doc2.embedding.to_list()[:5]}\")\n",
    "print(f\"  Last 5 dimensions: {doc2.embedding.to_list()[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 4: Dimension Validation\n",
    "\n",
    "FireVector enforces Firestore's maximum dimension limit of 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fire_prox.fire_vector import MAX_DIMENSIONS\n",
    "\n",
    "print(f\"Firestore maximum dimensions: {MAX_DIMENSIONS}\")\n",
    "\n",
    "# This works - exactly at the limit\n",
    "max_vector = FireVector([0.1] * MAX_DIMENSIONS)\n",
    "print(f\"✓ Created vector with {max_vector.dimensions} dimensions (max allowed)\")\n",
    "\n",
    "# This will fail - exceeds the limit\n",
    "try:\n",
    "    too_large = FireVector([0.1] * (MAX_DIMENSIONS + 1))\n",
    "except ValueError as e:\n",
    "    print(f\"\\n✗ Error: {e}\")\n",
    "\n",
    "# You can disable validation if needed (not recommended)\n",
    "unvalidated = FireVector([0.1] * 3000, validate=False)\n",
    "print(f\"\\n⚠️  Created unvalidated vector with {unvalidated.dimensions} dimensions\")\n",
    "print(\"   (This will fail when you try to save to Firestore!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 5: Async Operations with Vectors\n",
    "\n",
    "Vectors work seamlessly with the async API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async version - store and retrieve vectors\n",
    "async_documents = async_db.collection('semantic_documents')\n",
    "\n",
    "# Create and save\n",
    "async_doc = async_documents.new()\n",
    "async_doc.title = \"Neural Network Architectures\"\n",
    "async_doc.content = \"Neural networks consist of interconnected layers...\"\n",
    "async_doc.embedding = FireVector([0.23, 0.56, 0.89])\n",
    "\n",
    "await async_doc.save(doc_id='nn_architectures')\n",
    "\n",
    "print(f\"✓ Saved async document with {async_doc.embedding.dimensions}D embedding\")\n",
    "\n",
    "# Read back\n",
    "async_retrieved = async_db.doc('semantic_documents/nn_architectures')\n",
    "await async_retrieved.fetch()\n",
    "\n",
    "print(f\"\\nRetrieved: {async_retrieved.title}\")\n",
    "print(f\"Embedding: {async_retrieved.embedding.to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 6: Real-World Example - Text Embeddings\n",
    "\n",
    "Simulate generating embeddings from text using a hypothetical embedding model.\n",
    "\n",
    "**Note**: This example shows the pattern. In production, you would use a real embedding model like:\n",
    "- OpenAI's `text-embedding-ada-002` (1536 dimensions)\n",
    "- Sentence Transformers (384-768 dimensions)\n",
    "- Google's Vertex AI embeddings (768 dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_embedding(text: str, dimensions: int = 384) -> list:\n",
    "    \"\"\"\n",
    "    Simulate an embedding model (in production, use a real model).\n",
    "    \n",
    "    Real examples:\n",
    "    - openai.embeddings.create(input=text, model=\"text-embedding-ada-002\")\n",
    "    - sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2').encode(text)\n",
    "    - vertexai.TextEmbeddingModel.from_pretrained('textembedding-gecko').get_embeddings([text])\n",
    "    \"\"\"\n",
    "    import hashlib\n",
    "    import random\n",
    "\n",
    "    # Use text hash as seed for reproducible \"embeddings\"\n",
    "    seed = int(hashlib.md5(text.encode()).hexdigest(), 16) % (2**32)\n",
    "    random.seed(seed)\n",
    "\n",
    "    return [random.gauss(0, 1) for _ in range(dimensions)]\n",
    "\n",
    "# Example documents to embed\n",
    "articles = [\n",
    "    {\n",
    "        'title': 'Introduction to Python',\n",
    "        'content': 'Python is a high-level programming language known for its simplicity and readability.'\n",
    "    },\n",
    "    {\n",
    "        'title': 'JavaScript Basics',\n",
    "        'content': 'JavaScript is the programming language of the web, enabling interactive websites.'\n",
    "    },\n",
    "    {\n",
    "        'title': 'Database Design Principles',\n",
    "        'content': 'Good database design ensures data integrity, reduces redundancy, and improves query performance.'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Store articles with embeddings\n",
    "for i, article in enumerate(articles):\n",
    "    doc = documents.new()\n",
    "    doc.title = article['title']\n",
    "    doc.content = article['content']\n",
    "\n",
    "    # Generate embedding from content\n",
    "    embedding = generate_fake_embedding(article['content'])\n",
    "    doc.embedding = FireVector(embedding)\n",
    "\n",
    "    doc.save(doc_id=f'article_{i}')\n",
    "    print(f\"✓ Saved: {article['title']} ({doc.embedding.dimensions}D)\")\n",
    "\n",
    "print(\"\\n✓ All articles embedded and stored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 7: Vector Properties and Methods\n",
    "\n",
    "`FireVector` provides a Pythonic interface for working with embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector for demonstration\n",
    "demo_vector = FireVector([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "# 1. Length / Dimensions\n",
    "print(f\"Dimensions: {demo_vector.dimensions}\")\n",
    "print(f\"Length: {len(demo_vector)}\")\n",
    "\n",
    "# 2. Indexing\n",
    "print(f\"\\nFirst dimension: {demo_vector[0]}\")\n",
    "print(f\"Last dimension: {demo_vector[-1]}\")\n",
    "\n",
    "# 3. Iteration\n",
    "print(\"\\nAll dimensions:\")\n",
    "for i, value in enumerate(demo_vector):\n",
    "    print(f\"  [{i}]: {value}\")\n",
    "\n",
    "# 4. Convert to list (for further processing)\n",
    "values = demo_vector.to_list()\n",
    "print(f\"\\nAs list: {values}\")\n",
    "\n",
    "# 5. Equality comparison\n",
    "vector_a = FireVector([0.1, 0.2, 0.3])\n",
    "vector_b = FireVector([0.1, 0.2, 0.3])\n",
    "vector_c = FireVector([0.1, 0.2, 0.4])\n",
    "\n",
    "print(f\"\\nvector_a == vector_b: {vector_a == vector_b}\")  # True\n",
    "print(f\"vector_a == vector_c: {vector_a == vector_c}\")  # False\n",
    "\n",
    "# 6. String representations\n",
    "print(f\"\\nstr(): {str(demo_vector)}\")\n",
    "print(f\"repr(): {repr(demo_vector)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 8: Vector Type Conversion\n",
    "\n",
    "FireProx handles conversion between `FireVector` and native Firestore `Vector` automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a FireVector\n",
    "fire_vec = FireVector([0.1, 0.2, 0.3])\n",
    "print(f\"FireVector: {type(fire_vec).__name__}\")\n",
    "print(f\"  {fire_vec}\")\n",
    "\n",
    "# Convert to native Firestore Vector (happens automatically during save)\n",
    "native_vec = fire_vec.to_firestore_vector()\n",
    "print(f\"\\nNative Vector: {type(native_vec).__name__}\")\n",
    "\n",
    "# Convert back to FireVector (happens automatically during fetch)\n",
    "converted_back = FireVector.from_firestore_vector(native_vec)\n",
    "print(f\"\\nConverted back: {type(converted_back).__name__}\")\n",
    "print(f\"  {converted_back}\")\n",
    "\n",
    "# Verify they're equal\n",
    "print(f\"\\nEqual after round-trip: {fire_vec == converted_back}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server-Side Embedding Generation\n",
    "\n",
    "### Firebase Extension for Automatic Embeddings\n",
    "\n",
    "Firebase provides an extension that can automatically generate embeddings when documents are created or updated:\n",
    "\n",
    "**Extension**: `firestore-genkit-embedding`\n",
    "\n",
    "**How it works**:\n",
    "1. You configure which collection and field to monitor\n",
    "2. When a document is created/updated, the extension triggers\n",
    "3. It sends the text field to an embedding model (Vertex AI / Gemini)\n",
    "4. The generated embedding is stored back in the document\n",
    "\n",
    "**Configuration Example**:\n",
    "```yaml\n",
    "# Extension configuration\n",
    "collection: semantic_documents\n",
    "input_field: content\n",
    "output_field: embedding\n",
    "model: textembedding-gecko@003  # Vertex AI model\n",
    "dimensions: 768\n",
    "```\n",
    "\n",
    "**Workflow**:\n",
    "```python\n",
    "# 1. Save document with text content (no embedding yet)\n",
    "doc = documents.new()\n",
    "doc.title = \"My Article\"\n",
    "doc.content = \"This is the text content to embed...\"\n",
    "doc.save()\n",
    "\n",
    "# 2. Extension automatically triggers:\n",
    "#    - Reads doc.content\n",
    "#    - Calls Vertex AI embedding API\n",
    "#    - Writes result to doc.embedding\n",
    "\n",
    "# 3. Read back with embedding (after extension completes)\n",
    "import time\n",
    "time.sleep(2)  # Wait for extension to process\n",
    "doc.fetch(force=True)\n",
    "print(f\"Auto-generated embedding: {doc.embedding.dimensions}D\")\n",
    "```\n",
    "\n",
    "**Important Notes**:\n",
    "- Extension does NOT work with emulator (production only)\n",
    "- Requires Vertex AI API enabled\n",
    "- Incurs costs for embedding API calls\n",
    "- Processing is asynchronous (not instant)\n",
    "- Uses Cloud Functions under the hood\n",
    "\n",
    "**Alternative: Client-Side Embeddings**\n",
    "\n",
    "For more control, generate embeddings in your application:\n",
    "\n",
    "```python\n",
    "# Using OpenAI\n",
    "import openai\n",
    "\n",
    "response = openai.embeddings.create(\n",
    "    input=\"Your text here\",\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "embedding = response.data[0].embedding\n",
    "\n",
    "doc.embedding = FireVector(embedding)\n",
    "doc.save()\n",
    "\n",
    "# Using Sentence Transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding = model.encode(\"Your text here\").tolist()\n",
    "\n",
    "doc.embedding = FireVector(embedding)\n",
    "doc.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete test documents\n",
    "test_docs = [\n",
    "    'ml_intro',\n",
    "    'dl_fundamentals',\n",
    "    'nn_architectures',\n",
    "    'article_0',\n",
    "    'article_1',\n",
    "    'article_2'\n",
    "]\n",
    "\n",
    "for doc_id in test_docs:\n",
    "    try:\n",
    "        doc = db.doc(f'semantic_documents/{doc_id}')\n",
    "        doc.delete()\n",
    "        print(f\"✓ Deleted {doc_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  (Could not delete {doc_id}: {e})\")\n",
    "\n",
    "print(\"\\n✓ Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **FireVector Wrapper**: Pythonic interface for Firestore vector embeddings\n",
    "2. **Automatic Conversion**: FireProx handles Vector ↔ FireVector conversion seamlessly\n",
    "3. **Validation**: Enforces 2048 dimension limit by default\n",
    "4. **Sync & Async**: Works with both synchronous and asynchronous APIs\n",
    "5. **Production Only**: Vectors do NOT work with Firestore emulator\n",
    "\n",
    "### Limitations to Remember\n",
    "\n",
    "- ⚠️ Emulator does not support vectors\n",
    "- ⚠️ Maximum 2048 dimensions\n",
    "- ⚠️ Vectors cannot be nested in arrays/maps\n",
    "- ⚠️ Vectors must be top-level document fields\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Semantic Search**: Find documents similar to a query\n",
    "- **Content Recommendations**: Suggest related articles/products\n",
    "- **Question Answering**: Match questions to relevant answers\n",
    "- **Image Search**: Find similar images by embedding\n",
    "- **Clustering**: Group similar documents together\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To build a complete semantic search system:\n",
    "1. Choose an embedding model (OpenAI, Sentence Transformers, Vertex AI)\n",
    "2. Generate embeddings for your documents\n",
    "3. Store using `FireVector`\n",
    "4. Implement similarity search (cosine similarity, nearest neighbors)\n",
    "5. Consider using Firestore's vector search capabilities (if available)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
