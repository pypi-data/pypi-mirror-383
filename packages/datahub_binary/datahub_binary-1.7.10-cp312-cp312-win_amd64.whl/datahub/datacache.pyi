import polars as pl
from _typeshed import Incomplete
from datahub import PostgresSetting as PostgresSetting, Setting as Setting, StarRocksSetting as StarRocksSetting
from datahub.datahub import DataHub as DataHub
from datahub.utils.logger import logger as logger
from datetime import datetime, time
from enum import Enum
from typing import Any, Literal, Sequence

class UpdateLevel(Enum):
    META = 'meta'
    DF = 'df'

class KVJsonDB:
    db_path: Incomplete
    def __init__(self, db_path: str) -> None: ...
    def set(self, key: str, value: Any): ...
    def get(self, key: str, default: Any | None = None) -> Any | None: ...
    def delete(self, key: str) -> bool: ...
    def all(self) -> dict[str, Any]: ...
    def all_keys(self) -> list[str]: ...
    def clear(self) -> None: ...
    def close(self) -> None: ...

class DataCache:
    prefix: Incomplete
    data_path: Incomplete
    update_cache: Incomplete
    cache_only: Incomplete
    datahub: Incomplete
    meta_db: Incomplete
    data_files: Incomplete
    def __init__(self, datahub: DataHub, data_path: str, prefix: str, update_cache: bool = False, cache_only: bool = False) -> None: ...
    def get_data_matrix(self, trade_time: datetime, factors: list[str], instrument_ids: list[str], **kwargs) -> pl.DataFrame: ...
    def get_cache_filepath(self, trade_time: datetime) -> str: ...
    def update_datacache(self, filepath: str, df: pl.DataFrame, update_level: Sequence[UpdateLevel] = ()): ...
    def read_from_cache(self, trade_time: datetime, factors: list[str], instrument_ids: list[str], **kwargs) -> pl.DataFrame: ...
    def sync_all_meta_info(self) -> None: ...
    @staticmethod
    def f64_to_f32(df: pl.DataFrame) -> pl.DataFrame: ...
    @staticmethod
    def get_missing_times(df: pl.DataFrame, intra_time_list: list[time]) -> list[time]: ...
    @staticmethod
    def get_missing_instruments(df: pl.DataFrame, instruments: list[str]) -> list[str]: ...
    @staticmethod
    def get_missing_factors(df: pl.DataFrame, factors: list[str]) -> list[str]: ...

class FactorDataCache(DataCache):
    def get_data_matrix(self, trade_time: datetime, factors: list[str], instrument_ids: list[str], **kwargs) -> pl.DataFrame: ...
    def read_factor_from_cache(self, trade_time: datetime, factors: list[str], instrument_ids: list[str]) -> pl.DataFrame: ...

class RiskFactorDataCache(DataCache):
    version: Incomplete
    def __init__(self, datahub: DataHub, version: str, data_path: str, prefix: str, update_cache: bool = False) -> None: ...
    def get_data_matrix(self, trade_time: datetime, factors: list[str], instrument_ids: list[str], **kwargs) -> pl.DataFrame: ...
    def read_risk_factors_from_cache(self, trade_time: datetime, factors: list[str], instrument_ids: list[str]) -> pl.DataFrame: ...

class ReturnDataCache(DataCache):
    def get_data_matrix(self, trade_time: datetime, factors: list[str], instrument_ids: list[str], **kwargs) -> pl.DataFrame: ...
    def read_return_from_cache(self, trade_time: datetime, factors: list[str], instrument_ids: list[str], adj_method: Literal['forward'] = 'forward') -> pl.DataFrame: ...

class HFTFactorDataCache(DataCache):
    def read_factor_from_cache(self, trade_time: datetime, factors: list[str], instrument_ids: list[str]) -> pl.DataFrame: ...

class HFTReturnDataCache(DataCache):
    def read_return_from_cache(self, trade_time: datetime, factors: list[str], instrument_ids: list[str], adj_method: Literal['forward'] = 'forward') -> pl.DataFrame: ...

def main() -> None: ...
