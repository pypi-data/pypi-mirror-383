{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(tutorials-hubbard-base)=\n",
    "\n",
    "# Computing Hubbard parameters\n",
    "\n",
    "In this tutorial you will learn how to calculate the Hubbard parameters step by step using `aiida-hubbard`.\n",
    "\n",
    "We can divide this goal in three phases:\n",
    "\n",
    "* __Define the manifolds__: define the target Hubbard manifolds via the {{ hubbard_structure }}\n",
    "* __SCF ground-state__: calculate the ground-state using the {py:class}`~aiida_quantumespresso.workflows.pw.base.PwBaseWorkChain`\n",
    "* __DFPT calculation__: use the {py:class}`~aiida_hubbard.workflow.hp.base.HpBaseWorkChain` to do a self-consistent perturbation calculation to predict the Hubbard parameters.\n",
    "\n",
    "In this tutorial we will make use of the silicon structure to give you an overall understanding of the usage of the package.\n",
    "If you are interested in more advanced features, please have a look at the [next tutorial](./2_parallel_hubbard.ipynb) or to the [how tos](howto).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining the target manifold through the `HubbardStructureData`\n",
    "\n",
    "The Hubbard correction is a corrective term that is added to the Hamiltonian of a system\n",
    "which suffers from great __self-interaction errors__. This is usually the case for transition\n",
    "metals on their _d_ manifolds. An extra correction to account for the hybridization can be accounted\n",
    "for with the ligands, typically belonging to the _p_ element group. Such interaction needs to be\n",
    "localized in space. This is the reason why we need to define the __projectors__. Quantum ESPRESSO\n",
    "allows you to define different type of projections $| \\phi^I_m \\rangle$ ($m$ orbital quantum number, $I$ atom in cell). Currently, the __ortho-atomic__ projectors\n",
    "are the most accurate ones implemented. \n",
    "\n",
    "Still, we need to ask the program on _which atoms_ $I$ and _which manifolds_ $m$ to project and correct for this\n",
    "self-interaction.\n",
    "\n",
    "Since manifolds and atoms belong to the structure, then you need to definet them together as an {{ hubbard_structure }}.\n",
    "\n",
    "In the following, we take LiCoO{sub}`2` as example, and we suppose we want to target the _3d_ orbitals of cobalt and the intersite interaction between _2p_ of oxygen and _3d_ of cobalt.\n",
    "\n",
    "```{note}\n",
    "By default we set ortho-atomic projectors and we use the Dudarev formulation.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from local_module import load_temp_profile\n",
    "\n",
    "# If you download this file, you can run it with your own profile.\n",
    "# Put these lines instead:\n",
    "# from aiida import load_profile\n",
    "# load_profile()\n",
    "data = load_temp_profile(\n",
    "    name=\"hubbard-base-tutorial\",\n",
    "    add_computer=True,\n",
    "    add_pw_code=True,\n",
    "    add_hp_code=True,\n",
    "    add_sssp=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the {{ hubbard_structure }}:\n",
    "\n",
    ":::{note}\n",
    ":class: dropdown\n",
    "\n",
    "If you already have a {py:class}`aiida.orm.StructureData`, you can load the structure information in `HubbardStructureData` as follows:\n",
    "\n",
    "```python\n",
    "my_structure = load_node(IDENTIFIER)\n",
    "hubbard_structure = HubbardStructureData.from_structure(my_structure)\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_quantumespresso.data.hubbard_structure import HubbardStructureData\n",
    "\n",
    "a, b, c, d = 1.40803, 0.81293, 4.68453, 1.62585\n",
    "cell = [[a, -b, c], [0.0, d, c], [-a, -b, c]]\n",
    "sites = [\n",
    "    ['Co', 'Co', (0, 0, 0)],\n",
    "    ['O',   'O', (0, 0, 3.6608)], \n",
    "    ['O',   'O', (0, 0, 10.392)], \n",
    "    ['Li', 'Li', (0, 0, 7.0268)],\n",
    "]\n",
    "hubbard_structure = HubbardStructureData(cell=cell, sites=sites)\n",
    "hubbard_structure.initialize_onsites_hubbard(\"Co\", \"3d\")\n",
    "hubbard_structure.initialize_intersites_hubbard(\"Co\", \"3d\", \"O\", \"2p\")\n",
    "hubbard_structure.store()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize what will be print in the Hubbard card of Quantum ESPRESSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_quantumespresso.utils.hubbard import HubbardUtils\n",
    "print(HubbardUtils(hubbard_structure).get_hubbard_card())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the desired interactions have been initialized correctly. \n",
    "This is important because `hp.x` needs to know which atoms need to be perturbed. \n",
    "As you will see later, `hp.x` will take care of adding the remaining interactions with neighbouring atoms.\n",
    "\n",
    ":::{important}\n",
    "When you use your own structures, make sure to have your 'Hubbard atoms' first in the list of atoms.\n",
    "This is due to the way the `hp.x` routine works internally, requiring those to be first.\n",
    "You can simply do this with the following snippet (IF THE NODE IS YET NOT STORED!):\n",
    "\n",
    "```python\n",
    "from aiida_quantumespresso.utils.hubbard import HubbardUtils\n",
    "HubbardUtils(hubbard_structure).reorder_atoms\n",
    "```\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the SCF ground-state\n",
    "\n",
    "Now that we have defined the structure, we can calculate its ground-state via an SCF using the `PwBaseWorkChain`.\n",
    "We can fill the inputs of the builder of the `PwBaseWorkChain` through the `get_builder_from_protocol()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from aiida.engine import run_get_node\n",
    "from aiida.orm import KpointsData\n",
    "from aiida_quantumespresso.workflows.pw.base import PwBaseWorkChain\n",
    "from aiida_quantumespresso.common.types import ElectronicType\n",
    "kpoints = KpointsData()\n",
    "kpoints.set_kpoints_mesh([1,1,1])\n",
    "\n",
    "builder = PwBaseWorkChain.get_builder_from_protocol(\n",
    "    code=data.pw_code, # modify here if you downloaded the notebook\n",
    "    structure=hubbard_structure,\n",
    "    protocol=\"fast\",\n",
    "    electronic_type=ElectronicType.INSULATOR,\n",
    "    overrides={\"kpoints\":kpoints, \"clean_workdir\":False}\n",
    ")\n",
    "results, pw_node = run_get_node(builder)\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can notice from the results, the workchain (actually, the `PwCalculation`!) has a `remote_folder` output.\n",
    "This is what we need in order to run the `HpBaseWorkChain`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFPT calculation of Hubbard parameters\n",
    "\n",
    "We can perturb the ground-state previously found to compute the Hubbard parameters.\n",
    "Here we will need to use the `HpBaseWorkChain`, and link the `remote_folder` previously produced via the `parent_scf` input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import Dict\n",
    "from aiida_hubbard.workflows.hp.base import HpBaseWorkChain\n",
    "\n",
    "qpoints = KpointsData()\n",
    "qpoints.set_kpoints_mesh([1,1,1])\n",
    "\n",
    "builder = HpBaseWorkChain.get_builder()\n",
    "builder.hp.code = data.hp_code\n",
    "builder.hp.hubbard_structure = data.structure\n",
    "builder.hp.parameters = Dict({\"INPUTHP\":{\"conv_thr_chi\": 1e-4}})\n",
    "builder.hp.qpoints = qpoints\n",
    "builder.hp.parent_scf = pw_node.outputs.remote_folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or via the `get_builder_from_protocol`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from aiida_hubbard.workflows.hp.base import HpBaseWorkChain\n",
    "\n",
    "builder = HpBaseWorkChain.get_builder_from_protocol(\n",
    "    code=data.hp_code, # modify here if you downloaded the notebook\n",
    "    protocol=\"fast\",\n",
    "    parent_scf_folder=pw_node.outputs.remote_folder,\n",
    "    overrides={'hp':{'hubbard_structure':hubbard_structure}},\n",
    ")\n",
    "\n",
    "results, hp_node = run_get_node(builder)\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ Let's inspect the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(HubbardUtils(results['hubbard_structure']).get_hubbard_card())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final considerations\n",
    "\n",
    "We managed to compute the Hubbard parameters of LiCoO2  __fully__ ___ab initio___! ðŸŽ‰\n",
    "However, we had to execute quite a few steps manually, which can be tedious and error prone.\n",
    "Moreover, there are the following considerations:\n",
    "\n",
    "1. For larger and more complex structures you will need to perturb many more atoms.\n",
    "   Moreover, to get converged results you will need more than one q point.\n",
    "   Click [here](./2_parallel_hubbard.ipynb) to learn how to parallelize over atoms and q points.\n",
    "2. To do a _full_ self-consistent calculation of these parameters, you should _relax_ your structure with the Hubbard parameters from the `hp.x` run, repeat the steps of this tutorial, relax _again_, and do this procedure over and over till convergence.\n",
    "   Learn the automated way [here](./3_self_consistent.ipynb)!\n",
    "\n",
    ":::{admonition} Learn more and in details\n",
    ":class: hint\n",
    "\n",
    "To learn the full sets of inputs, to use proficiently the `get_builder_from_protocol` and more, have a look at the following sections:\n",
    "- [Specific how tos](howto/workflows/hp/base.md)\n",
    "- [General information of the implemented workchain](topics/workflows/hp/base.md)\n",
    ":::\n",
    "\n",
    ":::{note}\n",
    "We suggest to proceed first with the tutorial for point (1) and then the one for point (2). \n",
    "Nevertheless, tutorial (1) is not strictly necessary for (2).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
