{
  "models": {
    "gpt-4": {
      "context_length": 128000,
      "max_output_tokens": 4096,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": false,
      "audio_support": false,
      "source": "OpenAI official docs"
    },
    "gpt-4o": {
      "context_length": 128000,
      "max_output_tokens": 4096,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": true,
      "audio_support": true,
      "notes": "Multimodal, optimized for speed",
      "source": "OpenAI official docs"
    },
    "gpt-4o-long-output": {
      "context_length": 128000,
      "max_output_tokens": 64000,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": true,
      "audio_support": true,
      "notes": "16x output capacity variant",
      "source": "OpenAI official docs"
    },
    "gpt-4o-mini": {
      "context_length": 128000,
      "max_output_tokens": 16000,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": true,
      "audio_support": true,
      "source": "OpenAI official docs"
    },
    "gpt-3.5-turbo": {
      "context_length": 16385,
      "max_output_tokens": 4096,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": false,
      "audio_support": false,
      "source": "OpenAI official docs"
    },
    "o1": {
      "context_length": 128000,
      "max_output_tokens": 32768,
      "tool_support": "none",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "Reasoning model, no native tool support",
      "source": "OpenAI official docs"
    },
    "o1-mini": {
      "context_length": 128000,
      "max_output_tokens": 65536,
      "tool_support": "none",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "OpenAI official docs"
    },
    "o3": {
      "context_length": 128000,
      "max_output_tokens": 32768,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": false,
      "audio_support": false,
      "notes": "May hallucinate tools with complex sets",
      "source": "OpenAI official docs"
    },
    "o3-mini": {
      "context_length": 128000,
      "max_output_tokens": 32768,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": false,
      "audio_support": false,
      "notes": "Known issues in Assistants API",
      "source": "OpenAI official docs"
    },
    "claude-3.5-sonnet": {
      "context_length": 200000,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": true,
      "image_resolutions": [
        "up to 1568x1568"
      ],
      "audio_support": false,
      "notes": "disable_parallel_tool_use option available",
      "source": "Anthropic official docs"
    },
    "claude-3.7-sonnet": {
      "context_length": 200000,
      "max_output_tokens": 128000,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": true,
      "image_resolutions": [
        "up to 1568x1568"
      ],
      "audio_support": false,
      "notes": "Extended output with beta header",
      "source": "Anthropic official docs"
    },
    "claude-3.5-haiku": {
      "context_length": 200000,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": true,
      "image_resolutions": [
        "up to 1568x1568"
      ],
      "audio_support": false,
      "notes": "More likely to call unnecessary tools",
      "source": "Anthropic official docs"
    },
    "claude-3-opus": {
      "context_length": 200000,
      "max_output_tokens": 4096,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": false,
      "max_tools": 1,
      "vision_support": true,
      "image_resolutions": [
        "up to 1568x1568"
      ],
      "audio_support": false,
      "source": "Anthropic official docs"
    },
    "claude-3-sonnet": {
      "context_length": 200000,
      "max_output_tokens": 4096,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": false,
      "max_tools": 1,
      "vision_support": true,
      "image_resolutions": [
        "up to 1568x1568"
      ],
      "audio_support": false,
      "source": "Anthropic official docs"
    },
    "claude-3-haiku": {
      "context_length": 200000,
      "max_output_tokens": 4096,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": false,
      "max_tools": 1,
      "vision_support": true,
      "image_resolutions": [
        "up to 1568x1568"
      ],
      "audio_support": false,
      "source": "Anthropic official docs"
    },
    "llama-3.2-1b": {
      "context_length": 8192,
      "max_output_tokens": 2048,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "Text only, optimized for edge",
      "source": "Meta official docs"
    },
    "llama-3.2-3b": {
      "context_length": 8192,
      "max_output_tokens": 2048,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "Text only, optimized for edge",
      "source": "Meta official docs"
    },
    "llama-3.2-11b-vision": {
      "context_length": 128000,
      "max_output_tokens": 2048,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": true,
      "image_resolutions": [
        "variable"
      ],
      "audio_support": false,
      "notes": "Vision model, may be limited by deployment platform",
      "source": "Meta official docs"
    },
    "llama-3.3-70b": {
      "context_length": 128000,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": true,
      "vision_support": false,
      "audio_support": false,
      "notes": "Improved multilingual and tool use",
      "source": "Meta official docs"
    },
    "llama-3.1-8b": {
      "context_length": 128000,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "prompted",
      "parallel_tools": true,
      "vision_support": false,
      "audio_support": false,
      "notes": "Fine-tuned on tool calling",
      "source": "Meta official docs"
    },
    "llama-3.1-70b": {
      "context_length": 128000,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "prompted",
      "parallel_tools": true,
      "vision_support": false,
      "audio_support": false,
      "notes": "Fine-tuned on tool calling",
      "source": "Meta official docs"
    },
    "llama-3.1-405b": {
      "context_length": 128000,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "prompted",
      "parallel_tools": true,
      "vision_support": false,
      "audio_support": false,
      "notes": "Largest Llama model",
      "source": "Meta official docs"
    },
    "llama-4": {
      "context_length": 10000000,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "vision_support": true,
      "audio_support": true,
      "notes": "Multimodal with early fusion, 109B total params (MoE)",
      "source": "Meta announcement"
    },
    "llama4-17b-scout-16e-instruct": {
      "context_length": 10485760,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "vision_support": true,
      "audio_support": false,
      "notes": "Scout variant with 16 experts, optimized for efficiency",
      "source": "Community testing"
    },
    "qwen2.5-0.5b": {
      "context_length": 32768,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Alibaba official docs"
    },
    "qwen2.5-1.5b": {
      "context_length": 32768,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Alibaba official docs"
    },
    "qwen2.5-3b": {
      "context_length": 32768,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Alibaba official docs"
    },
    "qwen2.5-7b": {
      "context_length": 131072,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "MCP support",
      "source": "Alibaba official docs"
    },
    "qwen2.5-14b": {
      "context_length": 131072,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Alibaba official docs"
    },
    "qwen2.5-32b": {
      "context_length": 131072,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Alibaba official docs"
    },
    "qwen2.5-72b": {
      "context_length": 131072,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Alibaba official docs"
    },
    "qwen3-0.6b": {
      "context_length": 32768,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "MCP support",
      "source": "Alibaba official docs"
    },
    "qwen3-1.7b": {
      "context_length": 32768,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "MCP support",
      "source": "Alibaba official docs"
    },
    "qwen3-4b": {
      "context_length": 131072,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "MCP support, extended with YaRN",
      "source": "Alibaba official docs"
    },
    "qwen3-32b": {
      "context_length": 131072,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "MCP support, thinking modes",
      "source": "Alibaba official docs"
    },
    "qwen3-30b-a3b": {
      "context_length": 40960,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "4-bit precision, optimized for efficiency. Prompted tool support.",
      "source": "Alibaba official docs"
    },
    "qwen3-coder-30b": {
      "context_length": 32768,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "prompted",
      "parallel_tools": true,
      "vision_support": false,
      "audio_support": false,
      "notes": "Code-focused model with native tool support via chatml-function-calling format",
      "source": "Alibaba official docs"
    },
    "qwen2-vl": {
      "context_length": 32768,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": true,
      "image_resolutions": [
        "variable"
      ],
      "audio_support": false,
      "source": "Alibaba official docs"
    },
    "qwen2.5-vl": {
      "context_length": 128000,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "native",
      "parallel_tools": false,
      "vision_support": true,
      "image_resolutions": [
        "variable"
      ],
      "audio_support": false,
      "source": "Alibaba official docs"
    },
    "phi-2": {
      "context_length": 2048,
      "max_output_tokens": 2048,
      "tool_support": "none",
      "structured_output": "none",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Microsoft official docs"
    },
    "phi-3-mini": {
      "context_length": 4096,
      "max_output_tokens": 4096,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "Poor JSON, use XML format",
      "source": "Microsoft official docs"
    },
    "phi-3-small": {
      "context_length": 8192,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Microsoft official docs"
    },
    "phi-3-medium": {
      "context_length": 128000,
      "max_output_tokens": 4096,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Microsoft official docs"
    },
    "phi-3.5-mini": {
      "context_length": 128000,
      "max_output_tokens": 4096,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Microsoft official docs"
    },
    "phi-3.5-moe": {
      "context_length": 128000,
      "max_output_tokens": 4096,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "Mixture of Experts",
      "source": "Microsoft official docs"
    },
    "phi-3-vision": {
      "context_length": 128000,
      "max_output_tokens": 4096,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": true,
      "image_resolutions": [
        "variable"
      ],
      "audio_support": false,
      "source": "Microsoft official docs"
    },
    "phi-4": {
      "context_length": 16000,
      "max_output_tokens": 16000,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "Extended to 16K during mid-training",
      "source": "Microsoft official docs"
    },
    "mistral-7b": {
      "context_length": 8192,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Mistral AI docs"
    },
    "mixtral-8x7b": {
      "context_length": 32768,
      "max_output_tokens": 32768,
      "tool_support": "prompted",
      "structured_output": "native",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "MoE architecture",
      "source": "Mistral AI docs"
    },
    "mixtral-8x22b": {
      "context_length": 65536,
      "max_output_tokens": 65536,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Mistral AI docs"
    },
    "mistral-small": {
      "context_length": 32768,
      "max_output_tokens": 32768,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Mistral AI docs"
    },
    "mistral-medium": {
      "context_length": 32768,
      "max_output_tokens": 32768,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Mistral AI docs"
    },
    "mistral-large": {
      "context_length": 128000,
      "max_output_tokens": 128000,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "vision_support": false,
      "audio_support": false,
      "source": "Mistral AI docs"
    },
    "codestral": {
      "context_length": 32768,
      "max_output_tokens": 32768,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "Code-specialized",
      "source": "Mistral AI docs"
    },
    "gemma-2b": {
      "context_length": 8192,
      "max_output_tokens": 8192,
      "tool_support": "none",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Google docs"
    },
    "gemma-7b": {
      "context_length": 8192,
      "max_output_tokens": 8192,
      "tool_support": "none",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Google docs"
    },
    "gemma2-9b": {
      "context_length": 8192,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "native",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Google docs"
    },
    "gemma2-27b": {
      "context_length": 8192,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "native",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "source": "Google docs"
    },
    "gemma3": {
      "context_length": 128000,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "vision_support": false,
      "audio_support": false,
      "notes": "Native function calling support introduced in Gemma 3",
      "source": "Google docs"
    },
    "codegemma": {
      "context_length": 8192,
      "max_output_tokens": 8192,
      "tool_support": "none",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "Code-specialized",
      "source": "Google docs"
    },
    "paligemma": {
      "context_length": 8192,
      "max_output_tokens": 1024,
      "tool_support": "none",
      "structured_output": "none",
      "parallel_tools": false,
      "vision_support": true,
      "image_resolutions": [
        "224x224",
        "448x448",
        "896x896"
      ],
      "audio_support": false,
      "notes": "Vision-language model",
      "source": "Google docs"
    },
    "glm-4": {
      "context_length": 128000,
      "max_output_tokens": 4096,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "ChatGLM4 from Zhipu AI",
      "source": "Model documentation"
    },
    "glm-4-9b": {
      "context_length": 128000,
      "max_output_tokens": 4096,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "9B parameter version",
      "source": "Model documentation"
    },
    "glm-4-9b-0414-4bit": {
      "context_length": 128000,
      "max_output_tokens": 4096,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "MLX quantized version",
      "source": "Model documentation"
    },
    "deepseek-r1": {
      "context_length": 32768,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "vision_support": false,
      "audio_support": false,
      "notes": "Reasoning model with native tool calling capability",
      "source": "MLX community"
    },
    "qwen3": {
      "context_length": 32768,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "Instruct model with good reasoning. Use prompted tool support when running via MLX.",
      "source": "MLX community"
    },
    "qwen3-14b": {
      "context_length": 131072,
      "max_output_tokens": 8192,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": false,
      "vision_support": false,
      "audio_support": false,
      "notes": "14B parameter model with prompted tool support",
      "source": "Alibaba official docs"
    },
    "qwen3-next-80b-a3b": {
      "context_length": 262144,
      "max_output_tokens": 16384,
      "tool_support": "prompted",
      "structured_output": "prompted",
      "parallel_tools": true,
      "vision_support": false,
      "audio_support": false,
      "notes": "Hybrid attention (Gated DeltaNet + Gated Attention), High-sparsity MoE with 512 experts/10 activated, Multi-Token Prediction, extensible to 1M tokens with YaRN scaling",
      "source": "Hugging Face model card"
    },
    "gpt-5": {
      "context_length": 200000,
      "max_output_tokens": 8192,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": true,
      "audio_support": true,
      "notes": "Next generation model with improved capabilities",
      "source": "Expected specifications"
    },
    "gpt-5-turbo": {
      "context_length": 200000,
      "max_output_tokens": 4096,
      "tool_support": "native",
      "structured_output": "native",
      "parallel_tools": true,
      "max_tools": -1,
      "vision_support": true,
      "audio_support": true,
      "notes": "Faster variant of GPT-5",
      "source": "Expected specifications"
    }
  },
  "tool_support_levels": {
    "native": "Full native API support with structured tool calling",
    "prompted": "Works with careful prompt engineering",
    "none": "No tool support capabilities"
  },
  "structured_output_levels": {
    "native": "Native JSON mode or structured output support",
    "prompted": "Can output JSON with prompting",
    "none": "Poor structured output capability"
  },
  "default_capabilities": {
    "context_length": 16384,
    "max_output_tokens": 4096,
    "tool_support": "none",
    "structured_output": "none",
    "parallel_tools": false,
    "vision_support": false,
    "audio_support": false
  }
}