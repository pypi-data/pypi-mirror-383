> このドキュメントは AI によって生成されました。エラーを見つけた場合や改善のご提案がある場合は、ぜひ貢献してください！ [GitHub で編集](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/HunyuanImageToVideo/ja.md)

HunyuanImageToVideoノードは、Hunyuanビデオモデルを使用して画像をビデオの潜在表現に変換します。このノードは、コンディショニング入力とオプションの開始画像を受け取り、ビデオ生成モデルでさらに処理可能なビデオ潜在表現を生成します。開始画像がビデオ生成プロセスにどのように影響するかを制御するためのさまざまなガイダンスタイプをサポートしています。

## 入力

| パラメータ | データ型 | 必須 | 範囲 | 説明 |
|-----------|-----------|----------|-------|-------------|
| `ポジティブ` | CONDITIONING | はい | - | ビデオ生成をガイドするためのポジティブなコンディショニング入力 |
| `vae` | VAE | はい | - | 画像を潜在空間にエンコードするために使用されるVAEモデル |
| `幅` | INT | はい | 16 から MAX_RESOLUTION | 出力ビデオの幅（ピクセル単位）（デフォルト: 848, ステップ: 16） |
| `高さ` | INT | はい | 16 から MAX_RESOLUTION | 出力ビデオの高さ（ピクセル単位）（デフォルト: 480, ステップ: 16） |
| `長さ` | INT | はい | 1 から MAX_RESOLUTION | 出力ビデオのフレーム数（デフォルト: 53, ステップ: 4） |
| `バッチサイズ` | INT | はい | 1 から 4096 | 同時に生成するビデオの数（デフォルト: 1） |
| `ガイダンスタイプ` | COMBO | はい | "v1 (concat)"<br>"v2 (replace)"<br>"custom" | 開始画像をビデオ生成に組み込む方法 |
| `開始画像` | IMAGE | いいえ | - | ビデオ生成を初期化するためのオプションの開始画像 |

**注記:** `start_image`が提供された場合、ノードは選択された`guidance_type`に基づいて異なるガイダンス方法を使用します：

- "v1 (concat)": 画像の潜在表現をビデオの潜在表現と連結します
- "v2 (replace)": 初期のビデオフレームを画像の潜在表現で置き換えます
- "custom": ガイダンスのための参照潜在表現として画像を使用します

## 出力

| 出力名 | データ型 | 説明 |
|-------------|-----------|-------------|
| `潜在` | CONDITIONING | start_imageが提供された場合に画像ガイダンスが適用された修正済みポジティブコンディショニング |
| `latent` | LATENT | ビデオ生成モデルによるさらなる処理の準備が整ったビデオ潜在表現 |
