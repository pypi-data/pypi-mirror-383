> 本文档由 AI 生成。如果您发现任何错误或有改进建议，欢迎贡献！ [在 GitHub 上编辑](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/UNetSelfAttentionMultiply/zh.md)

UNetSelfAttentionMultiply 节点用于对 UNet 模型中的自注意力机制的查询、键、值和输出组件应用乘法因子。通过调整注意力计算不同部分的缩放比例，您可以探索注意力权重如何影响模型的行为表现。

## 输入参数

| 参数 | 数据类型 | 必需 | 取值范围 | 描述 |
|-----------|-----------|----------|-------|-------------|
| `模型` | MODEL | 是 | - | 需要应用注意力缩放因子的 UNet 模型 |
| `q` | FLOAT | 否 | 0.0 - 10.0 | 查询组件的乘法因子（默认值：1.0） |
| `k` | FLOAT | 否 | 0.0 - 10.0 | 键组件的乘法因子（默认值：1.0） |
| `v` | FLOAT | 否 | 0.0 - 10.0 | 值组件的乘法因子（默认值：1.0） |
| `输出` | FLOAT | 否 | 0.0 - 10.0 | 输出组件的乘法因子（默认值：1.0） |

## 输出结果

| 输出名称 | 数据类型 | 描述 |
|-------------|-----------|-------------|
| `MODEL` | MODEL | 经过注意力组件缩放处理后的 UNet 模型 |
