> Эта документация была создана с помощью ИИ. Если вы обнаружите ошибки или у вас есть предложения по улучшению, пожалуйста, внесите свой вклад! [Редактировать на GitHub](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/TextEncodeHunyuanVideo_ImageToVideo/ru.md)

Узел TextEncodeHunyuanVideo_ImageToVideo создает кондиционирующие данные для генерации видео, комбинируя текстовые промпты с эмбеддингами изображений. Он использует модель CLIP для обработки как текстового ввода, так и визуальной информации из вывода CLIP vision, а затем генерирует токены, которые объединяют эти два источника в соответствии с указанной настройкой чередования изображений.

## Входы

| Параметр | Тип данных | Обязательно | Диапазон | Описание |
|-----------|-----------|----------|-------|-------------|
| `clip` | CLIP | Да | - | Модель CLIP, используемая для токенизации и кодирования |
| `выход clip_vision` | CLIP_VISION_OUTPUT | Да | - | Визуальные эмбеддинги из модели CLIP vision, которые предоставляют контекст изображения |
| `подсказка` | STRING | Да | - | Текстовое описание для управления генерацией видео, поддерживает многострочный ввод и динамические промпты |
| `перемежение изображения` | INT | Да | 1-512 | Степень влияния изображения по сравнению с текстовым промптом. Более высокое значение означает большее влияние текстового промпта. (по умолчанию: 2) |

## Выходы

| Имя выхода | Тип данных | Описание |
|-------------|-----------|-------------|
| `CONDITIONING` | CONDITIONING | Кондиционирующие данные, объединяющие текстовую и визуальную информацию для генерации видео |
