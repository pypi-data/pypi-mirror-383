> Эта документация была создана с помощью ИИ. Если вы обнаружите ошибки или у вас есть предложения по улучшению, пожалуйста, внесите свой вклад! [Редактировать на GitHub](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/TrainLoraNode/ru.md)

Узел TrainLoraNode создает и обучает модель LoRA (Low-Rank Adaptation) на диффузионной модели, используя предоставленные латентные представления и данные кондиционирования. Он позволяет тонко настраивать модель с пользовательскими параметрами обучения, оптимизаторами и функциями потерь. Узел выдает обученную модель с примененным LoRA, веса LoRA, метрики потерь при обучении и общее количество выполненных шагов обучения.

## Входные параметры

| Параметр | Тип данных | Обязательный | Диапазон | Описание |
|-----------|-----------|----------|-------|-------------|
| `model` | MODEL | Да | - | Модель, на которой будет обучаться LoRA. |
| `latents` | LATENT | Да | - | Латентные представления, используемые для обучения, служат набором данных/входными данными для модели. |
| `positive` | CONDITIONING | Да | - | Положительное кондиционирование, используемое для обучения. |
| `batch_size` | INT | Да | 1-10000 | Размер пакета, используемый для обучения (по умолчанию: 1). |
| `grad_accumulation_steps` | INT | Да | 1-1024 | Количество шагов накопления градиента, используемых для обучения (по умолчанию: 1). |
| `steps` | INT | Да | 1-100000 | Количество шагов для обучения LoRA (по умолчанию: 16). |
| `learning_rate` | FLOAT | Да | 0.0000001-1.0 | Скорость обучения, используемая для тренировки (по умолчанию: 0.0005). |
| `rank` | INT | Да | 1-128 | Ранг слоев LoRA (по умолчанию: 8). |
| `optimizer` | COMBO | Да | "AdamW"<br>"Adam"<br>"SGD"<br>"RMSprop" | Оптимизатор, используемый для обучения (по умолчанию: "AdamW"). |
| `loss_function` | COMBO | Да | "MSE"<br>"L1"<br>"Huber"<br>"SmoothL1" | Функция потерь, используемая для обучения (по умолчанию: "MSE"). |
| `seed` | INT | Да | 0-18446744073709551615 | Сид (начальное значение), используемое для обучения (используется в генераторе для инициализации весов LoRA и сэмплирования шума) (по умолчанию: 0). |
| `training_dtype` | COMBO | Да | "bf16"<br>"fp32" | Тип данных (dtype), используемый для обучения (по умолчанию: "bf16"). |
| `lora_dtype` | COMBO | Да | "bf16"<br>"fp32" | Тип данных (dtype), используемый для LoRA (по умолчанию: "bf16"). |
| `algorithm` | COMBO | Да | Доступно несколько вариантов | Алгоритм, используемый для обучения. |
| `gradient_checkpointing` | BOOLEAN | Да | - | Использовать контрольные точки градиента для обучения (по умолчанию: True). |
| `existing_lora` | COMBO | Да | Доступно несколько вариантов | Существующий LoRA, к которому нужно добавить новые веса. Установите в None для создания нового LoRA (по умолчанию: "[None]"). |

**Примечание:** Количество входных данных положительного кондиционирования должно соответствовать количеству латентных изображений. Если предоставлено только одно положительное кондиционирование для нескольких изображений, оно будет автоматически повторено для всех изображений.

## Выходные данные

| Имя выхода | Тип данных | Описание |
|-------------|-----------|-------------|
| `model_with_lora` | MODEL | Исходная модель с примененным обученным LoRA. |
| `lora` | LORA_MODEL | Обученные веса LoRA, которые можно сохранить или применить к другим моделям. |
| `loss` | LOSS_MAP | Словарь, содержащий значения потерь во время обучения с течением времени. |
| `steps` | INT | Общее количество выполненных шагов обучения (включая любые предыдущие шаги из существующего LoRA). |
