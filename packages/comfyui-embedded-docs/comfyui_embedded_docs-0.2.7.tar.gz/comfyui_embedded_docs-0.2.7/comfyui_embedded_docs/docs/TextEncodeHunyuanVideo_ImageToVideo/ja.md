> このドキュメントは AI によって生成されました。エラーを見つけた場合や改善のご提案がある場合は、ぜひ貢献してください！ [GitHub で編集](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/TextEncodeHunyuanVideo_ImageToVideo/ja.md)

TextEncodeHunyuanVideo_ImageToVideoノードは、テキストプロンプトと画像埋め込みを組み合わせることで、動画生成のためのコンディショニングデータを作成します。CLIPモデルを使用してテキスト入力とCLIPビジョン出力からの視覚情報の両方を処理し、指定された画像インターリーブ設定に従ってこれら2つのソースをブレンドしたトークンを生成します。

## 入力

| パラメータ | データ型 | 必須 | 範囲 | 説明 |
|-----------|-----------|----------|-------|-------------|
| `clip` | CLIP | はい | - | トークン化とエンコードに使用されるCLIPモデル |
| `clip_vision_output` | CLIP_VISION_OUTPUT | はい | - | 画像コンテキストを提供するCLIPビジョンモデルからの視覚的埋め込み |
| `プロンプト` | STRING | はい | - | 動画生成をガイドするテキスト記述。複数行入力と動的プロンプトをサポート |
| `画像インターリーブ` | INT | はい | 1-512 | 画像がテキストプロンプトに対してどれだけ影響を与えるか。数値が高いほどテキストプロンプトからの影響が強くなります。（デフォルト: 2） |

## 出力

| 出力名 | データ型 | 説明 |
|-------------|-----------|-------------|
| `CONDITIONING` | CONDITIONING | テキストと画像情報を組み合わせた動画生成のためのコンディショニングデータ |
