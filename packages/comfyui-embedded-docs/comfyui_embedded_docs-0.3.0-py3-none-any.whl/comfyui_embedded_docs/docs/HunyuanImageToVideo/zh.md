> 本文档由 AI 生成。如果您发现任何错误或有改进建议，欢迎贡献！ [在 GitHub 上编辑](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/HunyuanImageToVideo/zh.md)

HunyuanImageToVideo 节点使用混元视频模型将图像转换为视频潜在表示。该节点接收条件输入和可选的起始图像，生成可供视频生成模型进一步处理的视频潜在表示。该节点支持不同的引导类型，用于控制起始图像对视频生成过程的影响方式。

## 输入参数

| 参数名 | 数据类型 | 必填 | 取值范围 | 描述 |
|-----------|-----------|----------|-------|-------------|
| `正向` | CONDITIONING | 是 | - | 用于引导视频生成的正向条件输入 |
| `vae` | VAE | 是 | - | 用于将图像编码到潜在空间的 VAE 模型 |
| `宽度` | INT | 是 | 16 至 MAX_RESOLUTION | 输出视频的宽度（单位：像素，默认值：848，步长：16） |
| `高度` | INT | 是 | 16 至 MAX_RESOLUTION | 输出视频的高度（单位：像素，默认值：480，步长：16） |
| `长度` | INT | 是 | 1 至 MAX_RESOLUTION | 输出视频的帧数（默认值：53，步长：4） |
| `批量大小` | INT | 是 | 1 至 4096 | 同时生成的视频数量（默认值：1） |
| `指导类型` | COMBO | 是 | "v1 (concat)"<br>"v2 (replace)"<br>"custom" | 将起始图像融入视频生成的方法 |
| `起始图像` | IMAGE | 否 | - | 用于初始化视频生成的可选起始图像 |

**注意：** 当提供 `start_image` 时，节点会根据选择的 `guidance_type` 使用不同的引导方法：

- "v1 (concat)"：将图像潜在表示与视频潜在表示进行拼接
- "v2 (replace)"：用图像潜在表示替换初始视频帧
- "custom"：使用图像作为参考潜在表示进行引导

## 输出参数

| 输出名称 | 数据类型 | 描述 |
|-------------|-----------|-------------|
| `潜在空间` | CONDITIONING | 应用了图像引导的修改后正向条件（当提供 start_image 时） |
| `latent` | LATENT | 准备供视频生成模型进一步处理的视频潜在表示 |
