> Эта документация была создана с помощью ИИ. Если вы обнаружите ошибки или у вас есть предложения по улучшению, пожалуйста, внесите свой вклад! [Редактировать на GitHub](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/OpenAIChatConfig/ru.md)

Узел OpenAIChatConfig позволяет задавать дополнительные параметры конфигурации для узла OpenAI Chat. Он предоставляет расширенные настройки, которые управляют тем, как модель генерирует ответы, включая поведение усечения, ограничения длины вывода и пользовательские инструкции.

## Входные параметры

| Параметр | Тип данных | Обязательный | Диапазон | Описание |
|-----------|-----------|----------|-------|-------------|
| `truncation` | COMBO | Да | `"auto"`<br>`"disabled"` | Стратегия усечения для ответа модели. auto: Если контекст этого ответа и предыдущих превышает размер контекстного окна модели, модель обрежет ответ, чтобы он поместился в контекстное окно, удаляя элементы ввода в середине разговора. disabled: Если ответ модели превысит размер контекстного окна, запрос завершится с ошибкой 400 (по умолчанию: "auto") |
| `max_output_tokens` | INT | Нет | 16-16384 | Верхняя граница количества токенов, которые могут быть сгенерированы для ответа, включая видимые выходные токены (по умолчанию: 4096) |
| `instructions` | STRING | Нет | - | Дополнительные инструкции для ответа модели (поддерживается многострочный ввод) |

## Выходные параметры

| Выходной параметр | Тип данных | Описание |
|-------------|-----------|-------------|
| `OPENAI_CHAT_CONFIG` | OPENAI_CHAT_CONFIG | Объект конфигурации, содержащий указанные настройки для использования с узлами OpenAI Chat |
