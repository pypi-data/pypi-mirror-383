{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923f7f17-48c6-4cbd-a677-84aff5deee0a",
   "metadata": {},
   "source": [
    "# Welcome to the ninth MAST-ML tutorial notebook, model container hosting!\n",
    "\n",
    "## In this notebook, we will learn about how MAST-ML can be used to:\n",
    "\n",
    "1. [Set up MAST-ML,import dependencies, and set important variables](#task1)\n",
    "2. [Standard machine learning setup](#task2)\n",
    "3. [Perform uncertainty calibration](#task3)\n",
    "4. [Fit domain model](#task4)\n",
    "5. [Gather all files to build model in a container](#task5)\n",
    "6. [Build and push a container with trained model](#task6)\n",
    "\n",
    "\n",
    "Note that this notebook will not work on Google Colab due to the Docker dependency for building containers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b5557-bd4c-4ba5-881b-f95ff8477ce0",
   "metadata": {},
   "source": [
    "## Task 1: Set up MAST-ML,import dependencies, and set important variables<a name=\"task1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4403e077-8cbb-4a65-bf13-7fbef8c65512",
   "metadata": {},
   "source": [
    "Crate a clean environment which will make building a container easier later. The steps needed are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2abd50-deb0-48ab-b818-eb9a655ac95f",
   "metadata": {},
   "source": [
    "1. python3 -m venv python_env\n",
    "2. source python_env/bin/activate\n",
    "3. pip install -U pip\n",
    "5. pip install jupyterlab\n",
    "6. jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e454ba-268a-4338-9b49-7c5ab78f0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install mastml (in this case a specific branch)\n",
    "!pip install git+https://github.com/uw-cmg/MAST-ML.git@dev_lane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920ea27-627a-4bff-8c1b-e605a31f44d8",
   "metadata": {},
   "source": [
    "Import all packages that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938493da-0850-44d3-b732-7f405fd6c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mastml.data_splitters import SklearnDataSplitter, NoSplit\n",
    "from mastml.preprocessing import SklearnPreprocessor\n",
    "from mastml.models import SklearnModel, HostedModel\n",
    "from mastml.datasets import LocalDatasets\n",
    "from mastml.domain import Domain\n",
    "from pathlib import Path\n",
    "\n",
    "import subprocess\n",
    "import docker\n",
    "import shutil\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f6fd8-db24-4f67-9ba0-36c8b38c8412",
   "metadata": {},
   "source": [
    "Define standard variables that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd6573-d3a2-4d19-ac38-02baa25be951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard names and locations to be used\n",
    "cal_name = 'calibration_run'  # Location to save calibration run\n",
    "dom_name = 'domain_run'  # Location to save domain run\n",
    "output = 'container_files'  # Building container\n",
    "docker_username = 'leschultz'  # Username\n",
    "container_name = 'test'  # Container name\n",
    "container_tag = 'dev_test'  # Container tag (or version)\n",
    "target = 'E_regression_shift'  # The target variable\n",
    "extra_columns = ['mat', 'group']  # Columns not used as features\n",
    "\n",
    "# Location in Dockerhub\n",
    "container = '{}/{}:{}'.format(\n",
    "                              docker_username,\n",
    "                              container_name,\n",
    "                              container_tag,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63d423-e110-4ab5-9983-36a4018cd7cd",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad077b6-0c17-42c6-8cfa-d25a2a9a281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in a standard manner\n",
    "d = LocalDatasets(\n",
    "                  file_path='./diffusion.csv',\n",
    "                  target=target,\n",
    "                  extra_columns=extra_columns,\n",
    "                  as_frame=True\n",
    "                  )\n",
    "data_dict = d.load_data()  # The actual loading\n",
    "\n",
    "# Data in a useful form\n",
    "X = data_dict['X']  # The features\n",
    "y = data_dict['y']  # The target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1966c7-c389-4111-bf55-bf4dd21f8a08",
   "metadata": {},
   "source": [
    "## Task 2: Standard machine learning setup<a name=\"task2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd618f27-05b4-4e38-94db-f8a4a60d66c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression metrics to include\n",
    "metrics = [\n",
    "           'r2_score',\n",
    "           'mean_absolute_error',\n",
    "           'root_mean_squared_error',\n",
    "           'rmse_over_stdev',\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a0aaa-13b1-4a59-86d4-051f7f8f0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data scaling that comes standard with many models\n",
    "preprocessor = SklearnPreprocessor(\n",
    "                                   preprocessor='StandardScaler',\n",
    "                                   as_frame=True,\n",
    "                                   )\n",
    "\n",
    "# The type of regression model to use\n",
    "model = SklearnModel(model='RandomForestRegressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64f874-a7e1-4259-b58e-640ec8e71883",
   "metadata": {},
   "source": [
    "## Task 3: Perform uncertainty calibration<a name=\"task3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b813bb8-defb-47f7-99d7-fe72afe707a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The type of cross validation to conduct\n",
    "splitter = SklearnDataSplitter(\n",
    "                               splitter='RepeatedKFold',\n",
    "                               n_repeats=1,\n",
    "                               n_splits=5\n",
    "                               )\n",
    "\n",
    "# Perform unceratinty quantification\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram', 'Error'],\n",
    "                  error_method='stdev_weak_learners',\n",
    "                  recalibrate_errors=True,\n",
    "                  )\n",
    "\n",
    "# Rename the output directory\n",
    "file_to_move = glob.glob('Ran*')[0]\n",
    "subprocess.run(['mv', file_to_move, cal_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2aa12f-2e4b-415e-ac9d-bdb95a91d067",
   "metadata": {},
   "source": [
    "## Task 4: Fit domain model<a name=\"task4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a385a3-b0eb-41a5-904a-c27ae06cdb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain with MADML\n",
    "params = {'n_repeats': 2}\n",
    "domain = ('madml', params)\n",
    "\n",
    "# MADML has a default set of splitters (can add other set with params)\n",
    "splitter = NoSplit()\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  domain=[domain],\n",
    "                  )\n",
    "\n",
    "# Rename the output directory\n",
    "file_to_move = glob.glob('Ran*')[0]\n",
    "subprocess.run(['mv', file_to_move, dom_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24103ff7-1f56-4fb0-a954-9c55ec0ec85f",
   "metadata": {},
   "source": [
    "## Task 5: Gather all files to build model in a container<a name=\"task5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276aab7-1947-4661-b277-7abdd9e7433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the standard objects to create a single model\n",
    "cal_params = os.path.join(cal_name, 'recalibration_parameters_train.csv')\n",
    "model_path = os.path.join(dom_name, 'RandomForestRegressor.pkl')\n",
    "preprocessor_path = os.path.join(dom_name, 'StandardScaler.pkl')\n",
    "domain_path = list(map(str, Path(dom_name).rglob('domain_*.pkl')))\n",
    "\n",
    "files = [cal_params, model_path, preprocessor_path, *domain_path]\n",
    "\n",
    "# Copy the files\n",
    "for f in files:\n",
    "    shutil.copy(f, os.path.join(output, os.path.basename(f)))\n",
    "\n",
    "# The training features\n",
    "X.to_csv(\n",
    "         os.path.join(output, 'X_train.csv'), \n",
    "         index=False\n",
    "         )\n",
    "y.to_csv(\n",
    "         os.path.join(output, 'y_train.csv'), \n",
    "         index=False\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad7a7d1-ffcf-4454-b430-0f958caa9b22",
   "metadata": {},
   "source": [
    "## Task 6: Build and push a container with trained model<a name=\"task6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6134eef-7cfa-434a-a2fa-bb47851d43f3",
   "metadata": {},
   "source": [
    "Build the container from a provided Dockerfile. You need to modify the Dockerfile and the predict.py files according to how the model you build behaves. Consider the type of scaler you use, model type, domain assessments, packages installed by pip, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed335d-db52-4881-98cb-4185f0914042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build container\n",
    "client = docker.from_env()\n",
    "image, _ = client.images.build(\n",
    "                               path=output,\n",
    "                               tag=container,\n",
    "                               quiet=False\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7910b9-f371-4c01-b9d0-a05619f374fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push container\n",
    "client.images.push(\n",
    "                   repository=container_name,\n",
    "                   tag=container_tag\n",
    "                   )\n",
    "\n",
    "client.images.remove(image.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a830ea58-4953-4251-b711-83bd66d1ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now predict on the training featues to make sure the container runs\n",
    "model = HostedModel(container)\n",
    "preds = model.predict(X)\n",
    "print(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
