Metadata-Version: 2.4
Name: script-run-tracker
Version: 0.1.0
Summary: A lightweight SQLite-based run tracker for Python scripts
Home-page: https://github.com/domiterd/run_tracker
Author: Dominik Domiter
Author-email: Dominik Domiter <dominik.domiter@autowallis.hu>
License: MIT
Project-URL: Homepage, https://github.com/domiterd/script-run-tracker
Project-URL: Bug Reports, https://github.com/yourusername/script-run-tracker/issues
Project-URL: Source, https://github.com/yourusername/script-run-tracker
Keywords: logging,tracking,sqlite,scheduler,monitoring
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# Run Tracker

A lightweight SQLite-based run tracker for Python scripts with automatic logging capabilities. Perfect for monitoring scheduled jobs, data pipelines, and automation scripts.

## Features

- üìä **SQLite-based tracking** - No external dependencies
- üìù **Automatic logging** - Creates timestamped log files for each run
- üîÑ **Log rotation** - Automatically manages old log files
- ‚ö° **Context manager support** - Clean and simple API
- üéØ **Trigger tracking** - Distinguishes between manual and scheduled runs
- ‚úÖ **Status tracking** - Automatically tracks success/failure states
- üìÅ **Project organization** - Logs stored alongside your scripts

## Installation

```bash
pip install run-tracker
```

## Quick Start

### 1. Initialize the database

First, create the database schema (run once):

```python
from run_tracker import init_database

init_database('tracking.db')
```

### 2. Register your flow

```python
from run_tracker import register_flow

register_flow(
    db_path='tracking.db',
    flow_name='Daily Data Processing',
    flow_path='/path/to/your/script.py',
    description='Processes daily sales data'
)
```

### 3. Use in your script

```python
from run_tracker import RunTracker

with RunTracker('tracking.db', trigger_type='scheduler') as tracker:
    tracker.log("Starting data processing")
    
    # Your code here
    data = load_data()
    tracker.log(f"Loaded {len(data)} records")
    
    process_data(data)
    tracker.log("Processing complete")
```

## Usage

### Basic Usage

```python
from run_tracker import RunTracker

with RunTracker('tracking.db') as tracker:
    tracker.log("Process started")
    # Your code here
    tracker.log("Process completed")
```

### Custom Project Name

```python
with RunTracker('tracking.db', project_name='my_etl_job') as tracker:
    tracker.log("ETL job started")
    # Your code here
```

### Trigger Types

```python
# For scheduled runs
with RunTracker('tracking.db', trigger_type='scheduler') as tracker:
    tracker.log("Automated run started")

# For manual runs
with RunTracker('tracking.db', trigger_type='manual') as tracker:
    tracker.log("Manual run started")
```

### Log Levels

```python
with RunTracker('tracking.db') as tracker:
    tracker.log("Informational message", level='INFO')
    tracker.log("Debug information", level='DEBUG')
    tracker.log("Warning message", level='WARNING')
    tracker.log("Error occurred", level='ERROR')
    tracker.log("Critical issue", level='CRITICAL')
```

### Configure Log Retention

```python
# Keep only the last 5 log files
with RunTracker('tracking.db', max_log_files=5) as tracker:
    tracker.log("Starting with custom retention")
```

## Database Schema

The package automatically creates two tables:

**flows** - Stores information about your scripts
- flow_id (PRIMARY KEY)
- flow_name
- flow_path
- description
- is_active
- created_at

**runs** - Stores execution history
- run_id (PRIMARY KEY)
- flow_id (FOREIGN KEY)
- status ('running', 'success', 'fail')
- trigger_type ('scheduler', 'manual')
- start_time
- finish_time
- error_message
- log_file_path

## Log Files

Log files are automatically created in a `logs/` directory next to your script:

```
your_project/
‚îú‚îÄ‚îÄ your_script.py
‚îî‚îÄ‚îÄ logs/
    ‚îú‚îÄ‚îÄ your_script_run_1.log
    ‚îú‚îÄ‚îÄ your_script_run_2.log
    ‚îî‚îÄ‚îÄ your_script_run_3.log
```

## Error Handling

RunTracker automatically captures and logs exceptions:

```python
with RunTracker('tracking.db') as tracker:
    tracker.log("Starting risky operation")
    
    # If this raises an exception, it will be:
    # 1. Logged to the log file
    # 2. Stored in the database
    # 3. Re-raised for your handling
    risky_operation()
```

## Utility Functions

### Initialize Database

```python
from run_tracker import init_database

init_database('tracking.db')
```

### Register a Flow

```python
from run_tracker import register_flow

register_flow(
    db_path='tracking.db',
    flow_name='Data Sync Job',
    flow_path='/opt/scripts/data_sync.py',
    description='Syncs data from external API'
)
```

### Deactivate a Flow

```python
from run_tracker import deactivate_flow

deactivate_flow('tracking.db', 'Data Sync Job')
```

## Requirements

- Python 3.7+
- No external dependencies (uses only Python standard library)

## License

MIT License

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Support

If you encounter any issues or have questions, please file an issue on the GitHub repository.
