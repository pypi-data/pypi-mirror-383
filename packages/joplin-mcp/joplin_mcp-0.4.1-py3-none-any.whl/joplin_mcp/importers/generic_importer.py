"""
Generic importer for Joplin MCP.

Handles unknown file formats and "Other applications..." imports.
Acts as a fallback importer for unsupported formats with intelligent delegation to specialized importers.
"""

import logging
import mimetypes
from pathlib import Path
from typing import List, Optional

from ..types.import_types import ImportedNote
from .base import BaseImporter, ImportProcessingError, ImportValidationError
from .utils import csv_to_markdown_table, looks_like_raw_export


class GenericImporter(BaseImporter):
    """Generic importer that delegates to specialized importers or handles unknown formats."""

    def get_supported_extensions(self) -> List[str]:
        """Return list of supported file extensions (generic handles any file)."""
        # GenericImporter handles all files regardless of extension
        # Return empty list to trigger scan_directory_safe's "all files" mode
        return []

    def can_import(self, file_path: Path) -> bool:
        """Check if file can be imported (generic can handle any file)."""
        return True

    def supports_directory(self) -> bool:
        """Generic format supports both files and directories."""
        return True

    async def validate(self, source_path: str) -> bool:
        """Validate source can be processed by generic importer."""
        path = Path(source_path)

        if path.is_file():
            # Use enhanced base class validation for files
            self.validate_file_comprehensive(path, allow_empty=True)
        elif path.is_dir():
            # Use enhanced base class validation for directories
            self.validate_directory_comprehensive(path)
        else:
            raise ImportValidationError(
                f"Path is not a file or directory: {source_path}"
            )

        return True

    async def parse(self, source_path: str) -> List[ImportedNote]:
        """Parse source and convert to ImportedNote objects."""
        path = Path(source_path)

        if path.is_dir():
            # Custom directory processing that can delegate RAW subtrees
            return await self._parse_directory_with_delegation(path)
        else:
            # Process single file
            note = await self._parse_file(path)
            return [note] if note else []

    async def _parse_directory_with_delegation(self, dir_path: Path) -> List[ImportedNote]:
        """Parse a directory, delegating nested RAW exports to RAWImporter.

        - Skips typical non-content folders (e.g., resources, VCS dirs)
        - When a subdirectory looks like a RAW export root, parse that subtree using RAWImporter
        - Otherwise, parse files individually with GenericImporter logic
        """
        notes: List[ImportedNote] = []

        # Import RAWImporter lazily to avoid circular dependencies
        try:
            raw_module = __import__("joplin_mcp.importers.raw_importer", fromlist=["RAWImporter"])
            RAWImporter = getattr(raw_module, "RAWImporter")
        except Exception:
            RAWImporter = None  # Fallback: treat everything generically

        skip_dirs = {"resources", ".git", ".svn", "__pycache__"}

        # DFS traversal with manual stack to allow subtree delegation
        stack: List[Path] = [dir_path]
        root = dir_path.resolve()

        while stack:
            current = stack.pop()
            # If not the root and the directory looks like a RAW export, delegate the whole subtree
            if RAWImporter and current.resolve() != root and looks_like_raw_export(current):
                try:
                    importer = RAWImporter(self.options)
                    sub_notes = await importer.parse(str(current))
                    notes.extend(sub_notes)
                except Exception:
                    # If delegation fails, fall back to generic traversal of this directory
                    pass
                # Do not descend into this subtree further whether delegation succeeded or not
                continue

            # Normal traversal: iterate contents
            try:
                for child in current.iterdir():
                    if child.is_dir():
                        # Skip known non-content folders
                        if child.name.lower() in skip_dirs:
                            continue
                        stack.append(child)
                    elif child.is_file():
                        try:
                            note = await self._parse_file(child)
                            if note:
                                notes.append(note)
                        except Exception as e:
                            logging.getLogger(__name__).warning(
                                "Failed to parse %s: %s", child, str(e)
                            )
            except Exception as e:
                logging.getLogger(__name__).warning(
                    "Failed to scan directory %s: %s", current, str(e)
                )

        return notes

    async def _parse_file(self, file_path: Path) -> Optional[ImportedNote]:
        """Parse a single file by delegating to specialized importers or handling unknown formats."""
        try:
            extension = file_path.suffix.lower().lstrip(".")
            
            # Delegate to specialized importers for known formats
            if extension in ["md", "markdown"]:
                return await self._delegate_to_importer("markdown_importer", "MarkdownImporter", file_path)
            
            elif extension in ["html", "htm"]:
                return await self._delegate_to_importer("html_importer", "HTMLImporter", file_path)
            
            elif extension in ["csv"]:
                return await self._delegate_to_importer("csv_importer", "CSVImporter", file_path)
            
            elif extension in ["tsv"]:
                # Handle TSV files (Tab-separated values) - similar to CSV but different delimiter
                return await self._handle_tsv_format(file_path)
            
            
            elif extension in ["jex"]:
                return await self._delegate_to_importer("jex_importer", "JEXImporter", file_path)
            
            
            
            # Handle special formats that need custom processing
            elif extension in ["json"]:
                return await self._handle_json_format(file_path)
            
            elif extension in ["xml"]:
                return await self._handle_xml_format(file_path)
            
            elif extension in ["py", "js", "java", "cpp", "c", "h", "css", "sql"]:
                return await self._handle_code_format(file_path)
            
            elif extension in ["log"]:
                return await self._handle_log_format(file_path)
            
            # Handle truly unknown formats
            else:
                return await self._handle_unknown_format(file_path)

        except Exception as e:
            raise ImportProcessingError(
                f"Error processing file {file_path}: {str(e)}"
            ) from e

    async def _delegate_to_importer(self, module_name: str, class_name: str, file_path: Path) -> Optional[ImportedNote]:
        """Delegate file processing to a specialized importer."""
        try:
            # Dynamic import to avoid circular dependencies
            module = __import__(f"joplin_mcp.importers.{module_name}", fromlist=[class_name])
            importer_class = getattr(module, class_name)
            
            # Create importer instance with same options
            importer = importer_class(self.options)
            
            # Parse the file
            notes = await importer.parse(str(file_path))
            
            # Return first note (specialized importers typically return one note per file)
            if notes:
                note = notes[0]
                # Add generic-import tag to indicate it came through GenericImporter
                if note.tags is None:
                    note.tags = []
                if "generic-import" not in note.tags:
                    note.tags.append("generic-import")
                return note
            
            return None
            
        except Exception as e:
            # If delegation fails, fall back to unknown format handling
            logging.getLogger(__name__).warning(
                "Delegation to %s failed for %s: %s", class_name, file_path, str(e)
            )
            return await self._handle_unknown_format(file_path)

    async def _handle_unknown_format(self, file_path: Path) -> Optional[ImportedNote]:
        """Handle files with truly unknown or unsupported formats."""
        # Detect file characteristics
        extension = file_path.suffix.lower()
        is_binary = self._is_binary_file(file_path)
        mime_type = self._detect_mime_type(file_path)
        file_metadata = self.get_file_metadata_safe(file_path)

        # Extract title from filename
        title = self._extract_title_from_path(file_path)

        if is_binary:
            # Create metadata note for binary files
            body = self._create_binary_file_note(file_path, mime_type, file_metadata.get("size", 0))
            tags = ["binary", "attachment", "generic-import"]
        else:
            # Try to read as text
            try:
                content, used_encoding = self.read_file_safe(file_path)
                if not content.strip():
                    # Handle empty files
                    body = f"# {title}\n\n*This file was empty when imported.*"
                    tags = ["empty-file", "generic-import"]
                else:
                    # Format as code block with basic processing
                    body = self._format_unknown_text_content(content, file_path, mime_type)
                    tags = self.extract_hashtags_safe(content) + ["generic-import"]
            except Exception:
                # If reading fails, treat as binary
                body = self._create_binary_file_note(file_path, mime_type, file_metadata.get("size", 0))
                tags = ["binary", "read-error", "generic-import"]

            # Add file type tags
            if extension:
                tags.append(f"ext{extension.replace('.', '-')}")

            if mime_type:
                main_type = mime_type.split("/")[0]
                tags.append(f"type-{main_type}")

        # Create note using enhanced base class utilities
        return self.create_imported_note_safe(
            title=title,
            body=body,
            file_path=file_path,
            tags=list(set(tags)),  # Remove duplicates
            additional_metadata={
                "original_format": "generic",
                "file_extension": extension,
                "mime_type": mime_type,
                "is_binary": is_binary,
            },
        )

    def _format_unknown_text_content(self, content: str, file_path: Path, mime_type: Optional[str]) -> str:
        """Format unknown text content with basic processing."""
        extension = file_path.suffix.lower()
        
        # For code-like files, use syntax highlighting
        if extension in {".py", ".js", ".java", ".cpp", ".c", ".h", ".css", ".sql", ".json", ".xml"}:
            language = extension.lstrip(".")
            if language == "py":
                language = "python"
            elif language == "js":
                language = "javascript"
            
            return f"# {self._extract_title_from_path(file_path)}\n\n```{language}\n{content}\n```"
        
        # For log files, preserve formatting
        elif extension in {".log"}:
            return f"# {self._extract_title_from_path(file_path)}\n\n```\n{content}\n```"
        
        # For other text files, add basic formatting
        else:
            lines = content.split('\n')
            if len(lines) > 1 and len(lines[0]) < 100:
                # First line might be a title
                title = lines[0].strip()
                body = '\n'.join(lines[1:]).strip()
                if title and body:
                    return f"# {title}\n\n{body}"
            
            return f"# {self._extract_title_from_path(file_path)}\n\n{content}"

    def _is_binary_file(self, file_path: Path) -> bool:
        """Check if file is binary."""
        try:
            # Read first 8192 bytes to check for binary content
            with open(file_path, "rb") as f:
                chunk = f.read(8192)
                if not chunk:
                    return False

            # Check for null bytes (common in binary files)
            if b'\x00' in chunk:
                return True

            # Check for high percentage of non-text characters
            text_chars = sum(1 for byte in chunk if 32 <= byte <= 126 or byte in (9, 10, 13))
            return (text_chars / len(chunk)) < 0.75

        except Exception:
            return False

    def _detect_mime_type(self, file_path: Path) -> Optional[str]:
        """Detect MIME type of file."""
        mime_type, _ = mimetypes.guess_type(str(file_path))
        return mime_type

    def _extract_title_from_path(self, file_path: Path) -> str:
        """Extract title from file path."""
        # Use filename without extension as base title
        title = file_path.stem

        # Replace common separators with spaces
        title = title.replace("_", " ").replace("-", " ").replace(".", " ")
        
        # Remove extra whitespace
        title = " ".join(title.split())

        # Capitalize first letter of each word
        title = " ".join(word.capitalize() for word in title.split())

        return title or "Untitled"

    def _create_binary_file_note(self, file_path: Path, mime_type: Optional[str], file_size: int) -> str:
        """Create note content for binary files."""
        size_mb = file_size / (1024 * 1024)

        content = f"# {self._extract_title_from_path(file_path)}\n\n"
        content += "**Binary File Information**\n\n"
        content += f"- **File**: `{file_path.name}`\n"
        content += f"- **Size**: {file_size:,} bytes ({size_mb:.2f} MB)\n"
        content += f"- **Type**: {mime_type or 'Unknown'}\n"
        content += f"- **Extension**: {file_path.suffix}\n"
        content += f"- **Location**: `{file_path.parent}`\n\n"
        content += "This is a binary file that cannot be displayed as text. "
        content += "The original file should be accessed directly from its location.\n\n"
        content += f"**Original Path**: `{file_path}`\n"

        return content


    def _format_json_content(self, content: str, title: str) -> str:
        """Format JSON content."""
        try:
            import json

            # Try to parse and pretty-print JSON
            parsed = json.loads(content)
            formatted = json.dumps(parsed, indent=2, ensure_ascii=False)
            return f"# {title}\n\n```json\n{formatted}\n```"
            
        except json.JSONDecodeError:
            # If not valid JSON, return as-is in code block
            return f"# {title}\n\n```json\n{content}\n```"

    def _format_xml_content(self, content: str, title: str) -> str:
        """Format XML content."""
        try:
            import xml.dom.minidom
            
            # Try to pretty-print XML
            dom = xml.dom.minidom.parseString(content)
            formatted = dom.toprettyxml(indent="  ")
            # Remove empty lines
            lines = [line for line in formatted.split('\n') if line.strip()]
            formatted = '\n'.join(lines)
            return f"# {title}\n\n```xml\n{formatted}\n```"

        except Exception:
            # If parsing fails, return as-is in code block
            return f"# {title}\n\n```xml\n{content}\n```"

    def _format_code_content(self, content: str, extension: str, title: str) -> str:
        """Format code content with syntax highlighting."""
        # Map extensions to language names for syntax highlighting
        language_map = {
            "py": "python",
            "js": "javascript",
            "java": "java",
            "cpp": "cpp",
            "c": "c",
            "h": "c",
            "css": "css",
            "sql": "sql"
        }
        
        language = language_map.get(extension, extension)
        return f"# {title}\n\n```{language}\n{content}\n```"

    def _format_log_content(self, content: str, title: str) -> str:
        """Format log file content."""
        # Split into lines and add some basic formatting
        lines = content.strip().split("\n")

        # Limit to last 1000 lines for very large logs
        if len(lines) > 1000:
            content = "\n".join(lines[-1000:])
            header = f"# {title}\n\n**Log File** (showing last 1000 of {len(lines)} lines)\n\n"
        else:
            header = f"# {title}\n\n**Log File Content**\n\n"

        return header + f"```log\n{content}\n```"

    async def _handle_tsv_format(self, file_path: Path) -> Optional[ImportedNote]:
        """Handle TSV (Tab-separated values) files."""
        try:
            content, used_encoding = self.read_file_safe(file_path)
            title = self._extract_title_from_path(file_path)
            
            # Convert TSV to Markdown table using shared utility
            body = csv_to_markdown_table(content, title, delimiter="\t")
            tags = self.extract_hashtags_safe(content) + ["tsv", "tabular", "generic-import"]
            
            return self.create_imported_note_safe(
                title=title,
                body=body,
                file_path=file_path,
                tags=tags,
                additional_metadata={
                    "original_format": "tsv",
                    "encoding": used_encoding,
                },
            )
        except Exception as e:
            logging.getLogger(__name__).warning(
                "TSV processing failed for %s: %s", file_path, str(e)
            )
            return await self._handle_unknown_format(file_path)

    async def _handle_json_format(self, file_path: Path) -> Optional[ImportedNote]:
        """Handle JSON files."""
        try:
            content, used_encoding = self.read_file_safe(file_path)
            title = self._extract_title_from_path(file_path)
            
            # Format JSON content
            body = self._format_json_content(content, title)
            tags = self.extract_hashtags_safe(content) + ["json", "data", "generic-import"]
            
            return self.create_imported_note_safe(
                title=title,
                body=body,
                file_path=file_path,
                tags=tags,
                additional_metadata={
                    "original_format": "json",
                    "encoding": used_encoding,
                },
            )
        except Exception as e:
            logging.getLogger(__name__).warning(
                "JSON processing failed for %s: %s", file_path, str(e)
            )
            return await self._handle_unknown_format(file_path)

    async def _handle_xml_format(self, file_path: Path) -> Optional[ImportedNote]:
        """Handle XML files."""
        try:
            content, used_encoding = self.read_file_safe(file_path)
            title = self._extract_title_from_path(file_path)
            
            # Format XML content
            body = self._format_xml_content(content, title)
            tags = self.extract_hashtags_safe(content) + ["xml", "markup", "generic-import"]
            
            return self.create_imported_note_safe(
                title=title,
                body=body,
                file_path=file_path,
                tags=tags,
                additional_metadata={
                    "original_format": "xml",
                    "encoding": used_encoding,
                },
            )
        except Exception as e:
            logging.getLogger(__name__).warning(
                "XML processing failed for %s: %s", file_path, str(e)
            )
            return await self._handle_unknown_format(file_path)

    async def _handle_code_format(self, file_path: Path) -> Optional[ImportedNote]:
        """Handle code files."""
        try:
            content, used_encoding = self.read_file_safe(file_path)
            title = self._extract_title_from_path(file_path)
            extension = file_path.suffix.lower().lstrip(".")
            
            # Format code content
            body = self._format_code_content(content, extension, title)
            tags = self.extract_hashtags_safe(content) + [extension, "code", "generic-import"]
            
            return self.create_imported_note_safe(
                title=title,
                body=body,
                file_path=file_path,
                tags=tags,
                additional_metadata={
                    "original_format": extension,
                    "encoding": used_encoding,
                },
            )
        except Exception as e:
            logging.getLogger(__name__).warning(
                "Code processing failed for %s: %s", file_path, str(e)
            )
            return await self._handle_unknown_format(file_path)

    async def _handle_log_format(self, file_path: Path) -> Optional[ImportedNote]:
        """Handle log files."""
        try:
            content, used_encoding = self.read_file_safe(file_path)
            title = self._extract_title_from_path(file_path)
            
            # Format log content
            body = self._format_log_content(content, title)
            tags = self.extract_hashtags_safe(content) + ["log", "text", "generic-import"]
            
            return self.create_imported_note_safe(
                title=title,
                body=body,
                file_path=file_path,
                tags=tags,
                additional_metadata={
                    "original_format": "log",
                    "encoding": used_encoding,
                },
            )
        except Exception as e:
            logging.getLogger(__name__).warning(
                "Log processing failed for %s: %s", file_path, str(e)
            )
            return await self._handle_unknown_format(file_path)
